{"meta":{"title":"zhengrenjie blog","subtitle":"","description":"","author":"zhengrenjie","url":"https://www.jelliclecat.cn","root":"/"},"pages":[],"posts":[{"title":"从Mysql不走索引看InnoDB的索引原理","slug":"Mysql-1","date":"2020-03-20T14:29:53.000Z","updated":"2021-06-25T13:47:33.057Z","comments":true,"path":"articles/Mysql/Mysql-1/","link":"","permalink":"https://www.jelliclecat.cn/articles/Mysql/Mysql-1/","excerpt":"","text":"有索引的情况下，Mysql还是扫表，怎么回事今天碰到一个这个问题：在where语句中有一个字段可以走二级索引去范围查的情况下，发现mysql并没有走索引，而是扫表。不知道大家有没有遇到过这个问题，并产生疑问。 为什么mysql在明明有索引的情况下却选择不走索引，而选择扫表呢？今天我们从InnoDB的索引原理讲一下为什么会出现这种现象。 InnoDB索引原理InnoDB对于PK的索引策略和二级索引的策略是不一样的。 部分知识来自于《高性能MySQL》，以及我自己的理解，本人没有看过源码，所以大家对内容要自行甄别对错 数据结构InnoDB的索引数据结构是B树，更准确的说是B+树。为什么是B+树呢？因为B+树叶子节点不带数据，所以存储索引数据可以使用更少的磁盘存储空间，那么在PageCache读盘的时候，预读可以一次读取更多的索引数据，从而使用更少的磁盘IO就可以查询到更多的索引数据，这样就可以更快的定位到数据位置。 聚集索引一张表只能由唯一的聚集索引。一般PK上的索引会自动被设置为聚集索引（但是你也可以先创建聚集索引，再创建PK，大多数情况下，PK索引就是聚集索引）。之所以叫聚集索引，是因为所有叶子节点上的记录都紧凑的按主键顺序存储在磁盘上。由于这个特点，使用主键自增会获得很好的写性能，因为是顺序写。 非聚集索引二级索引和PK索引不一样，虽然数据结构也是B+树，但是叶子节点上的数据记录的是PK的值，而不是实际的数据，所以在使用二级索引查找到的实际是二级索引对应的PK索引。 这样会导致一个问题，就是对于二级索引上的范围查找，会导致大量的随机读IO。因为首先根据二级索引查找到的是一批离散的PK，然后再根据这些PK去查找记录，这时候会发生随机读IO，并且还带来了logn的额外查询时间。 这种索引称为覆盖索引。 覆盖索引上面说到二级索引范围查找带来的随机IO现象，再有一种情况下不会发生，那就是SELECT的字段只有PK和二级索引的列，由于二级索引的叶子节点上保存的就是PK数据，并且二级索引中就保存了列的值，所以这时候不需要再回到PK索引上查找。 所以，如果我们SELECT中的列都有对应的索引存在的话，那么会提升查找效率，因为不需要去真正的记录里面去查找数据，只用在索引数据里面查找就行了。 回答问题好了，对索引原理有一个大致的了解。 那么为什么有时候，where语句里面明明有索引可走的情况下，mysql会选择扫表呢？原因就是扫表是顺序IO，而二级索引是先查找PK，然后再在PK索引中查找，是一个随机IO，外带一个logn的查询开销。 那么当二级索引范围查的扫描列大于一定的数量的时候，explain会发现，prossible_keys显示有索引可走，但是实际的key却没有走索引，type=ALL。 当逐渐缩小二级索引上的查找范围的时候，会发现，mysql会突然又选择去使用prossible_keys下显示的索引了。 举个例子举个例子： 12345678CREATE TABLE `test` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `type` int(11) DEFAULT &#x27;0&#x27;, `status` int(11) DEFAULT &#x27;0&#x27;, `created_at` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_create_at` (`created_at`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; created_at列上有一个二级索引。 使用查询语句： 1SELECT count(*) FROM test WHERE type=? and status=? and created_at&gt;&#x27;2020-01-01 00:00:00&#x27;; 这时explain： select_type type prossible_keys key Extra SIMPLE ALL idx_create_at NULL Using where 可以看到有索引却没有走。 当我们缩小created_at的范围时： 1SELECT count(*) FROM test WHERE type=? and status=? and created_at&gt;&#x27;2020-03-01 00:00:00&#x27;; 这时explain： select_type type prossible_keys key Extra SIMPLE range idx_create_at idx_create_at Using index condition; Using where 发现同样一个语句，在范围查不同的情况下，有时候Mysql会选择不同的方式去进行实际的查找。 刚刚说过了，这种权衡是在较少的随机IO和较多的顺序IO这两者之间抉择的，并不是没有走索引性能就一定会差。 *这里count()可以换成表中各个具体的列，但是不要用select ，这样不会走索引，原因我还不知道* 让mysql强制走索引也很简单，查询分两步走： 12SELECT count(*)FROM test as a inner join test as b on a.id=b.id and a.status=? AND a.type=? AND b.created_at&gt;&quot;2020-01-01 00:00:00&quot;; 再次expain： select_type table type prossible_keys key Extra SIMPLE b range PRIMARY,idx_create_at idx_create_at Using where; Using index SIMPLE a eq_ref PRIMARY PRIMARY Using where 发现两次查询都走了索引。 并且使用idx_create_at二级索引的时候，还是用了覆盖索引，因为这一步只取出了PK。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.jelliclecat.cn/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.jelliclecat.cn/tags/Mysql/"}]},{"title":"聊透Spring-2-聊透Xml配置和注解的混用以及其原理","slug":"spring-2","date":"2019-11-21T14:29:53.000Z","updated":"2021-06-25T13:47:33.049Z","comments":true,"path":"articles/Spring/spring-2/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/spring-2/","excerpt":"","text":"先看看AnnotationConfigApplicationContext上篇博客我们讲了一下ClassPathXmlApplicationContext解析Xml的总体流程，没有深入到细节。ClassPathXmlApplicationContext负责解析Xml，对应Xml的spring启动方式，我们可以这样启动spring： ApplicationContext context = new ClassPathXmlApplicationContext(“applicationContext.xml”); 相对应的AnnotationConfigApplicationContext代表的是以纯注解的方式启动spring： ApplicationContext context = new AnnotationConfigApplicationContext(“com.zrj”); 这里传入的参数是扫描的Root包，spring会扫描这个包下的所有Class。 ###AnnotationConfigApplicationContext启动spring 12345678910111213141516171819// AnnotationConfigApplicationContext.javapublic class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry &#123; private final AnnotatedBeanDefinitionReader reader; private final ClassPathBeanDefinitionScanner scanner; public AnnotationConfigApplicationContext() &#123; this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; public AnnotationConfigApplicationContext(String... basePackages) &#123; this(); scan(basePackages); refresh(); &#125; // ...&#125; new AnnotationConfigApplicationContext(“com.nowcoder.spring”); 这样创建的AnnotationConfigApplicationContext调用的是上面的构造函数（其他的构造函数不列举了，都差不多），这样构造出来后，创建了一个AnnotatedBeanDefinitionReader和一个ClassPathBeanDefinitionScanner，这个两个类非常的重要，AnnotationConfigApplicationContext所有的工作都交给了这两个类去完成。 看一下这个构造函数，首先调用this()初始化reader、scanner，然后调用scan，这是关键的一步，最终调用了ClassPathBeanDefinitionScanner#doScan方法： 1234567891011121314151617181920212223242526protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, &quot;At least one base package must be specified&quot;); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) &#123; postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; if (candidate instanceof AnnotatedBeanDefinition) &#123; AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions; &#125; 首先调用findCandidateComponents找到basePackage下所有的BeanDefinition，这个过程比较复杂，是通过ASM实现的，通过读取Class文件的字节码，拿到类的元信息。这里Spring可以说是一丝不苟，通过读取Class字节码的方式，让自己的扫描元信息的工作坚决不影响类的加载周期，换句话说这里完全不用对类进行任何的加载工作就能拿到类的元信息了。 找到所有的BeanDefinition后，工作就完成了一大半，Spring启动简单来说分两步走，第一步构建BeanDefinition作为Bean的候选人，第二步就是将BeanDefinition创建成一个个的Bean对象。 最后将BeanDefinition注册进BeanFactory中，等待Bean被创建。 在构造函数最后调用了refresh方法，这个方法和上篇博客中的ClassPathXmlApplicationContext里面调用的refresh是同一个方法，这里不再赘述了。 传送门：透Spring-1-ClassPathXmlApplicationContext 注意一点，AbstractRefreshableApplicationContext#refreshBeanFactory方法会调用loadBeanDefinitions，这是一个模板方法，在ClassPathXmlApplicationContext是有实现的，但是在AnnotationConfigApplicationContext是没有实现的，因为AnnotationConfigApplicationContext中BeanDefinition的扫描是交给ClassPathBeanDefinitionScanner去做的。 调用完doScan之后，调用了AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry)： 12345678910111213// ClassPathBeanDefinitionScanner.javapublic int scan(String... basePackages) &#123; int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); doScan(basePackages); // Register annotation config processors, if necessary. if (this.includeAnnotationConfig) &#123; AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125; return (this.registry.getBeanDefinitionCount() - beanCountAtScanStart);&#125; 这个方法用于开启对注解的解析，这部分代码后面会讲解，我们还会遇到它的。includeAnnotationConfig这个配置默认是true。 Xml和注解配置Spring混用是怎么实现的？如果我们纯粹的使用Xml作为Spring的启动方式的话，那么全部bean的组装是有Xml文件控制的，类中定义的@Autowired、@Component等等注解是不会起作用的。 但是绝大多数情况下，我们既需要使用Xml配置Bean，同时也需要使用Annotation配置或组装Bean。这是怎么做到的呢？就是使用context扩展标签（除了spring-beans.xsd中定义的标签以外的所有标签都是扩展标签）： &lt;context:component-scan base-package=”xxx.xxx” /&gt; 这个标签的命名空间是http://www.springframework.org/schema/context 通过使用&lt;context:component-scan base-package=”xxx.xxx” /&gt;标签，spring会去扫描base-package指定的包下去扫描所有的Class文件，寻找潜在的Bean（被@Component标注的类），然后转换为BeanDefinition注册进BeanFactory。当使用component-scan扩展标签的时候，就默认开启了注解的解析功能，这时候，工程中所有的注解就会被spring识别并处理了（比如@Autowired、@Configuration、@Resource等）。 这里一旦使用了component-scan标签，那么不管是通过Xml标签解得来的Bean还是通过component-scan扫描注解得来Bean都会开启对Spring注解（例如@Autowired）的识别（不单单是base-package中扫描得到的Bean），因为component-scan会使得BeanFactory注册一系类解析注解的BeanPostProcessor，这些BeanPostProcessor对于不管是Xml定义的Bean还是注解配置的Bean都会生效。这部分稍后会分析代码。 这样就实现了spring中Xml和注解混用。 扩展标签在context:component-scan中，context是命名空间，真正的标签是component-scan。 与component-scan相似的扩展标签还有很多，具体的作用不解释了，我们主要关心的是扩展标签是如何被spring处理的，部分扩展标签如下： &lt;context:annotation-config /&gt; &lt;task:scheduled-tasks /&gt; &lt;cache:annotation-driven mode=”aspectj”/&gt; &lt;aop:aspectj-autoproxy /&gt; 每个扩展标签（这里的context、task、cache、aop就是扩展标签的命名空间，”:”后面的是扩展标签）都有各自的命名空间，例如context标签的命名空间就是http://www.springframework.org/schema/context。 那么扩展标签（或者说扩展命名空间，spring中是以命名空间为单位进行处理的而不是单个的标签）在spring中是如何被处理的呢？关键就在spring.handler配置文件中。 spring.handler配置文件首先，我们关注一下Spring中的一个配置文件，spring.handler： 12345http\\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandlerhttp\\://www.springframework.org/schema/jee=org.springframework.ejb.config.JeeNamespaceHandlerhttp\\://www.springframework.org/schema/lang=org.springframework.scripting.config.LangNamespaceHandlerhttp\\://www.springframework.org/schema/task=org.springframework.scheduling.config.TaskNamespaceHandlerhttp\\://www.springframework.org/schema/cache=org.springframework.cache.config.CacheNamespaceHandler 这是一个property文件，由几组key-value组成，现在先看一下这个配置文件中的value，value比较明显都是一个全限定类名。很容易就能找到上面我们使用的context的命名空间的处理类：ContextNamespaceHandler。我们的context命名空间就是在这个类里面被处理的了。 1234567891011121314public class ContextNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser(&quot;property-placeholder&quot;, new PropertyPlaceholderBeanDefinitionParser()); registerBeanDefinitionParser(&quot;property-override&quot;, new PropertyOverrideBeanDefinitionParser()); registerBeanDefinitionParser(&quot;annotation-config&quot;, new AnnotationConfigBeanDefinitionParser()); registerBeanDefinitionParser(&quot;component-scan&quot;, new ComponentScanBeanDefinitionParser()); registerBeanDefinitionParser(&quot;load-time-weaver&quot;, new LoadTimeWeaverBeanDefinitionParser()); registerBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser()); registerBeanDefinitionParser(&quot;mbean-export&quot;, new MBeanExportBeanDefinitionParser()); registerBeanDefinitionParser(&quot;mbean-server&quot;, new MBeanServerBeanDefinitionParser()); &#125;&#125; 可以看到ContextNamespaceHandler可以处理context命名空间中的如下扩展标签： property-placeholder property-override annotation-config component-scan load-time-weaver spring-configured mbean-export mbean-server 每个标签又有一个专门的类去解析，这里我们用上面举过的例子component-scan，看看它的处理类：ComponentScanBeanDefinitionParser。 在哪里解析扩展标签这里要回顾上一篇博客中的ClassPathXmlApplicationContext类了，上一节我们讲到了Xml的解析流程交给了DefaultBeanDefinitionDocumentReader去控制，这个类会遍历Xml中的每一个节点，根据节点的类型执行不同的逻辑。关键的方法在这里（类：DefaultBeanDefinitionDocumentReader.java）： 123456789101112131415161718192021// DefaultBeanDefinitionDocumentReader.javaprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 方法遍历了root（代表Xml配置文件的根节点），然后遍历每一个子节点。关键方法是delegate.isDefaultNamespace这个方法，这个方法用来判断当前节点是否是beans命名空间（也是spring的Xml配置文件的默认命名空间），如果是，则继续对&lt;bean&gt;标签等进行解析，这个步骤在上篇博客详细讲过了（传送门：透Spring-1-ClassPathXmlApplicationContext），如果不是，则是扩展标签，需要对扩展命名空间内的标签进行特殊处理，也就是调用delegate.parseCustomElement(ele)方法。 12345678// BeanDefinitionParserDelegate.java// 判断当前标签是否属于默认（beans）命名空间的方法public static final String BEANS_NAMESPACE_URI = &quot;http://www.springframework.org/schema/beans&quot;;public boolean isDefaultNamespace(@Nullable String namespaceUri) &#123; return (!StringUtils.hasLength(namespaceUri) || BEANS_NAMESPACE_URI.equals(namespaceUri)); &#125; 好了我们接着看parseCustomElement方法，同样在BeanDefinitionParserDelegate类中： 1234567891011121314// BeanDefinitionParserDelegate.java public BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); if (namespaceUri == null) &#123; return null; &#125; NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(&quot;Unable to locate Spring NamespaceHandler for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;, ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); &#125; 这里通过节点的namespaceUri找到对应处理当前节点标签的命名空间的NamespaceHandler，然后调用parse方法去解析。 嗯~我们终于看到NamespaceHandler的身影了，还记得上面的ContextNamespaceHandler吗？快接上了，咱们继续往下看。 这里getNamespaceHandlerResolver是获取的什么类呢？获取的是接口NamespaceHandlerResolver的实现类，这个接口的实现类只有一个，就是DefaultNamespaceHandlerResolver。 DefaultNamespaceHandlerResolver1public static final String DEFAULT_HANDLER_MAPPINGS_LOCATION = &quot;META-INF/spring.handlers&quot;; 这是这个类上来的第一句话，是不是特别特别的亲切！（前提是你好好看了这篇博客上面的内容） 这里定义了一个字符串常量表示spring.handlers文件的位置，你是不是立马就意识到了这个类是用来干嘛的，没错，就是用来加载spring.handlers配置的，不光可以加载配置，还可以决定一个namespaceUri对应的是哪个NamespaceHandler。看看具体代码： 123456789101112131415161718192021222324252627282930313233// DefaultNamespaceHandlerResolver.java public NamespaceHandler resolve(String namespaceUri) &#123; Map&lt;String, Object&gt; handlerMappings = getHandlerMappings(); Object handlerOrClassName = handlerMappings.get(namespaceUri); if (handlerOrClassName == null) &#123; return null; &#125; else if (handlerOrClassName instanceof NamespaceHandler) &#123; return (NamespaceHandler) handlerOrClassName; &#125; else &#123; String className = (String) handlerOrClassName; try &#123; Class&lt;?&gt; handlerClass = ClassUtils.forName(className, this.classLoader); if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) &#123; throw new FatalBeanException(&quot;Class [&quot; + className + &quot;] for namespace [&quot; + namespaceUri + &quot;] does not implement the [&quot; + NamespaceHandler.class.getName() + &quot;] interface&quot;); &#125; NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass); namespaceHandler.init(); handlerMappings.put(namespaceUri, namespaceHandler); return namespaceHandler; &#125; catch (ClassNotFoundException ex) &#123; throw new FatalBeanException(&quot;Could not find NamespaceHandler class [&quot; + className + &quot;] for namespace [&quot; + namespaceUri + &quot;]&quot;, ex); &#125; catch (LinkageError err) &#123; throw new FatalBeanException(&quot;Unresolvable class definition for NamespaceHandler class [&quot; + className + &quot;] for namespace [&quot; + namespaceUri + &quot;]&quot;, err); &#125; &#125; &#125; 这里的handlerMappings最初是一个字符串对字符串的map，因为最初加载的spring.handlers还是一个property文件。最后一个else里面，使用反射区拿到对应的NamespaceHandler，并保存在了handlerMappings中。这样，就加载完了spring.handlers中的所有命名空间对应的NamespaceHandler实例了。 这里是不是有点SPI的味道~ 当spring扫描Xml扫描到&lt;context:component-scan base-package=&quot;xxx.xxx&quot; /&gt;标签时，发现不是默认命名空间，就去查找context的命名空间，就是http://www.springframework.org/schema/context，然后通过DefaultNamespaceHandlerResolver查找这个命名空间对应的NamespaceHandler，这里就找到了ContextNamespaceHandler。 接下来的解析工作就委托给了ContextNamespaceHandler，所以我们接着看ContextNamespaceHandler。 ContextNamespaceHandler这个类只是实现了init方法，注册进了一批标签和处理类，component-scan的处理类是ComponentScanBeanDefinitionParser，我们重点看看这个类，这个类实现了BeanDefinitionParser接口： 123public interface BeanDefinitionParser &#123; BeanDefinition parse(Element element, ParserContext parserContext);&#125; ComponentScanBeanDefinitionParser的实现如下： 12345678910111213// ComponentScanBeanDefinitionParser.java public BeanDefinition parse(Element element, ParserContext parserContext) &#123; String basePackage = element.getAttribute(BASE_PACKAGE_ATTRIBUTE); basePackage = parserContext.getReaderContext().getEnvironment().resolvePlaceholders(basePackage); String[] basePackages = StringUtils.tokenizeToStringArray(basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); ClassPathBeanDefinitionScanner scanner = configureScanner(parserContext, element); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = scanner.doScan(basePackages); registerComponents(parserContext.getReaderContext(), beanDefinitions, element); return null; &#125; 流程非常清晰： 从Element中找到base-package属性，设置待扫描包。 创建ClassPathBeanDefinitionScanner 使用ClassPathBeanDefinitionScanner扫描base-package包获得BeanDefinitions 将扫描到的BeanDefinitions注册进BeanFactory 这里有个熟悉的朋友：ClassPathBeanDefinitionScanner，在这篇博客的开头讲AnnotationConfigApplicationContext的时候就提到了ClassPathBeanDefinitionScanner，里面有一个重要的方法叫doScan，用来将Class文件转换为BeanDefinition。 处理注解这里还没完，还有一个重要的功能没有看到，就是在什么地方注册的处理注解的BeanPostProcessor。 上面parse的最后调用了registerComponents方法： 12345678910111213141516171819202122232425// ComponentScanBeanDefinitionParser.javaprotected void registerComponents( XmlReaderContext readerContext, Set&lt;BeanDefinitionHolder&gt; beanDefinitions, Element element) &#123; Object source = readerContext.extractSource(element); CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), source); for (BeanDefinitionHolder beanDefHolder : beanDefinitions) &#123; compositeDef.addNestedComponent(new BeanComponentDefinition(beanDefHolder)); &#125; // Register annotation config processors, if necessary. boolean annotationConfig = true; if (element.hasAttribute(ANNOTATION_CONFIG_ATTRIBUTE)) &#123; annotationConfig = Boolean.valueOf(element.getAttribute(ANNOTATION_CONFIG_ATTRIBUTE)); &#125; if (annotationConfig) &#123; Set&lt;BeanDefinitionHolder&gt; processorDefinitions = AnnotationConfigUtils.registerAnnotationConfigProcessors(readerContext.getRegistry(), source); for (BeanDefinitionHolder processorDefinition : processorDefinitions) &#123; compositeDef.addNestedComponent(new BeanComponentDefinition(processorDefinition)); &#125; &#125; readerContext.fireComponentRegistered(compositeDef); &#125; 里面调用了 1AnnotationConfigUtils.registerAnnotationConfigProcessors(readerContext.getRegistry(), source); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// AnnotationConfigUtils.javapublic static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, @Nullable Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(4); if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( &quot;Cannot load optional framework class: &quot; + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs; &#125; 里面注册了一堆BeanPostProcessor： ConfigurationClassPostProcessor，处理@Configuration和@Bean AutowiredAnnotationBeanPostProcessor，处理@Autowired，@Value等相关注解 CommonAnnotationBeanPostProcessor，支持JSR-250标签，@PostConstruct、@PreDestroy、@Resource EventListenerMethodProcessor，处理@EventListener 这些BeanPostProcessor就是处理各种注解的关键了。 这里也印证了上面说到的，由于注解的处理是借助BeanPostProcessor实现的，所以对所有的BeanDefinition都会生效，即使是从Xml解析过来的BeanDefinition。 要注意的是，BeanPostProcessor有很多子接口，不同的子类是在不同的生命周期中执行的，这个咱们之后会用一篇博客聊透Bean的生命周期。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"}]},{"title":"聊透Spring-1-ClassPathXmlApplicationContext源码解析","slug":"spring-1","date":"2019-11-13T14:41:10.000Z","updated":"2021-06-25T13:47:33.056Z","comments":true,"path":"articles/Spring/spring-1/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/spring-1/","excerpt":"","text":"前言离上次写Spring的博客有一段时间了，之前写了三篇关于Spring的博客： spring-beans包源码阅读-2-BeanWrapper spring-beans包源码阅读-3-BeanDefinition spring-beans包源码阅读-4-BeanFactory 从标题可以很容易看出来，主要讲了三个类BeanWrapper，BeanDefinition，BeanFactory。这三个类是spring-beans这个包里面的核心类，但是，这三篇文章在我现在看来写得不算太完整，有些理解也不算太准确。这篇博客会从ClassPathXmlApplicationContext入手，完整的走一遍Spring从xml配置文件加载Bean的过程。 Context做的事情和BeanFactory不太一样，Context是BeanFactory的超集，具有BeanFactory的所有功能。Context还提供了对Resource的访问、捕获事件等。 一、入口1ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); ClassPathXmlApplicationContext的用法入上所示，直接看构造方法： 12345678910public ClassPathXmlApplicationContext( String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125;&#125; 最终使用的是重载的构造方法，具体代码如上，关键的一步是调用refresh方法，所以接下来看看refresh接口： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125; &#125; 咱们到了ClassPathXmlApplicationContext最关键的一个方法，这个方法里面包含了完整的Spring启动代码。这里先不进到具体的代码里面，先大致解释一下每个方法的作用： prepareRefresh，没干什么，设置了几个标志位标志refresh开始，不是重点。 obtainFreshBeanFactory，很关键，首先完成了读取Xml并将配置翻译为BeanDefinition，创建了一个DefaultListableBeanFactory作为Context的BeanFactory。DefaultListableBeanFactory前面的博客中讲到过，是BeanFactory的默认实现，也是BeanFactory功能的集大成者。最后将翻译过后的BeanDefinition全部注册进BeanFactory，等待初始化。 prepareBeanFactory，对BeanFactory做了一些基本的设置，设置了一些默认的Bean，比如ApplicationContext，这也是为什么我们我们可以直接通过@Autowired去获取一个ApplicationContext的原因。 postProcessBeanFactory，一个钩子方法，或者说模板方法，留给子类实现。 invokeBeanFactoryPostProcessors，调用所有的BeanFactoryPostProcessor，这步会借助BeanFactory的getBean去获取BeanFactoryPostProcessor类型的Bean。 registerBeanPostProcessors，找出所有的BeanPostProcessor，然后注册进BeanFactory，等待会实例化和初始化Bean的时候使用。 initMessageSource，初始化国际化资源。 initApplicationEventMulticaster，初始化事件分发器。 onRefresh，也是一个模板方法。 registerListeners，找到时间监听的Bean，并注册。 finishBeanFactoryInitialization，重要的一个方法，里面触发了对所有Bean的初始化。 finishRefresh，结束了Context的refresh，修改一些标志位和发送刷新完成的事件。 接下来我们一个一个跟进这些方法，国际化、事件相关的不是本篇博客的重点。 二、obtainFreshBeanFactory方法这个方法创建了BeanFactory，并将Xml配置中配置的Bean转换成了BeanDefinition。 123456789101112131415161718192021// AbstractRefreshableApplicationContext.java @Override protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125; &#125; 跟两次就能来到这个方法，这个方法会先试图销毁已经存在的BeanFactory，然后会创建一个DefaultListableBeanFactory（可以参考spring-beans包源码阅读-4-BeanFactory）。最后调用了一个loadBeanDefinitions，这步就是从Xml配置中加载BeanDefinition了，我们稍微进去看一下： 1234567891011121314151617// AbstractXmlApplicationContext.java@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context&#x27;s // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader);&#125; 可以看到创建了一个XmlBeanDefinitionReader去解析Xml，继续进入loadBeanDefinitions方法，最终可以走到XmlBeanDefinitionReader的doLoadBeanDefinition方法中： 123456789// XmlBeanDefinitionReader.javaprotected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource); return registerBeanDefinitions(doc, resource); &#125; // ...&#125; 首先使用doLoadDocument将Xml文件通过w3c.doc工具解析成Document，这部分就不赘述了，继续看registerBeanDefinitions： 1234567// XmlBeanDefinitionReader.javapublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; 重要的方法是registerBeanDefinitions，这个方法在BeanDefinitionDocumentReader这个类中，这个类是专门负责将Document转换成BeanDefinition的类，进去看： 1234567891011121314151617181920212223242526272829303132// DefaultBeanDefinitionDocumentReader.javaprotected void doRegisterBeanDefinitions(Element root) &#123; // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(&quot;Skipped XML bean definition file due to specified profiles [&quot; + profileSpec + &quot;] not matching: &quot; + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; preProcessXml(root); parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent;&#125; 最后的方法落在这里： 123preProcessXml(root);parseBeanDefinitions(root, this.delegate);postProcessXml(root); preProcessXml和postProcessXml也是两个模板方法，留给子类一个扩展的入口，核心方法是parseBeanDefinitions，最后会走到parseDefaultElement方法： 123456789101112131415private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125;&#125; 这个方法里面可以看到解析Xml的骨干方法了： importBeanDefinitionResource，首先检查Xml有没有import其他的Xml配置文件，如果有，则递归解析import标签所引用的配置文件。 processAliasRegistration，解析alias标签。 processBeanDefinition，核心方法，将&lt;bean&gt;标签解析成一个BeanDefinition。 doRegisterBeanDefinitions，递归解析嵌套的&lt;beans&gt;标签。 所以我们只用看processBeanDefinition就可以了，最终会走到BeanDefinitionParserDelegate这个类中，这个类是更加具体的解析一个BeanDefinition的委托类，不要和刚刚的BeanDefinitionDocumentReader混淆，BeanDefinitionDocumentReader负责整体的解析流程的控制，没有涉及解析的细节，解析每个具体的BeanDefinition的任务是交给BeanDefinitionParserDelegate实现的。BeanDefinitionParserDelegate里面可以看到完整的将Xml标签转换为Definition的过程，核心方法是parseBeanDefinitionElement： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// BeanDefinitionParserDelegate.java@Nullablepublic AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, @Nullable BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; try &#123; AbstractBeanDefinition bd = createBeanDefinition(className, parent); parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); parseMetaElements(ele, bd); parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); parseConstructorArgElements(ele, bd); parsePropertyElements(ele, bd); parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error(&quot;Bean class [&quot; + className + &quot;] not found&quot;, ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error(&quot;Class that bean class [&quot; + className + &quot;] depends on not found&quot;, ele, err); &#125; catch (Throwable ex) &#123; error(&quot;Unexpected failure during bean definition parsing&quot;, ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null;&#125; 到这里其实就比较简单了，首先拿到Xml标签中的class属性的值，然后就可以去拿到对应的Class创建BeanDefinition了，然后后面继续解析Xml的节点，将配置都保存在BeanDefinition中。 最后我们回到DefaultBeanDefinitionDocumentReader中的processBeanDefinition方法中，可以看到在我们获得具体BeanDefinition之后，调用registerBeanDefinition方法将BeanDefinition和classname注册进了我们的BeanFactory中，这部分代码如下： 1234567891011121314151617// DefaultBeanDefinitionDocumentReader.javaprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(&quot;Failed to register bean definition with name &#x27;&quot; + bdHolder.getBeanName() + &quot;&#x27;&quot;, ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; 1234567891011121314151617// BeanDefinitionReaderUtils.javapublic static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125;&#125; 具体解析每个标签的过程就不追究细节了。 这部分代码在《Spring源码深度解析》这本书里面有详细介绍。 三、invokeBeanFactoryPostProcessors方法BeanFactoryPostProcessor的作用，是给用户在BeanDefinition被创建为一个个Bean实例之前做一些自定义行为的扩展接口，这个接口在一些和Spring对接的框架里面非常有用，比如我们的框架中可以自定义了各种各样的Bean，最终需要Spring帮我们去创建和管理这些Bean，那么我们可以写一个自定义的BeanFactoryPostProcessor，然后里面将我们的各种类转换为BeanDefinition，最后注册进BeanFactory，在之后BeanFactory创建Bean的时候，就会把我们自定义的BeanDefinition也创建成一个一个的Bean了。当然我们也可以通过这个接口去修改已经存在的BeanDefinition。 invokeBeanFactoryPostProcessors这个方法最终委托给了PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors方法，这个方法非常的长，但是其实很有调理，主要是通过检查我们的BeanFactory和BeanFactoryPostProcessor不同的子类，并通过不同优先级去执行所有的BeanFactoryPostProcessor。 这里有个问题，获取BeanFactoryPostProcessor是通过BeanFactory#getBean的方法获取的，这意味着如果在BeanFactoryPostProcessor中引用了其他的Bean，就会引起这些Bean提前被创建，那么某些BeanFactoryPostProcessor和BeanPostProcessor的自定义修改就不会对这些Bean生效了，这块需要特别注意，不然会引发一些奇怪的Bug。 这部分代码就不跟踪了，因为调用栈很浅，最终代码全部都在PostProcessorRegistrationDelegate这个类里面，大家自行查看吧。 四、registerBeanPostProcessors方法BeanPostProcessors和BeanFactoryPostProcessor的作用不同，BeanPostProcessors作用在Bean的实例化、初始化的过程中。BeanPostProcessors有很多不同的扩展子类，用于创建Bean的不同生命周期中。 这里的registerBeanPostProcessors方法和invokeBeanFactoryPostProcessors方法非常类似，代码也在PostProcessorRegistrationDelegate中，只不过这里只是将所有的BeanPostProcessors通过BeanFactory#getBean找出来，然后注册进了BeanFactory中。 具体的细节也不展开了，这里的逻辑比较简单，同时要注意被BeanPostProcessors引用的Bean会提前暴露的问题。 五、finishBeanFactoryInitialization方法最后看看这个方法： 12345678910111213141516171819202122232425262728293031// AbstractApplicationContext.javaprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Initialize conversion service for this context. if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons();&#125; 最关键的是最后一行： 1beanFactory.preInstantiateSingletons(); 这里加载了Spring中所有的Bean： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// DefaultListableBeanFactory.javapublic void preInstantiateSingletons() throws BeansException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Pre-instantiating singletons in &quot; + this); &#125; // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; getBean(beanName); &#125; &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125; &#125; 这里挨个初始化了所有的Bean，也比较好懂。 当调用了getBean之后，后面的逻辑就可以参考spring-beans包源码阅读-4-BeanFactory这篇博客了。 六、总结ClassPathXmlApplicationContext的代码还是挺简单的，这个Context负责的是纯Xml配置的Spring加载方式，之后我们会讲AnnotationConfigApplicationContext，这个Context支持的是注解配置类型的加载方式，以及会讲Xml和注解是如何混合使用的。 在讲AnnotationConfigApplicationContext之前，还会使用一篇博客回顾一下BeanFactory初始化Bean的过程。 这里有一篇宏观讲解Spring的博客，是我见过的所有写Spring博客里面最好的一篇，推荐给大家： Spring 框架的设计理念与设计模式分析","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"}]},{"title":"6.1-11.11小结","slug":"summary-20191112","date":"2019-11-12T00:02:10.000Z","updated":"2021-06-25T13:47:33.045Z","comments":true,"path":"articles/Summary/summary-20191112/","link":"","permalink":"https://www.jelliclecat.cn/articles/Summary/summary-20191112/","excerpt":"","text":"6.1-11.11小结上次总结的时间是6月1号，到今天已经过去了五个半月，在这过去的五个半月里面，我对自己的学习进度还是比较满意的。 六月份，我参加了第五届中间件性能挑战赛，这对我来说是一个全新的开始。初赛的内容是基于dubbo框架设计一个动态负载均衡算法，使得系统的综合吞吐量达到最大，我的思路是在加权随机的基础上，根据服务器的实时负载计算权重，使得负载最为合理。考虑使用加权随机是因为随机加权不需要加锁，而加权轮询是需要加锁的，后来想想这也许是一个错误的决定，因为在所有provider几乎满载的情况下，随机带来的扰动是非常致命的。在主体思路确定之后，整个算法面临着两个挑战：一，如何获取服务器的实时负载，并让Gateway实时知晓每个服务器的负载；二，如何根据负载调整权重。框架提供了一个callback方法，用于让provider给Gateway回传信息，这样，服务器可以自行计算自己的负载，然后通过callback回传给Gateway，这样Gateway就知晓了每个provider的负载。但是这样明显是不合理的，因为一个callback的RPC调用将会有数毫秒的延迟，在高并发下，数毫秒的延迟意味着Gateway在这段时间里面使用的是没有调整的权重，轻则导致整体性能下降，重则导致服务器负载发生震荡，甚至宕机。解决办法是使用Gateway去记录每个provider的负载，这样可以做到实时性，但是会轻微加重Gateway的负载（记录负载必须加锁）。另一种更好的做法是使用CompletableFuture，这样可以实现反应式流回压。再就是如何根据负载信息调整权重了，我采用的方式也比较简单，根据服务器的平均响应时间和空闲线程数综合考虑，平均响应时间使用的是时间窗平均值的做法，削弱服务器响应时间的波动。如果服务器略微超载，那么多余的请求会排队，由于排队对于提升系统吞吐量没有任何的帮助，所以我们需要尽量避免排队。这时有一个非常棒的算法叫做“拥塞探测法”，指的是在高并发下，如果有请求在某个时间内返回，那么可以断言该服务器没有拥塞（或者说排队），这样，我们就可以适当提高该服务器的权重，同理，如果某个服务器在一段时间内没有任何请求可以在一个规定的时间内返回，那么可以认定该服务器发生了拥塞，那么可以对其进行适当的降权。最终初赛的成绩是34名（4000+队伍）。复赛由于主办方在最后十天换了题目并且清空了排行榜，而我在那段时间又特别忙，所以没有走到最后，改题之前到了30多名。复赛的内容是做一个类似TSDB的存储引擎，具有范围查、范围聚合的能力，能够在规定时间内写入100G的数据，具体思路不展开了。 不得不说中间件比赛真是有意思，见识了很多大佬，也有机会认识一些大佬，和大佬们交流交流心得，学习到了很多，也意识到自己的路还有很长很长。 中间件比赛之后，我对dubbo以及中间件框架产生了浓厚的兴趣，这段时间，基本上都在dubbo、motan、netty这三个框架的源码中遨游。不得不说，读源码真是一件会让人上瘾的事情，每天不读一下就是难受。由于自己有着浓厚的兴趣，netty的核心代码（Channel、Pipeline、ChannelHandler、ByteBuf、Codec、Bootstrap）已经熟读于心了，核心原理自然是完全掌握。netty的内存管理也是一绝，这部分还没看到，之后会继续将整个框架看完。motan是dubbo的缩小版，代码量不多，极其适合作为RPC的入门读物，motan的整个框架我也看完了。之后就是dubbo，看motan之前，觉得dubbo充满了炫技，有点点华而不实的感觉。在看motan的过程中将两个框架来回比较，每一个motan的实现我都会去看看dubbo是怎么实现的，最后看完motan之后，才觉得dubbo的代码是那么的好。dubbo我还没有完全看完，不过主体框架以及编程思路可以算是略知一二了。看完这几个框架之后，我有点手痒痒，就自己尝试写了一个RPC框架，在自己写框架的时候，才发现自己的很多不足，比如异常的设计，如何增强代码健壮性等等问题，都足以让我头疼，不过我就是邯郸学步，一点一点来吧。 最近好好研究了一下异步RPC框架怎么实现。motan的做法是对业务方的服务接口自己扩展一个接口，这个接口是motan自己使用JavaPoet动态生成的，用以对每个同步的业务方法扩展出一个对应的异步方法。实际上业务方会得到两个接口，异步接口使用的接口是motan生成的接口而不是自己定义的业务接口。这样做怎么说呢，也算是一种实现吧，有一点不好的是motan扩展出的异步方法返回的是一个AsyncResponse，这是RPC框架内部的一个类。我觉得更好的方法是返回一个CompletableFuture，这样RPC内部的类没有侵入到业务方法中去。还有一点不好的是这里框架自动生成了一个接口，如果对这点不了的会有一些框架学习成本，没有做到完全的RPC过程透明。dubbo提供了N种异步调用的方式dubbo全链路异步调用，在我看来只有第一种是合理的做法，其他的做法都会对业务方造成框架侵入，第一种做法也和我自己实现的异步调用的方法不谋而合。我自己实现了一版异步RPC调用，原理是RPC框架检查业务方方法返回的类型是否是一个CompletableFuture，如果是，则判断该方法是异步方法。这样做其实非常的合理，因为如果业务方定义的返回类型是CompletableFuture，那毫无疑问这个方法将会是一个异步方法，这样，业务方的服务实现照常的实现，不会感觉到RPC的存在，也就是没有任何的侵入，然后RPC在业务方返回的CompletableFuture中的whenComplete方法中注册一条回调函数链，这个链一端连着业务方的实现（RPC的Server端），一端连着调用方（RPC的Client端），中间跨越了网络，当业务方complete的时候，就会沿着回调链一直触发到Client端。这样，无论是在调用方还是实现方，都感觉不到RPC框架的存在，实现了零侵入，这种模式也是一种反应式设计模式。实现连接 最近回头再看Spring的源码，之前写了几篇Spring的博客，但其实没有写的很详细，最近回头再看Spring的源码的时候才觉得，温故而知新。Spring的源码看的非常舒服，除了使用非人类的“\\t”作为代码缩进之外。我看源码的时候多了很多的思考，比如看到Spring执行PostBeanProcessor的时候，我不禁会想，如果在PostBeanProcessor中引用了其他的Bean，是不是会导致这部分被引用的Bean提前被加载，从而享受不到后面的PostBeanProcessor的服务呢？答案还真是这样，这里通过看源码发现了一个大坑，如果这里没注意的话，极可能发生一些难以排查的Bug。还有，Xml加载Bean很容易理解，只用根据Xml中定义的class字段使用ClassLoader去加载就行了，但是Annotation的Scan加载Bean怎么办？如果使用ClassLoader去加载每个Class文件的话，开销大不说，如果不小心触发了一些Class的static域怎么办，那样肯定会出一些奇怪的Bug。那到底要怎么样既不去加载Class，又可以获取Class的元信息呢？抱着这个疑问去看源码，发现果然，Spring直接将class的ASM字节码作为byte[]读出来，然后去解析class的字节码找每个class的原信息。不看不知道，一看吓一跳啊，之前从来没有在其他博客里面见有人提到这个问题。 博客有段时间没有更新了，主要是我这个人，非得到自己看源码看到满足才会愿意花时间写博客，看源码在学习新知识的同时，也会抛出各种新的东西需要去理解和学习，所以一般来说会等到把一个框架的主要代码都看得差不多了才会想起来写博客。接下来应该是写一些Spring的源码以及Dubbo的源码解读吧，这段时间回头看了Spring的Context部分，之后会继续看一下SpringMVC和WebFlux的部分，Spring对反应式的支持还是非常吸引我的。之前想了继续完善一下Netty的源码博客，比如编解码部分、ByteBuf部分，但是想了想，这部分代码没有Channel内容多，也没有transport包下的代码有意思，所以还是先搁置吧。Dubbo的话，应该说还没有仔细深入的看，motan源码倒是看完了，motan可以用1-2篇博客简单介绍一下，因为代码量确实不多，实现也没有dubbo那么复杂。 接下来学习的话，Spring再巩固巩固吧，paxos确实很迷人，尝试了几次也没有完整的理解下来，距离2020年还有1个半月，这一个半月尽量将raft算法彻底掌握吧。当然不止这一个算法，Dubbo和Zookeeper可以继续深入一下。之前看了Tomcat的部分源码，只看了很少的一部分，HTTP协议解析的那一部分，结合《How Tomcat Works》这本书一起看的，这本书真的很不错，手把手教你写一个Tomcat，但是里面代码比较老了，是基于Tomcat4写的，所以里面有很多代码需要自己重新写一遍（作者也不是全部代码都是自己写的，有一些类直接copy的tomcat4源码），这儿部分暂时没有时间去做了，接下来看时间吧，攒的源码有点过于多了，看不过来，只能一个一个来，路漫漫其修远。 双11买了四本书：《反应式设计模式》、《Hbase原理与实现》、《Hadoop权威指南》、《k8s权威指南》，接下来应该好好看看Hadoop家族和微服务了（明年吧），还有Linux的一些底层原理。 之前找到了Linux0.1.1版的源码，据说这是Linux能找到的最早的一个版本，用我大学的C语言基础尝试着看了一部分，可把我牛逼坏了，哎哟叉会腰。目前还没有看出什么名堂，C语言还需要系统的学习才行，看源码是需要一定基础的。 在知乎上经常看到不建议阅读源码的论调，说“代码本来就不是给人读的”，“读源码是效率极低的学习方法”等等。我强烈反对这种观点。不得不说，看源码的门槛非常高，至少比普通的开发工作难很多（业务开发，不是开发框架），需要有扎实的语言基础和英语基础，还需要有对框架正确的理解，以及一些阅读源码甚至开发框架的经验。但是一旦读顺了之后，就会发现所有的其他学习方法都不如静下心来debug一遍源码。debug源码耗费的时间并没有想象中那么长，只不过源码极其枯燥并且抽象，所以这个过程很少有人能坚持下来，但是如果能坚持下来，会发现这样做比看书要好得多，书本上的生涩语言并不如源码来得直接，特别是从英文翻译过来的书籍。拿《Netty In Action》举例，我手上的是中文版的，很多翻译晦涩难懂，很难将那些翻译后的中文名词和源码中原本的内容相对应起来，把本来就很难懂的代码徒增了不少理解成本，而《Spring In Action》我看的是英文原版，只能说你看过一次英文版的就再也回不去了。当然，书也是必不可少的，书本最有用的部分在于目录部分，因为目录是对一个知识体系很好的归纳，可以根据目录去查漏补缺，毕竟看源码很难有这种宏观的体系感，对于你感兴趣的章节，也可以静下心来阅读以下，也许能发现不一样的视角和知识盲点。总的来说，优秀的源码是programmer最好的教材，其次是优秀的英文书籍，再其次是中文书籍，最次的是视屏，我觉得视屏知识密度太低。 加油吧，作为一个Java小菜鸡~","categories":[{"name":"Summary","slug":"Summary","permalink":"https://www.jelliclecat.cn/categories/Summary/"}],"tags":[{"name":"Summary","slug":"Summary","permalink":"https://www.jelliclecat.cn/tags/Summary/"}]},{"title":"Netty源码-5-Accept和Read事件监听过程","slug":"netty-5","date":"2019-09-21T11:32:03.000Z","updated":"2021-06-25T13:47:33.056Z","comments":true,"path":"articles/Netty/netty-5/","link":"","permalink":"https://www.jelliclecat.cn/articles/Netty/netty-5/","excerpt":"","text":"前面我们仔细分析过NioEventLoop的源码，以及找到了Netty事件驱动的源头代码： 12345678910111213141516171819202122232425262728293031323334353637private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) &#123; final EventLoop eventLoop; try &#123; eventLoop = ch.eventLoop(); &#125; catch (Throwable ignored) &#123; return; &#125; if (eventLoop != this || eventLoop == null) &#123; return; &#125; unsafe.close(unsafe.voidPromise()); return; &#125; try &#123; int readyOps = k.readyOps(); if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); &#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125; &#125; 讲NioEventLoop的时候，后面就没有接着讲事件被触发之后的操作了，我们当时只知道了，这里是Nio事件触发的源头，是监听事件的地方。 这篇博客我们来看一看，当SelectionKey.OP_READ | SelectionKey.OP_ACCEPT这两个事件被Netty监听到之后，Netty会怎么操作。 先看看SelectionKey.OP_ACCEPT。看到这篇文章应该知道了，Server端的是有两个层次的：boss和worker，boss用来接收ACCEPT事件，worker用来持有建立的连接以及继续监听连接的读写事件。 所以这里SelectionKey.OP_ACCEPT事件触发后，最后一定会创建一个连接，并交给worker线程池。下面我们分析源码： ServerBootstrapAcceptor先必须要回忆一下ServerBootstrapAcceptor，这个类是一个ChannelHanlder，是boss Channel创建的时候注册到pipeline中去的： 1234567891011121314// ServerBootstrap#init()方法，截取一部分p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) throws Exception &#123; // ... ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125;&#125;); 最后调用pipeline.addLast，将一个ServerBootstrapAcceptor实例注册进了pipeline。 ServerBootstrapAcceptor.java： 1234567891011121314151617181920212223242526272829private static class ServerBootstrapAcceptor extends ChannelInboundHandlerAdapter &#123; @Override @SuppressWarnings(&quot;unchecked&quot;) public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) &#123; child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); &#125; try &#123; childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125; &#125;&#125; 这个类主要实现了channelRead方法，这个方法会被pipeline#fireChannelRead方法回调。也就是说，read事件链被触发的时候，这个方法会被回调，这里记一下这个方法被触发的地方。 先看一下这个channelRead方法干了什么，首先传进来的参数msg被强制转换为Channel类型，这个应该是在调用方保证的，可以猜想到这个Channel是刚刚Client和Server建立的连接。接下来调用child.pipeline().addLast(childHandler)往子Channel的pipeline中注册一个事件处理类：childHandler，这个类是在调用ServerBootstrap#childHandler的时候设置进来的。最后将Channel注册进childGroup，这个childGroup是一个NioEventLoopGroup，也就是worker线程池。 这里验证了我们的猜想，总结一下： 初始化NioServerSocketChannel（init方法）的时候，在NioServerSocketChannel的pipeline中注册了一个ServerBootstrapAcceptor，当这个类的channelRead方法被回调时，建立的连接，也就是一个新的Channel被注册到worker线程组中。 这就是NioServerSocketChannel负责的功能啦。 好了，大致流程已经分析清楚了，接下来仔仔细细的看一下整个流程： SelectionKey.OP_ACCEPT事件这个事件被触发的时候，调用了unsafe.read()，这个unsafe就是NioServerSocketChannel对应的unsafe，调用的unsafe#read方法实际是调用NioServerSocketChannel的父类AbstractNioMessageChannel中的内部类NioMessageUnsafe#read方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960private final class NioMessageUnsafe extends AbstractNioUnsafe &#123; private final List&lt;Object&gt; readBuf = new ArrayList&lt;Object&gt;(); @Override public void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try &#123; try &#123; do &#123; int localRead = doReadMessages(readBuf); if (localRead == 0) &#123; break; &#125; if (localRead &lt; 0) &#123; closed = true; break; &#125; allocHandle.incMessagesRead(localRead); &#125; while (allocHandle.continueReading()); &#125; catch (Throwable t) &#123; exception = t; &#125; int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; readPending = false; pipeline.fireChannelRead(readBuf.get(i)); &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (exception != null) &#123; closed = closeOnReadError(exception); pipeline.fireExceptionCaught(exception); &#125; if (closed) &#123; inputShutdown = true; if (isOpen()) &#123; close(voidPromise()); &#125; &#125; &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125; &#125;&#125; 这里面干了两件事： doReadMessages(readBuf) pipeline.fireChannelRead(readBuf.get(i)) 惯例一个个看： 1. doReadMessages123456789101112131415161718192021@Overrideprotected int doReadMessages(List&lt;Object&gt; buf) throws Exception &#123; SocketChannel ch = SocketUtils.accept(javaChannel()); try &#123; if (ch != null) &#123; buf.add(new NioSocketChannel(this, ch)); return 1; &#125; &#125; catch (Throwable t) &#123; logger.warn(&quot;Failed to create a new channel from an accepted socket.&quot;, t); try &#123; ch.close(); &#125; catch (Throwable t2) &#123; logger.warn(&quot;Failed to close a socket.&quot;, t2); &#125; &#125; return 0;&#125; 这个方法在子类NioServerSocketChannel中，很简单的调用了SocketUtils.accept(javaChannel())，其实就是调用JDK原生的accept方法，接纳一个新的客户端，并返回一个客户端的句柄SocketChannel，然后包装成Netty中的NioSocketChannel类，add到buf中。 当这个方法返回之后，List&lt;Object&gt; buf中被填充了所有刚刚Accept的Client端的连接。 2. pipeline.fireChannelRead(readBuf.get(i))这个方法在一个for循环中，挨个触发channelRead事件链。这里的pipeline是NioServerSocketChannel这个类的pipeline，所以最终会调用ServerBootstrapAcceptor的channelRead方法，传入的参数是NioSocketChannel实例。 这里调用完后，后面的逻辑上面已经讲过了，ServerBootstrapAcceptor将这个客户端连接实例注册到了worker线程组中，开始监听并处理之后的读写事件。 总结这里比较容易疑惑的是，SelectionKey.OP_READ | SelectionKey.OP_ACCEPT这两个事件被同时监听，并都触发的是unsafe.read()事件，但是，如果调用了NioServerSocketChannel的pipeline的channelRead事件链的话，可以保证一定是SelectionKey.OP_ACCEPT事件，因为NioServerSocketChannel监听的只有OP_ACCEPT事件，所以NioServerSocketChannel绑定的EventLoop中触发出来的事件只可能是SelectionKey.OP_ACCEPT事件被触发。 趁热打铁看看Read事件Read事件由刚刚accept之后，new出来的NioSocketChannel来负责监听。看看这个类的创建： NioSocketChannel.java构造函数： 1234public NioSocketChannel(Channel parent, SocketChannel socket) &#123; super(parent, socket); config = new NioSocketChannelConfig(this, socket.socket()); &#125; 调用了父类AbstractNioByteChannel的构造函数，注意：NioSocketChannel.java的父类是AbstractNioByteChannel，NioServerSocketChannel的父类是AbstractNioMessageChannel，这两个父类是不一样的，名字很相似。 【BTW】NioServerSocketChannel和NioSocketChannel两个句柄前面是服务端的，后面是客户端的，和JDK命名规则一样。 看AbstractNioByteChannel的构造： 123protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123; super(parent, ch, SelectionKey.OP_READ);&#125; 好了这里得到了一个重要的信息，NioSocketChannel监听的是OP_READ事件。剩下两个参数很好理解，parent就是NioServerSocketChannel实例，ch是Accept事件被处理之后，创建的java原生的SelectableChannel。 所以当监听到OP_READ事件之后，会调用unsafe.read()，这里的unsafe是在AbstractNioByteChannel中实现的unsafe，看看它的NioByteUnsafe#read方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Overridepublic final void read() &#123; final ChannelConfig config = config(); if (shouldBreakReadReady(config)) &#123; clearReadPending(); return; &#125; final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &#123; do &#123; byteBuf = allocHandle.allocate(allocator); allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &#123; byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; if (close) &#123; readPending = false; &#125; break; &#125; allocHandle.incMessagesRead(1); readPending = false; pipeline.fireChannelRead(byteBuf); byteBuf = null; &#125; while (allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (close) &#123; closeOnRead(pipeline); &#125; &#125; catch (Throwable t) &#123; handleReadException(pipeline, byteBuf, t, close, allocHandle); &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125;&#125; 对应于NioMessageUnsafe的read方法，这里同样干了两个重要的事情： doReadBytes fireChannelRead doReadBytes这个方法是一个模板方法，在NioSocketChannel中实现： 12345protected int doReadBytes(ByteBuf byteBuf) throws Exception &#123; final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.attemptedBytesRead(byteBuf.writableBytes()); return byteBuf.writeBytes(javaChannel(), allocHandle.attemptedBytesRead());&#125; 这里其实就是将javaChannel中的数据读到了ByteBuf中，然后返回了，具体过程不再分析。 fireChannelRead在获取到javaChannel中的读取的数据之后，就发起了channelRead事件链，这里的pipeline是NioSocketChannel的事件链（看pipeline事件触发时，要看清楚pipeline是属于哪个Channel，这将影响后面的逻辑分析）。 最终会运行childHandler的channelRead方法，也就是开发者自定义的handler，这里其实就是把事件传给了开发人员的逻辑里面了。 以Netty提供的Echo例子为例，它的childHandler是这样的： 1234567891011121314151617181920@Sharablepublic class EchoServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ctx.write(msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) &#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); &#125;&#125; 直接将读到的数据使用ctx.write(msg)方法写回到客户端，也就是echo服务。 这里解释一下@Sharable： @Sharable12345678910111213/** * Indicates that the same instance of the annotated &#123;@link ChannelHandler&#125; * can be added to one or more &#123;@link ChannelPipeline&#125;s multiple times * without a race condition. * &lt;p&gt; * If this annotation is not specified, you have to create a new handler * instance every time you add it to a pipeline because it has unshared * state such as member variables. * &lt;p&gt; * This annotation is provided for documentation purpose, just like * &lt;a href=&quot;http://www.javaconcurrencyinpractice.com/annotations/doc/&quot;&gt;the JCIP annotations&lt;/a&gt;. */ 表示一个ChannelHandler是否是可以多个Pipeline共享的，可以和：是否是可重入的、是否是可以并发调用的、是否是线程安全的、是否是单例的这几个问题结合起来理解Sharable。 1️⃣","categories":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/tags/Netty/"}]},{"title":"Netty源码-4-ChannelPipeline","slug":"netty-4","date":"2019-09-20T15:32:41.000Z","updated":"2021-06-25T13:47:33.061Z","comments":true,"path":"articles/Netty/netty-4/","link":"","permalink":"https://www.jelliclecat.cn/articles/Netty/netty-4/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940* &lt;pre&gt;* I/O Request* via &#123;@link Channel&#125; or* &#123;@link ChannelHandlerContext&#125;* |* +---------------------------------------------------+---------------+* | ChannelPipeline | |* | \\|/ |* | +---------------------+ +-----------+----------+ |* | | Inbound Handler N | | Outbound Handler 1 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* | | \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler N-1 | | Outbound Handler 2 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ . |* | . . |* | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|* | [ method call] [method call] |* | . . |* | . \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler 2 | | Outbound Handler M-1 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* | | \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler 1 | | Outbound Handler M | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* +---------------+-----------------------------------+---------------+* | \\|/* +---------------+-----------------------------------+---------------+* | | | |* | [ Socket.read() ] [ Socket.write() ] |* | |* | Netty Internal I/O Threads (Transport Implementation) |* +-------------------------------------------------------------------+* &lt;/pre&gt; 这里先帖一段ChannelPipeline.java的注释。 其实pipeline比起三篇博客中介绍的类要简单很多，简单总结如下： 一个Channel对应一个pipeline。 一个Channel对应一个EventLoop。 一个Pipeline中有一个双向链表，链表中保存着两种PipelineHandler：Inbound和Outbound。 入站事件（比如read）会触发所有的InboundHandler中的逻辑，方向从head-&gt;tail。 出站事件（比如write）会触发OutboundHandler中的逻辑，方向从tail-&gt;head。 PipelineHandler并不是直接存在Pipeline中，而是使用了ChannelHandlerContext包装了一下，链表由ChannelHandlerContext构成。 结合这些理解，上图中注释就很容易理解了。 具体内容不分析了，比较简单。 Netty源码分析（三）—数据管道ChannelPipeline源码分析","categories":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/tags/Netty/"}]},{"title":"Netty源码-3-ServerBootstrap","slug":"netty-3","date":"2019-09-20T00:55:10.000Z","updated":"2021-06-25T13:47:33.043Z","comments":true,"path":"articles/Netty/netty-3/","link":"","permalink":"https://www.jelliclecat.cn/articles/Netty/netty-3/","excerpt":"","text":"前面的两篇博客分别分析了NioEventLoopGroup和NioEventLoop这两个类的创建以及重要功能，这为这篇博客全面分析Netty的启动类ServerBootstrap奠定了基础。 先回顾一下Server的核心启动代码： 123456789101112131415161718192021222324252627EventLoopGroup bossGroup = new NioEventLoopGroup(1);EventLoopGroup workerGroup = new NioEventLoopGroup();final EchoServerHandler serverHandler = new EchoServerHandler();try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); p.addLast(serverHandler); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync();&#125; finally &#123; // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully();&#125; 可以看到创建ServerBootstrap的过程，最后调用b.bind(PORT)将服务绑定到端口上。 ServerBootstrap的构造函数什么也没有干，核心的内容都在bind方法中，所以接下来我们重点分析bind方法，看看netty究竟是怎么启动的。 bind方法所有的重载的bind方法最终都调用了doBind方法： 1234567891011121314151617181920212223242526272829303132333435private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; if (regFuture.isDone()) &#123; // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; // Registration future is almost always fulfilled already, but just in case it&#x27;s not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); &#125; else &#123; // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125;&#125; 这里面干了两件事情： 调用initAndRegister方法创建Channel并注册Nio事件 调用doBind0触发pipeline中的事件链 initAndRegister方法12345678910111213141516171819202122final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; channel = channelFactory.newChannel(); init(channel); &#125; catch (Throwable t) &#123; if (channel != null) &#123; channel.unsafe().closeForcibly(); return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &#125; return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); &#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture;&#125; 这个方法里面主要干了三件事情： 使用channelFactory创建channel 使用init方法初始化channel 最后调用config().group().register(channel)将刚刚创建的channel绑定到一个EventLoop上（就是一个NioEventLoop上） 1. channelFactory创建channel首先弄清楚channelFactory是什么，当我们调用ServerBootstrap的channel方法时： 12b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) 调用的实际上是父类AbstractBootstrap的方法： 123456789101112131415161718public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException(&quot;channelClass&quot;); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));&#125;public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) &#123; if (channelFactory == null) &#123; throw new NullPointerException(&quot;channelFactory&quot;); &#125; if (this.channelFactory != null) &#123; throw new IllegalStateException(&quot;channelFactory set already&quot;); &#125; this.channelFactory = channelFactory; return self();&#125; 调用AbstractBootstrap#channel方法时，创建了一个ReflectiveChannelFactory对象，并最终赋值给了channelFactory。 到这里我们就知道了channelFactory其实是一个ReflectiveChannelFactory实例，那继续看看ReflectiveChannelFactory是什么东西： 12345678910111213141516171819202122232425public class ReflectiveChannelFactory&lt;T extends Channel&gt; implements ChannelFactory&lt;T&gt; &#123; private final Class&lt;? extends T&gt; clazz; public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) &#123; if (clazz == null) &#123; throw new NullPointerException(&quot;clazz&quot;); &#125; this.clazz = clazz; &#125; @Override public T newChannel() &#123; try &#123; return clazz.getConstructor().newInstance(); &#125; catch (Throwable t) &#123; throw new ChannelException(&quot;Unable to create Channel from class &quot; + clazz, t); &#125; &#125; @Override public String toString() &#123; return StringUtil.simpleClassName(clazz) + &quot;.class&quot;; &#125;&#125; ReflectiveChannelFactory其实就是用反射去创建一个新的Channel，也就是我们传入的NioServerSocketChannel，所以看到这里就明白了，initAndRegister方法初始化和注册的是NioServerSocketChannel这个Channel。 看一下NioServerSocketChannel创建的大致过程： 1234public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125; 这里调用了父类的构造函数： 12345678910111213141516171819protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; if (logger.isWarnEnabled()) &#123; logger.warn( &quot;Failed to close a partially initialized socket.&quot;, e2); &#125; &#125; throw new ChannelException(&quot;Failed to enter non-blocking mode.&quot;, e); &#125;&#125; 这里最重要的是，将SelectionKey.OP_ACCEPT赋值给了readInterestOp属性，这个在之后向Selector中注册的时候会用到。 这里分析一下为什么只关心SelectionKey.OP_ACCEPT事件，记得ServerBootstrap传入了两个EventLoopGroup，分别命名为bossGroup和workerGroup，代码如下： 12EventLoopGroup bossGroup = new NioEventLoopGroup(1);EventLoopGroup workerGroup = new NioEventLoopGroup(); bossGroup和workerGroup的职责不同，bossGroup专门负责接收客户端的链接，一旦连接建立，就会把接下来的io读写工作交给workerGroup，这也是为什么bossGroup在new的时候只需要一个线程了。workerGroup才是执行io读写工作的线程，所以命名为工作线程。NioServerSocketChannel是处理客户端连接的Channel，所以它关心的事件只有SelectionKey.OP_ACCEPT。 在AbstractNioChannel的构造函数中还调用了父类AbstractChannel的构造函数，AbstractChannel构造函数干了三件事情： 123id = newId();unsafe = newUnsafe();pipeline = newChannelPipeline(); 比较重要的是创建了unsafe实例和pipeline实例，这里的unsafe不同于sun包中的unsafe，后面会仔细分析，这里只用知道这两个实例被初始化了。pipeline是Netty中另一个核心构建，如果说NioEventLoop是心脏，那pipeline就是血管了。这里创建的pipeline是DefaultChannelPipeline，记住这一点后，后面分析的pipeline的方法实现都在DefaultChannelPipeline中。这里简化了我们的分析，不用去找多个父类和多个实现才知道最终的方法。 当使用channelFactory创建完Channel之后，调用init方法去初始化这个channel。 2. init方法初始化channel1234567891011121314151617181920212223// 剔除掉一些无用的方法@Overridevoid init(Channel channel) throws Exception &#123; ChannelPipeline p = channel.pipeline(); p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;);&#125; 剔除掉一些不管心的方法之后，这里的功能就比较清晰了，首先通过channel.pipeline()方法获取pipeline，这里的pipeline就是上文中创建的DefaultChannelPipeline。 然后pipeline中增加了一个ChannelHandle，ChannelHandle在对应事件触发的时候回调ChannelHandle里面的一些方法，所以这个类里面的方法是异步执行的。 稍微看一下这个ChannelInitializer： 123456789101112131415@Sharablepublic abstract class ChannelInitializer&lt;C extends Channel&gt; extends ChannelInboundHandlerAdapter &#123;PlatformDependent.newConcurrentHashMap(); protected abstract void initChannel(C ch) throws Exception; @Override @SuppressWarnings(&quot;unchecked&quot;) public final void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; if (initChannel(ctx)) &#123; ctx.pipeline().fireChannelRegistered(); &#125; else &#123; ctx.fireChannelRegistered(); &#125; &#125; initChannel方法实际是在channelRegistered被回调的时候调用的，这里mark一下。 在initChannel方法中，最重要的是往自己的事件处理连中添加了一个ServerBootstrapAcceptor。 上文已经分析过了，NioServerSocketChannel的作用其实就是监听并接受客户端的连接请求，连接建立完成之后，就会扔给worker线程。这里的ServerBootstrapAcceptor就是干这个用的，看一下ServerBootstrapAcceptor的代码： 1234567891011121314151617181920212223242526@Override@SuppressWarnings(&quot;unchecked&quot;)public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) &#123; child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); &#125; try &#123; childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125;&#125; 当NioServerSocketChannel监听到SelectionKey.OP_ACCEPT时间后，会触发pipeline中的channelRead事件链，最终会执行ServerBootstrapAcceptor中的channelRead方法。这个方法调用childGroup.register(child)将客户端和服务端建立的连接，也就是这里传进来的msg（一个Channel实例）注册进childGroup。childGroup（一个NioEventLoopGroup实例）会从自己的children（一个NioEventLoop数组）中选出一个NioEventLoop去接纳这个新的Channel。 到这里init方法就执行完了，注意这里的很多动作其实都仅仅注册了一个回调函数，还没有被真正的执行。 接下来看看config().group().register(channel)。 3. config().group().register(channel)config方法返回的是一个ServerBootstrapConfig实例，这部分代码朋友们可以自己跟踪，比较简单。 ServerBootstrapConfig#group方法返回的其实就是ServerBootstrap中的group，这里的group是bossGroup，同样大家跟踪一下这部分代码，不再赘述了。关键我们看group.register(channel)干了什么： 首先，调用NioEventLoopGroup#register方法实际调用了父类MultithreadEventLoopGroup#register方法： 12345// MultithreadEventLoopGroup.java@Overridepublic ChannelFuture register(Channel channel) &#123; return next().register(channel);&#125; 然后先调用了一个next方法，调用的是父类MultithreadEventExecutorGroup#next方法： 1234@Overridepublic EventExecutor next() &#123; return chooser.next();&#125; 这里调用了chooser.next()，看过上篇博客的朋友们肯定有印象，这个chooser其实就是从NioEventLoopGroup的children数组中选出一个NioEventLoop。 回到MultithreadEventLoopGroup#register方法中，这里的next().register(channel)其实调用的是NioEventLoop#register方法： （这里比较绕，多看几遍这部分） 123456789101112// SingleThreadEventLoop.java@Overridepublic ChannelFuture register(Channel channel) &#123; return register(new DefaultChannelPromise(channel, this));&#125;@Overridepublic ChannelFuture register(final ChannelPromise promise) &#123; ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); return promise;&#125; 然后调用的是unsafe的register方法： 这里调用register方法时，将自己传进去了，也就是一个EventLoop，这步的作用其实就是将这个Channel和一个EventLoop绑定起来了，或者说将Channel注册到了EventLoop中： 1234567891011121314151617181920212223242526272829303132333435363738// AbstractChannel.java@Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; throw new NullPointerException(&quot;eventLoop&quot;); &#125; if (isRegistered()) &#123; promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); return; &#125; if (!isCompatible(eventLoop)) &#123; promise.setFailure( new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); return; &#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: &#123;&#125;&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125;&#125; 这里面有一个AbstractChannel.this.eventLoop = eventLoop;，可以印证我们刚刚分析的，这里将传进来的EventLoop赋值到了自己的eventLoop对象上，还记的上面的init方法中，最后有一段代码： 1234567ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125;&#125;); 这里ch.eventLoop()拿到的其实就是刚刚赋值的eventLoop对象。 哎这里是不是很奇怪，ch.eventLoop()这步是在eventLoop对象被赋值之前调用的啊，这时拿到的eventLoop难道不是null嘛？这就是上面反复提到过的，这里的ch.eventLoop()其实并没有执行，只是注册了一个回调函数，当它真正被调用执行的时候，eventLoop已经被赋值了。 继续看AbstractChannel的register方法，这个方法调用了register0： 12345678910111213141516171819202122232425private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; 这段代码干了两件重要的事情： doRegister beginRead 这两个后面分析。这里还做了一件重要的事情，调用了pipeline.fireChannelRegistered();，这里触发了pipeline中的注册事件链，注册事件链比较特殊，上文提到过，ChannelInitializer的initChannel方法实际是由channelRegistered方法触发的。 1.doRegister1234567891011121314151617@Override protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; &#125; catch (CancelledKeyException e) &#123; if (!selected) &#123; eventLoop().selectNow(); selected = true; &#125; else &#123; throw e; &#125; &#125; &#125; &#125; 看到了重要的一个调用： selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);，这里selectionKey是JDK的selectionKey，javaChannel返回的是JDK的Channel，然后将eventLoop中的Selector注册进了这个Channel中，到这里总算是落地到JDK的代码上了，到这里，Nio Server算是真正的启动了。 这里还没完，这里注册的interestOps是0，0不是任何一个Nio事件，所以这里其实是借助register方法初始化selectionKey，并没有开始真正的监听Nio事件。这里将自己作为attachment传进SelectionKey，之后会反过来从SelectionKey中取这个NettyChannel。 2.beginRead刚刚说了，doRegister方法中并没有开启真正的事件监听，那唯一的可能就是在beginRead中开启监听了： 进过一顿寻找，发现最终beginRead调用了这个方法： 123456789101112131415// AbstractNioChannel.java@Overrideprotected void doBeginRead() throws Exception &#123; final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 这里将刚刚创建的selectionKey中的interestOps换成了在AbstractNioChannel构造的时候传进来的interestOps，文章开头看到了，最初传进来的interestOps是SelectionKey.OP_ACCEPT事件，所以最后selectionKey绑定的事件就是SelectionKey.OP_ACCEPT事件。 doBind方法这个方法就很简单了，就是触发了pipeline中的bind事件链，并最终调用JDK绑定到端口，这里最后调用JDK的代码比较难找，最开始我找了好久也没有找到是在哪里调用的，仔细梳理了一遍之后发现，触发pipeline中的bind事件链中，bind事件被定义为出站事件，所以事件会从tail流到head，我们去看那一下DefaultChannelPipeline中的headContext： 1234567891011121314151617181920212223242526272829303132333435final class HeadContext extends AbstractChannelHandlerContext implements ChannelOutboundHandler, ChannelInboundHandler &#123; private final Unsafe unsafe; HeadContext(DefaultChannelPipeline pipeline) &#123; super(pipeline, null, HEAD_NAME, false, true); unsafe = pipeline.channel().unsafe(); setAddComplete(); &#125; @Override public ChannelHandler handler() &#123; return this; &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; // NOOP &#125; @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception &#123; // NOOP &#125; @Override public void bind( ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception &#123; unsafe.bind(localAddress, promise); &#125;// ... 省略&#125; 最终委托给了unsafe#bind方法，后面的代码跟踪就比较简单了。 总结我们看到，在注册这一步的时候，绕了好大一个弯，从NioEventLoopGroup#register到NioEventLoop#register再到Unsafe#register方法。 从NioEventLoopGroup#register到NioEventLoop#register这步，其实是从EventLoopGroup选出一个EventLoop（通过调用next方法），NioEventLoop#register到Unsafe#register这步，其实是将NioEventLoop绑定到Channel，这里Unsafe是Channel的内部类，最终，Unsafe调用了JDK的Nio register方法创建了一个selectionKey。Unsafe最后还点燃了pipeline的register事件链，并最终绑定了SelectionKey.OP_ACCEPT事件。 这里分一下Unsafe这个命名，与JDK打交道的功能封装在Unsafe中，它是连接Netty Nio与JDK Nio的桥梁，那为什么要命名为Unsafe呢？这里就很有趣了： 我们熟悉Sun提供的Unsafe工具，这个工具可以与一些底层直接进行交互，比如CAS，比如堆外内存的使用，这里命名为Unsafe的意思是说，这些东西都不属于JVM管理的，请知晓，JVM是不保证这些操作的安全性的！ 在Netty中就很有意思了，Netty是在说谁Unsafe呢？其实说的是JDK，Netty说JDK是Unsafe的，因为对于Netty来说，JDK中的代码是不受自己控制的，调用JDK出了问题Netty是无能为力的，Netty同样不能保证JDK的安全！所以与JDK打交道的代码被称为Unsafe。 这样的话，在以后自己写框架的过程中，如果需要对其他的依赖的框架做一些封装，那这个封装的类也可以被命名为Unsafe，告诉别人，这个类里面的功能都是别人的！我不能保证安全性！我只是提供一层封装！（虽然我自己可能不会这么去做^_^）。","categories":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/tags/Netty/"}]},{"title":"Netty源码-2-NioEventLoop","slug":"netty-2","date":"2019-09-19T01:12:28.000Z","updated":"2021-06-25T13:47:33.049Z","comments":true,"path":"articles/Netty/netty-2/","link":"","permalink":"https://www.jelliclecat.cn/articles/Netty/netty-2/","excerpt":"","text":"长文预警！！！ 一、NioEventLoop概要NioEventLoop就是上文中NioEventLoopGroup的children，可以先通过名字分析一下这个类的作用，这个类名有三个单词：Nio、Event、Loop。 通过Loop可以猜测，这个类里面有一个死循环，死循环的逻辑一般都会扔给一个单独的线程，所以可以猜测NioEventLoop中会管理一个线程或者线程池，这个线程中用来执行死循环逻辑，既然涉及到线程或者线程池，那么还要有管理线程生命周期的方法。如果是线程池，那就会有线程池相关的一些逻辑，比如线程池的拒绝策略等等。 通过Event可以猜测到，死循环执行的逻辑是在监听某一个或一类事件，监听过程一定是阻塞的。 通过Nio可以知道，上面提到的Event是Nio中的事件，而且是SocketNio的事件，SocketNio的事件定义在SelectionKey中，有四种事件，读事件，写事件，客户端的连接事件，服务端的接收事件。 1234public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4; 通过上面的猜测总结一下NioEventLoop的功能：开启一个线程循环监听Socket Nio中的事件。 接下来看下源码： 接着上文，创建NioEventLoop的入口在NioEventLoopGroup中，上文讲了NioEventLoopGroup构造时，会根据nThread参数创建相应大小的children数组，children数组实际上就是NioEventLoop数组，MultithreadEventExecutorGroup中的newChild方法是一个模板方法，实现在NioEventLoopGroup中： 12345@Override protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); &#125; 可以看到就是new了一个NioEventLoop，这里注意一下传入的参数： executor SelectorProvider SelectStrategyFactory （先不管） RejectedExecutionHandler 这里印证了一些上文的猜测，我们挨个看一下这几个参数（其实这里面的参数都在上文中提到过）： 1. executor上文中讲过了executor的创建，这里复习一下，executor是一个netty中自己定义的线程池：ThreadPerTaskExecutor，从名字就能看出，这个线程池为每一个新的任务都创建一个新的线程去执行，这个线程池最主要的作用是，从这个线程池中创建出来的每一个线程都是Netty自定义的线程：FastThreadLocalThread，这个线程池中使用的是FastThreadLocal而不是jdk原生的ThreadLocal，FastThreadLocal比ThreadLocal更快，因为FastThreadLocal没有算hash，并解决了伪共享的问题。 这里创建FastThreadLocal并不是ThreadPerTaskExecutor本身的功能，而是因为MultithreadEventExecutorGroup创建ThreadPerTaskExecutor时传入的是DefaultThreadFactory，真正负责创建FastThreadLocal的类实际是DefaultThreadFactory。 2. SelectorProvider这是Java中的原生类，用来获取一个Selector。 3. RejectedExecutionHandler对应的executor的拒绝策略。 二、构造NioEventLoop看了构造函数的参数之后，再看一下构造的过程。 12345678910111213141516NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) &#123; throw new NullPointerException(&quot;selectorProvider&quot;); &#125; if (strategy == null) &#123; throw new NullPointerException(&quot;selectStrategy&quot;); &#125; provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy;&#125; 首先调用了父类的构造函数，看一下SingleThreadEventExecutor这个父类的构造函数： 12345678910protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ObjectUtil.checkNotNull(executor, &quot;executor&quot;); taskQueue = newTaskQueue(this.maxPendingTasks); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;);&#125; 上文中提到的几个参数，在这里都有体现了，父类构造也比较简单，只是进行了简单的赋值。 继续看NioEventLoop的构造函数，构造函数中，除了一些赋值之外，执行了一个重要的方法：openSelector()，这个方法用来获取Selector： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394private SelectorTuple openSelector() &#123; final Selector unwrappedSelector; try &#123; unwrappedSelector = provider.openSelector(); &#125; catch (IOException e) &#123; throw new ChannelException(&quot;failed to open a new selector&quot;, e); &#125; if (DISABLE_KEYSET_OPTIMIZATION) &#123; return new SelectorTuple(unwrappedSelector); &#125; Object maybeSelectorImplClass = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; try &#123; return Class.forName( &quot;sun.nio.ch.SelectorImpl&quot;, false, PlatformDependent.getSystemClassLoader()); &#125; catch (Throwable cause) &#123; return cause; &#125; &#125; &#125;); if (!(maybeSelectorImplClass instanceof Class) || // ensure the current selector implementation is what we can instrument. !((Class&lt;?&gt;) maybeSelectorImplClass).isAssignableFrom(unwrappedSelector.getClass())) &#123; if (maybeSelectorImplClass instanceof Throwable) &#123; Throwable t = (Throwable) maybeSelectorImplClass; logger.trace(&quot;failed to instrument a special java.util.Set into: &#123;&#125;&quot;, unwrappedSelector, t); &#125; return new SelectorTuple(unwrappedSelector); &#125; final Class&lt;?&gt; selectorImplClass = (Class&lt;?&gt;) maybeSelectorImplClass; final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); Object maybeException = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; try &#123; Field selectedKeysField = selectorImplClass.getDeclaredField(&quot;selectedKeys&quot;); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(&quot;publicSelectedKeys&quot;); if (PlatformDependent.javaVersion() &gt;= 9 &amp;&amp; PlatformDependent.hasUnsafe()) &#123; // Let us try to use sun.misc.Unsafe to replace the SelectionKeySet. // This allows us to also do this in Java9+ without any extra flags. long selectedKeysFieldOffset = PlatformDependent.objectFieldOffset(selectedKeysField); long publicSelectedKeysFieldOffset = PlatformDependent.objectFieldOffset(publicSelectedKeysField); if (selectedKeysFieldOffset != -1 &amp;&amp; publicSelectedKeysFieldOffset != -1) &#123; PlatformDependent.putObject( unwrappedSelector, selectedKeysFieldOffset, selectedKeySet); PlatformDependent.putObject( unwrappedSelector, publicSelectedKeysFieldOffset, selectedKeySet); return null; &#125; // We could not retrieve the offset, lets try reflection as last-resort. &#125; Throwable cause = ReflectionUtil.trySetAccessible(selectedKeysField, true); if (cause != null) &#123; return cause; &#125; cause = ReflectionUtil.trySetAccessible(publicSelectedKeysField, true); if (cause != null) &#123; return cause; &#125; selectedKeysField.set(unwrappedSelector, selectedKeySet); publicSelectedKeysField.set(unwrappedSelector, selectedKeySet); return null; &#125; catch (NoSuchFieldException e) &#123; return e; &#125; catch (IllegalAccessException e) &#123; return e; &#125; &#125; &#125;); if (maybeException instanceof Exception) &#123; selectedKeys = null; Exception e = (Exception) maybeException; logger.trace(&quot;failed to instrument a special java.util.Set into: &#123;&#125;&quot;, unwrappedSelector, e); return new SelectorTuple(unwrappedSelector); &#125; selectedKeys = selectedKeySet; logger.trace(&quot;instrumented a special java.util.Set into: &#123;&#125;&quot;, unwrappedSelector); return new SelectorTuple(unwrappedSelector, new SelectedSelectionKeySetSelector(unwrappedSelector, selectedKeySet)); &#125; 这个方法有看起来非常复杂，但其实有一个开关：DISABLE_KEYSET_OPTIMIZATION： 12private static final boolean DISABLE_KEYSET_OPTIMIZATION = SystemPropertyUtil.getBoolean(&quot;io.netty.noKeySetOptimization&quot;, false); 默认是false。 先看如果是true怎么办，如果是true，那么直接返回了SelectorProvider的openSelector方法返回的Selector，这里简单包装了一下，SelectorTuple，但是其实什么也没干，然后这个方法就直接返回了。 这里有两个问题：SelectorProvider的openSelector获得的是什么Selector？如果DISABLE_KEYSET_OPTIMIZATION是false怎么办？咱们一个一个看： 1. SelectorProvider的openSelector方法这里的SelectorProvider是使用SelectorProvider.provider()方法获取的SelectorProvider是sun.nio.ch.DefaultSelectorProvider.create()返回的SelectorProvider： 1234567891011121314151617public static SelectorProvider provider() &#123; synchronized (lock) &#123; if (provider != null) return provider; return AccessController.doPrivileged( new PrivilegedAction&lt;SelectorProvider&gt;() &#123; public SelectorProvider run() &#123; if (loadProviderFromProperty()) return provider; if (loadProviderAsService()) return provider; provider = sun.nio.ch.DefaultSelectorProvider.create(); return provider; &#125; &#125;); &#125;&#125; 而sun.nio.ch.DefaultSelectorProvider.create()返回的是KQueueSelectorProvider。所以SelectorProvider的openSelector方法实际是调用的KQueueSelectorProvider的openSelector方法： 12345678public class DefaultSelectorProvider &#123; private DefaultSelectorProvider() &#123; &#125; public static SelectorProvider create() &#123; return new KQueueSelectorProvider(); &#125;&#125; 这里可以体现出JDK的跨平台特性了，我使用的是iOS系统，所以返回的是KQueue，可以猜想，如果使用的是Linux系统，那这里返回的应该是Epoll，因为iOS和Linux的epoll系统调用不一样。 那第一个问题解决了，最终创建的Selector是KQueueSelectorImpl，使用了k-queue系统调用。 2. DISABLE_KEYSET_OPTIMIZATION为false传统，先看名字：DISABLE_KEYSET_OPTIMIZATION，禁用KeySet优化，默认是false，即默认是启用KeySet优化。 当DISABLE_KEYSET_OPTIMIZATION == true的时候，直接返回了KQueueSelectorImpl。 如果是false的时候，逻辑就稍微比较复杂一些，首先通过反射找到了sun.nio.ch.SelectorImpl这个类，这个类是KQueueSelectorImpl的父类： 12345678910111213141516171819public abstract class SelectorImpl extends AbstractSelector &#123; protected Set&lt;SelectionKey&gt; selectedKeys = new HashSet(); protected HashSet&lt;SelectionKey&gt; keys = new HashSet(); private Set&lt;SelectionKey&gt; publicKeys; private Set&lt;SelectionKey&gt; publicSelectedKeys; protected SelectorImpl(SelectorProvider var1) &#123; super(var1); if (Util.atBugLevel(&quot;1.4&quot;)) &#123; this.publicKeys = this.keys; this.publicSelectedKeys = this.selectedKeys; &#125; else &#123; this.publicKeys = Collections.unmodifiableSet(this.keys); this.publicSelectedKeys = Util.ungrowableSet(this.selectedKeys); &#125; &#125; // ... 略&#125; 继续看下面的逻辑： 123456789101112131415161718Object maybeException = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; try &#123; Field selectedKeysField = selectorImplClass.getDeclaredField(&quot;selectedKeys&quot;); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(&quot;publicSelectedKeys&quot;); // ... 省略 selectedKeysField.set(unwrappedSelector, selectedKeySet); publicSelectedKeysField.set(unwrappedSelector, selectedKeySet); return null; &#125; catch (NoSuchFieldException e) &#123; return e; &#125; catch (IllegalAccessException e) &#123; return e; &#125; &#125;&#125;); 可以看到，通过反射拿到了SelectorImpl的selectedKeys和publicSelectedKeys这两个Field，然后调用了set方法，替换掉了这两个Field的值。 用什么替换掉的呢？SelectedSelectionKeySet，为什么要用这个替换呢，替换掉的是什么呢？ 看看SelectorImpl的构造函数，构造selectedKeys和publicSelectedKeys使用的是HashSet，所以实际上使用SelectedSelectionKeySet替换掉了HashSet。 看看SelectedSelectionKeySet： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778final class SelectedSelectionKeySet extends AbstractSet&lt;SelectionKey&gt; &#123; SelectionKey[] keys; int size; SelectedSelectionKeySet() &#123; keys = new SelectionKey[1024]; &#125; @Override public boolean add(SelectionKey o) &#123; if (o == null) &#123; return false; &#125; keys[size++] = o; if (size == keys.length) &#123; increaseCapacity(); &#125; return true; &#125; @Override public boolean remove(Object o) &#123; return false; &#125; @Override public boolean contains(Object o) &#123; return false; &#125; @Override public int size() &#123; return size; &#125; @Override public Iterator&lt;SelectionKey&gt; iterator() &#123; return new Iterator&lt;SelectionKey&gt;() &#123; private int idx; @Override public boolean hasNext() &#123; return idx &lt; size; &#125; @Override public SelectionKey next() &#123; if (!hasNext()) &#123; throw new NoSuchElementException(); &#125; return keys[idx++]; &#125; @Override public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; void reset() &#123; reset(0); &#125; void reset(int start) &#123; Arrays.fill(keys, start, size, null); size = 0; &#125; private void increaseCapacity() &#123; SelectionKey[] newKeys = new SelectionKey[keys.length &lt;&lt; 1]; System.arraycopy(keys, 0, newKeys, 0, size); keys = newKeys; &#125;&#125; HashSet本身是基于HashMap实现的，而HashMap的插入会有很复杂的操作，链表、扩容、rehash、链表转红黑树等等操作，而这里这里并不需要这么复杂的操作，所以Netty直接用了一个数组代替，数组的顺序插入比HashMap的插入要高效得多。 所以简而言之，这里不需要使用HashSet，Netty认为SelectorImpl的实现不够高效，所以使用反射，将SelectorImpl中的selectedKeys和publicSelectedKeys替换为自己用数组实现的性能更好的SelectedSelectionKeySet。 到这里就能完全看出DISABLE_KEYSET_OPTIMIZATION的意思了，是否开启KeySet优化。 【BTW】，这种使用数组替换hash的方法在Netty中其实并不陌生，FastThreadLocal就是用数组的顺序添加替代JDK原生ThreadLocal中的hash。 总结：这里没有Thread的启动逻辑诶，不是说NioEventLoop会管理自己的Thread，为什么没有在构造函数里面体现呢？这里可以这么认为，NioEventLoop的构造函数属于NioEventLoop的生命周期，而内部Thread的生命周期需要单独管理。换个角度思考，这里也可以说这是一种懒加载，只有在真正需要启动Thread的时候，再去启动，毕竟Thread是比较昂贵的系统资源。 三、内部Thread的启动那内部的Thread是怎么启动的呢？ 在构造函数中，我们看到executor被SingleThreadEventExecutor持有，我很好奇这个executor会怎么用呢？通过查找executor，找到了一个doStartThread方法： 12345678910111213141516171819202122private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; boolean success = false; updateLastExecutionTime(); try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; finally &#123; // ... 省略 更新状态位等收尾工作。 &#125; &#125; &#125;); &#125; thread是SingleThreadEventExecutor持有的一个Thread引用。 这里调用了executor.execute方法，这里面的方法贼好玩，我们知道这个executor是ThreadPerTaskExecutor，看一下ThreadPerTaskExecutor的execute方法： 1234@Overridepublic void execute(Runnable command) &#123; threadFactory.newThread(command).start();&#125; 这里从threadFactory创建了一个新的线程（threadFactory是DefaultThreadFactory，创建的是FastThreadLocalThread，后面不再赘述了，已经讲了很多遍了），然后doStartThread调用executor.execute方法中，进行了一步赋值：thread = Thread.currentThread()。 这个就很有味道了，首先Thread.currentThread()是什么，就是ThreadPerTaskExecutor刚刚创建出来的新线程，然后把这个新线程给了SingleThreadEventExecutor持有的Thread引用。 这样，SingleThreadEventExecutor持有的Thread引用其实是由DefaultThreadFactory创建出来的。 在给thread赋值之后，后面接着调用了SingleThreadEventExecutor.this.run()，即自己的run方法，待会着重看一下run方法。 最后做了一些收尾工作。所以我们能看到，前面说了这么久的内部线程，最后是在这里创建并启动的。 那么，doStartThread是什么时候调用的呢？直接查找可以看到startThread方法调用了doStartThread，而SingleThreadEventExecutor的execute方法调用了startThread方法： 12345678910111213141516171819@Overridepublic void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; boolean inEventLoop = inEventLoop(); addTask(task); if (!inEventLoop) &#123; startThread(); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125;&#125; inEventLoop判断当前的线程是否是自己持有的thread，判断的方法是”==”，这样如果thread是null的话，就调用startThread创建线程。 到这里，我们就知道了NioEventLoop是如何创建并启动持有的thread了。 有朋友可能要问，哎，这个thread没有start啊，其实我们回头看ThreadPerTaskExecutor就知道了： 1234@Overridepublic void execute(Runnable command) &#123; threadFactory.newThread(command).start();&#125; 这里调用了start，所以在Runnable内部通过Thread.currentThread()拿到的thread其实就已经启动了。这段代码真的玩的很花。 四、NioEventLoop中的run方法通过SingleThreadEventExecutor.this.run();调用的实际上是NioEventLoop中的run方法，这个方法是NioEventLoop的核心方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@Overrideprotected void run() &#123; for (;;) &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.BUSY_WAIT: // fall-through to SELECT since the busy-wait is not supported with NIO case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); // &#x27;wakenUp.compareAndSet(false, true)&#x27; is always evaluated // before calling &#x27;selector.wakeup()&#x27; to reduce the wake-up // overhead. (Selector.wakeup() is an expensive operation.) // // However, there is a race condition in this approach. // The race condition is triggered when &#x27;wakenUp&#x27; is set to // true too early. // // &#x27;wakenUp&#x27; is set to true too early if: // 1) Selector is waken up between &#x27;wakenUp.set(false)&#x27; and // &#x27;selector.select(...)&#x27;. (BAD) // 2) Selector is waken up between &#x27;selector.select(...)&#x27; and // &#x27;if (wakenUp.get()) &#123; ... &#125;&#x27;. (OK) // // In the first case, &#x27;wakenUp&#x27; is set to true and the // following &#x27;selector.select(...)&#x27; will wake up immediately. // Until &#x27;wakenUp&#x27; is set to false again in the next round, // &#x27;wakenUp.compareAndSet(false, true)&#x27; will fail, and therefore // any attempt to wake up the Selector will fail, too, causing // the following &#x27;selector.select(...)&#x27; call to block // unnecessarily. // // To fix this problem, we wake up the selector again if wakenUp // is true immediately after selector.select(...). // It is inefficient in that it wakes up the selector for both // the first case (BAD - wake-up required) and the second case // (OK - no wake-up required). if (wakenUp.get()) &#123; selector.wakeup(); &#125; // fall through default: &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; // Always handle shutdown even if the loop processing threw an exception. try &#123; if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; return; &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; &#125;&#125; 先要介绍一下：ioRatio，NioEventLoop并不是所有的时间都在做nio相关的事情，还有提交到NioEventLoop中执行的普通任务，提交的入口就在SingleThreadEventExecutor#execute方法中，当调用这个方法之后，会将task加入到内部的一个队列中，这部分逻辑和JDK中的线程池很像，不再赘述了。 看一下addTask： 12345678protected void addTask(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; if (!offerTask(task)) &#123; reject(task); &#125;&#125; 细看一下究竟，首先offerTask： 123456final boolean offerTask(Runnable task) &#123; if (isShutdown()) &#123; reject(); &#125; return taskQueue.offer(task);&#125; taskQueue是什么呢？是SingleThreadEventExecutor构造的时候创建的，回头看一下这部分代码： 12345678910protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ObjectUtil.checkNotNull(executor, &quot;executor&quot;); taskQueue = newTaskQueue(this.maxPendingTasks); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;);&#125; 这里调用了newTaskQueue方法： 123protected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) &#123; return new LinkedBlockingQueue&lt;Runnable&gt;(maxPendingTasks);&#125; 这里创建了一个LinkedBlockingQueue，到这里taskQueue是什么算是明白了，再看看reject方法： 有两个reject方法： reject() reject(Runnable task) 1234567protected static void reject() &#123; throw new RejectedExecutionException(&quot;event executor terminated&quot;);&#125;protected final void reject(Runnable task) &#123; rejectedExecutionHandler.rejected(task, this);&#125; 这里调用了rejectedExecutionHandler，这个rejectedExecutionHandler不知道还记不记得，在创建NioEventLoopGroup的时候就传入了这个参数： 123456private static final RejectedExecutionHandler REJECT = new RejectedExecutionHandler() &#123; @Override public void rejected(Runnable task, SingleThreadEventExecutor executor) &#123; throw new RejectedExecutionException(); &#125;&#125;; 这里面不管是哪个reject方法，最终都是抛出了一个RejectedExecutionException异常。 到这里，addTask方法内的逻辑就看清楚了。 知道这这些，再看一下ioRatio这个参数，这个参数代表单位时间内处理nio和普通task的时间分配比率，默认是50，即用在两边的时间一样。 再仔细看看run方法内的逻辑： 1234567891011switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.BUSY_WAIT: case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; default:&#125; calculateStrategy方法是什么呢： 12345678910final class DefaultSelectStrategy implements SelectStrategy &#123; static final SelectStrategy INSTANCE = new DefaultSelectStrategy(); private DefaultSelectStrategy() &#123; &#125; @Override public int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception &#123; return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT; &#125;&#125; hasTasks()方法返回taskQueue中是否有任务，如果没有任务的话，返回SelectStrategy.SELECT，那样就就会调用select(wakenUp.getAndSet(false))方法，如果任务不为空，则调用selectSupplier.get()，selectSupplier在NioEventLoop中定义： 1234567891011121314151617private final IntSupplier selectNowSupplier = new IntSupplier() &#123; @Override public int get() throws Exception &#123; return selectNow(); &#125; &#125;; int selectNow() throws IOException &#123; try &#123; return selector.selectNow(); &#125; finally &#123; // restore wakeup state if needed if (wakenUp.get()) &#123; selector.wakeup(); &#125; &#125; &#125; get方法调用了selectNow()方法，这个方法也很简单，调用了jdk selector的selectNow方法，这个selector是在NioEventLoop构造的时候创建的。selectNow返回的值是大于等于0的，所以会跳过switch中的所有逻辑。 switch内的逻辑总结一下，如果有task，则调用selectNow并跳出switch，如果没有task，则调用select(wakenUp.getAndSet(false))。 这两条路都看一下。 1. select(wakenUp.getAndSet(false))先说一下这个方法干了啥，这个方法其实就是NioEventLoop没事情做了，现在只能跑过来等Nio事件，并且一边等Nio事件一边还要检查taskQueue中有没有任务到来： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; selector.selectNow(); selectCnt = 1; break; &#125; int selectedKeys = selector.select(timeoutMillis); selectCnt ++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; break; &#125; if (Thread.interrupted()) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Selector.select() returned prematurely because &quot; + &quot;Thread.currentThread().interrupt() was called. Use &quot; + &quot;NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.&quot;); &#125; selectCnt = 1; break; &#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; logger.warn( &quot;Selector.select() returned prematurely &#123;&#125; times in a row; rebuilding Selector &#123;&#125;.&quot;, selectCnt, selector); rebuildSelector(); selector = this.selector; selector.selectNow(); selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Selector.select() returned prematurely &#123;&#125; times in a row for Selector &#123;&#125;.&quot;, selectCnt - 1, selector); &#125; &#125; &#125; catch (CancelledKeyException e) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(CancelledKeyException.class.getSimpleName() + &quot; raised by a Selector &#123;&#125; - JDK bug?&quot;, selector, e); &#125; &#125;&#125; 首先算出一个selectDeadLineNanos，是由下一个定时任务的开始时间算出来的。看一下循环方法内部： 首先看一下下一个定时任务是否会在500微秒内开始，如果在接下来500微秒开始则退出循环。如果hasTask，则退出循环。然后调用selector.select(timeoutMillis);，这里会阻塞线程，除非有一个以上的Channel被唤醒或者时间到了，才会唤醒线程，唤醒之后又会检查hasTask和是否有Channel被唤醒（selectedKeys是否&gt;0）等检查条件。 在下面这里解决了一个bug，那就是JDK本身select被无限唤醒导致CPU空转的bug，原理是，一旦bug触发，由于selector.select这步会被一直唤醒而不会阻塞，所以selectCnt会增加的很快，并且消耗的时间将会非常的短，当在非常短的时间内，selectCnt增加到512之后，就会任务bug被触发了，因为selector.select的阻塞失效了。这时候会调用rebuildSelector()。 rebuildSelector比较简单，就是重新创建一个Selector，然后把旧的Selector中注册过的Channel重新注册到新的Selector中，然后替换掉旧的Selector就可以了，最后调用close关闭掉旧的Selector。 2. 当switch跳出后，就会根据ioRatio将时间分比率分配到Nio事件和Task上跳出上面的select循环后，有两个重要的函数：processSelectedKeys()，runAllTasks()。分别对应nio事件处理和task任务。 processSelectedKeys：首先在processSelectedKeysPlain中循环遍历了所有的SelectionKey： 123456789101112131415161718192021222324252627282930313233343536373839private void processSelectedKeysPlain(Set&lt;SelectionKey&gt; selectedKeys) &#123; // check if the set is empty and if so just return to not create garbage by // creating a new Iterator every time even if there is nothing to process. // See https://github.com/netty/netty/issues/597 if (selectedKeys.isEmpty()) &#123; return; &#125; Iterator&lt;SelectionKey&gt; i = selectedKeys.iterator(); for (;;) &#123; final SelectionKey k = i.next(); final Object a = k.attachment(); i.remove(); if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; if (!i.hasNext()) &#123; break; &#125; if (needsToSelectAgain) &#123; selectAgain(); selectedKeys = selector.selectedKeys(); // Create the iterator again to avoid ConcurrentModificationException if (selectedKeys.isEmpty()) &#123; break; &#125; else &#123; i = selectedKeys.iterator(); &#125; &#125; &#125; &#125; 然后对于每个SelectionKey调用processSelectedKey去处理： 1234567891011121314151617181920212223242526272829303132333435private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) &#123; final EventLoop eventLoop; try &#123; eventLoop = ch.eventLoop(); &#125; catch (Throwable ignored) &#123; return; &#125; if (eventLoop != this || eventLoop == null) &#123; return; &#125; unsafe.close(unsafe.voidPromise()); return; &#125; try &#123; int readyOps = k.readyOps(); if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); &#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125; &#125; 这里，就是处理NioEvent的核心内容了，对于每个SelectionKey，都看一下有没有就绪的事件。 对于就绪的事件，会调用unsafe相应的方法，这里面会触发Netty中Pipeline中的事件链，去调用各个Handler中的处理逻辑。这部分之后会讲。 到这里就知道了，Netty的事件入口了，可以说，这里是Netty的引擎，是驱动Netty工作的核心逻辑！ runAllTasks这个没什么好说的了，挨个执行taskQueue中的任务，留意一下分配的处理时间就完事了。 五、总结NioEventLoop可以说是Netty的心脏，他驱动了各种Nio事件，并处理各种提交过来的任务。 我们一段一段的分析了NioEventLoop中的核心方法，看看它到底是如何运作的，是如何创建自己以及如何创建内部的Thread的，也看到了NioEventLoop是如何消除JDK中的bug的。 NioEventLoop的触发方式还是水平触发，和JDK是一样的。 还有一个比较重要的方法没有分析，那就是shutdownGracefully方法，里面封装了Netty著名的优雅关机逻辑，回头我们看一下这个方法。 这里只讲了事件是如何触发的，之后我们会看到事件是如何在Pipeline中的各个Handler中流动的。 希望你喜欢这篇文章~","categories":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/tags/Netty/"}]},{"title":"Netty源码-1-NioEventLoopGroup","slug":"netty-1","date":"2019-09-18T14:05:51.000Z","updated":"2021-06-25T13:47:33.057Z","comments":true,"path":"articles/Netty/netty-1/","link":"","permalink":"https://www.jelliclecat.cn/articles/Netty/netty-1/","excerpt":"","text":"建议大家手头都有一份netty的源码对照阅读。 从EchoServer入手 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public final class EchoServer &#123; static final boolean SSL = System.getProperty(&quot;ssl&quot;) != null; static final int PORT = Integer.parseInt(System.getProperty(&quot;port&quot;, &quot;8007&quot;)); public static void main(String[] args) throws Exception &#123; // Configure SSL. final SslContext sslCtx; if (SSL) &#123; SelfSignedCertificate ssc = new SelfSignedCertificate(); sslCtx = SslContextBuilder.forServer(ssc.certificate(), ssc.privateKey()).build(); &#125; else &#123; sslCtx = null; &#125; // Configure the server. EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); final EchoServerHandler serverHandler = new EchoServerHandler(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); if (sslCtx != null) &#123; p.addLast(sslCtx.newHandler(ch.alloc())); &#125; //p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(serverHandler); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); &#125; finally &#123; // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; SSL的部分先不管，先看看netty的服务启动过程，主要有两个重要的点： 创建NioEventLoopGroup，服务端有两个，bossGroup和workerGroup ServerBootstrap绑定端口。 在创建NioEventLoopGroup的过程中，会创建NioEventLoop，这部分比较复杂需要单独写成一篇，然后创建NioEventLoopGroup的过程和创建ServerBootstrap的过程各写成一篇博客，一共用三篇博客来看netty的启动过程。 创建NioEventLoopGroup看看创建NioEventLoopGroup的过程： 12345678910111213141516171819202122// NioEventLoopGroup.javapublic NioEventLoopGroup() &#123; this(0);&#125;public NioEventLoopGroup(int nThreads) &#123; this(nThreads, (Executor) null);&#125;public NioEventLoopGroup(int nThreads, Executor executor) &#123; this(nThreads, executor, SelectorProvider.provider());&#125;public NioEventLoopGroup( int nThreads, Executor executor, final SelectorProvider selectorProvider) &#123; this(nThreads, executor, selectorProvider, DefaultSelectStrategyFactory.INSTANCE);&#125;public NioEventLoopGroup(int nThreads, Executor executor, final SelectorProvider selectorProvider, final SelectStrategyFactory selectStrategyFactory) &#123; super(nThreads, executor, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject());&#125; 可以看到如果我们没有传入线程数的话，nThreads默认为零，之后可以看到如果nThreads为零的话，会使用availableProcessors() * 2代替，即可用线程数的两倍。 三个默认参数：在构造方法的传递过程中，传入了几个默认参数： SelectorProvider.provider() DefaultSelectStrategyFactory.INSTANCE RejectedExecutionHandlers.reject() 稍微点进去看一下这几个类是干什么的： SelectorProvider负责打开一个Selector，这是java nio中的原生Selector。 DefaultSelectStrategyFactory.INSTANCE是一个SelectStrategy的工厂实例，返回的是DefaultSelectStrategy.INSTANCE，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public final class DefaultSelectStrategyFactory implements SelectStrategyFactory &#123; public static final SelectStrategyFactory INSTANCE = new DefaultSelectStrategyFactory(); private DefaultSelectStrategyFactory() &#123; &#125; @Override public SelectStrategy newSelectStrategy() &#123; return DefaultSelectStrategy.INSTANCE; &#125;&#125;final class DefaultSelectStrategy implements SelectStrategy &#123; static final SelectStrategy INSTANCE = new DefaultSelectStrategy(); private DefaultSelectStrategy() &#123; &#125; @Override public int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception &#123; return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT; &#125;&#125;public interface SelectStrategy &#123; /** * Indicates a blocking select should follow. */ int SELECT = -1; /** * Indicates the IO loop should be retried, no blocking select to follow directly. */ int CONTINUE = -2; /** * Indicates the IO loop to poll for new events without blocking. */ int BUSY_WAIT = -3; /** * The &#123;@link SelectStrategy&#125; can be used to steer the outcome of a potential select * call. * * @param selectSupplier The supplier with the result of a select result. * @param hasTasks true if tasks are waiting to be processed. * @return &#123;@link #SELECT&#125; if the next step should be blocking select &#123;@link #CONTINUE&#125; if * the next step should be to not select but rather jump back to the IO loop and try * again. Any value &gt;= 0 is treated as an indicator that work needs to be done. */ int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception;&#125; 这个类具体干嘛用的之后会看到，现在不用纠结。 RejectedExecutionHandlers.reject()返回的也是一个单例的RejectedExecutionHandler()，这个类是一个拒绝策略，熟悉线程池的同学都知道。这个类简单的抛出一个异常RejectedExecutionException。 最后，NioEventLoopGroup中的构造函数调用了父类MultithreadEventLoopGroup的构造函数： 1234// MultithreadEventLoopGroup.javaprotected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) &#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args);&#125; 这里可以看到，如果nThreads为0的话，使用DEFAULT_EVENT_LOOP_THREADS代替，也就是availableProcessors() * 2。这里又调用了父类MultithreadEventExecutorGroup的构造函数： 1234// MultithreadEventExecutorGroup.javaprotected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object... args) &#123; this(nThreads, executor, DefaultEventExecutorChooserFactory.INSTANCE, args);&#125; 真正的构造函数：最终委托给了真正的构造函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; if (nThreads &lt;= 0) &#123; throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); &#125; if (executor == null) &#123; executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); &#125; children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; children[i] = newChild(executor, args); success = true; &#125; catch (Exception e) &#123; // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); &#125; finally &#123; if (!success) &#123; for (int j = 0; j &lt; i; j ++) &#123; children[j].shutdownGracefully(); &#125; for (int j = 0; j &lt; i; j ++) &#123; EventExecutor e = children[j]; try &#123; while (!e.isTerminated()) &#123; e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); &#125; &#125; catch (InterruptedException interrupted) &#123; // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; &#125; &#125; &#125; &#125; &#125; chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() &#123; @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception &#123; if (terminatedChildren.incrementAndGet() == children.length) &#123; terminationFuture.setSuccess(null); &#125; &#125; &#125;; for (EventExecutor e: children) &#123; e.terminationFuture().addListener(terminationListener); &#125; Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet);&#125; MultithreadEventExecutorGroup持有一个EventExecutor[] children，是真正执行任务的线程，ExecutorGroup可以看做一个线程容器，负责管理持有的EventExecutor。这里可以对照java原生的线程池，EventExecutorGroup可以看做ExecutorService，EventExecutor可以看做线程池中的Thread，不过是升级版的。 这个构造函数主要干了三件事情： 1. 创建executor看这个构造函数，如果executor是null（这个例子中就是null，可以回顾一下之前的构造函数，第二个构造函数就传入了一个null的executor），就new了一个ThreadPerTaskExecutor，这个ThreadPerTaskExecutor对于每个提交的任务（顾名思义，Thread Per Task），都使用ThreadFactory创建一个新的Thread去 执行这个任务。关键是ThreadFactory，是使用newDefaultThreadFactory()获得的，newDefaultThreadFactory方法创建了一个DefaultThreadFactory，DefaultThreadFactory除了定制了Thread的名字之类的属性外，最重要的是他返回的是FastThreadLocalThread类型的Thread，FastThreadLocalThread里面使用的ThreadLocal是FastThreadLocal，并将任务Runnable包装成一个新的Runable：FastThreadLocalRunnable.wrap(r)。 所以这个executor的逻辑是对于每个新的任务，都创建一个FastThreadLocalThread类型的线程去执行这个任务。 netty中所有的线程都是使用FastThreadLocalThread+FastThreadLocal这样的搭配，原因是FastThreadLocal比java原生的ThreadLocal要快，并且杜绝了原生ThreadLocal潜在的内存泄漏，这部分代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475 // MultithreadEventExecutorGroup的构造函数 if (executor == null) &#123; executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); &#125; protected ThreadFactory newDefaultThreadFactory() &#123; return new DefaultThreadFactory(getClass()); &#125;// netty的默认ThreadFactory，创建出来的Thread是FastThreadLocalThreadpublic class DefaultThreadFactory implements ThreadFactory &#123; // ... 省略 @Override public Thread newThread(Runnable r) &#123; Thread t = newThread(FastThreadLocalRunnable.wrap(r), prefix + nextId.incrementAndGet()); try &#123; if (t.isDaemon() != daemon) &#123; t.setDaemon(daemon); &#125; if (t.getPriority() != priority) &#123; t.setPriority(priority); &#125; &#125; catch (Exception ignored) &#123; // Doesn&#x27;t matter even if failed to set. &#125; return t; &#125; protected Thread newThread(Runnable r, String name) &#123; return new FastThreadLocalThread(threadGroup, r, name); &#125;&#125;// 一个简单的Executor，对于每个新的任务都创建一个新的线程去执行任务public final class ThreadPerTaskExecutor implements Executor &#123; private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) &#123; if (threadFactory == null) &#123; throw new NullPointerException(&quot;threadFactory&quot;); &#125; this.threadFactory = threadFactory; &#125; @Override public void execute(Runnable command) &#123; threadFactory.newThread(command).start(); &#125;&#125;// netty中的runable都被包装成这个，目的是在run方法执行完后，主动调用FastThreadLocal.removeAll();final class FastThreadLocalRunnable implements Runnable &#123; private final Runnable runnable; private FastThreadLocalRunnable(Runnable runnable) &#123; this.runnable = ObjectUtil.checkNotNull(runnable, &quot;runnable&quot;); &#125; @Override public void run() &#123; try &#123; runnable.run(); &#125; finally &#123; // 手动清理这ThreadLocal，防止内存泄漏 FastThreadLocal.removeAll(); &#125; &#125; static Runnable wrap(Runnable runnable) &#123; return runnable instanceof FastThreadLocalRunnable ? runnable : new FastThreadLocalRunnable(runnable); &#125;&#125; 这里不讲FastThreadLocalThread和FastThreadLocal的代码。 2. 创建所有的children好了，接下来就是其创建children，每一个children都是一个NioEventLoop，看一下这个类： 这个类是一个SingleThreadEventLoop，简而言之就是一个单线程的线程池。这个类非常复杂，之后再看这个类，现在只用知道，EventExecutorGroup现在初始化了一个NioEventLoop数组并持有。 3. 创建chooser先看一下chooser是什么： 1234567891011121314151617181920@UnstableApipublic interface EventExecutorChooserFactory &#123; /** * Returns a new &#123;@link EventExecutorChooser&#125;. */ EventExecutorChooser newChooser(EventExecutor[] executors); /** * Chooses the next &#123;@link EventExecutor&#125; to use. */ @UnstableApi interface EventExecutorChooser &#123; /** * Returns the new &#123;@link EventExecutor&#125; to use. */ EventExecutor next(); &#125;&#125; 首先传入了一个EventExecutor[]，然后又一个next方法用来从EventExecutor[]中选出一个EventExecutor。这里的EventExecutor就是NioEventLoop。 构造函数中使用的EventExecutorChooserFactory是DefaultEventExecutorChooserFactory.INSTANCE： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@UnstableApipublic final class DefaultEventExecutorChooserFactory implements EventExecutorChooserFactory &#123; public static final DefaultEventExecutorChooserFactory INSTANCE = new DefaultEventExecutorChooserFactory(); private DefaultEventExecutorChooserFactory() &#123; &#125; @SuppressWarnings(&quot;unchecked&quot;) @Override public EventExecutorChooser newChooser(EventExecutor[] executors) &#123; if (isPowerOfTwo(executors.length)) &#123; return new PowerOfTwoEventExecutorChooser(executors); &#125; else &#123; return new GenericEventExecutorChooser(executors); &#125; &#125; private static boolean isPowerOfTwo(int val) &#123; return (val &amp; -val) == val; &#125; private static final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser &#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTwoEventExecutorChooser(EventExecutor[] executors) &#123; this.executors = executors; &#125; @Override public EventExecutor next() &#123; return executors[idx.getAndIncrement() &amp; executors.length - 1]; &#125; &#125; private static final class GenericEventExecutorChooser implements EventExecutorChooser &#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) &#123; this.executors = executors; &#125; @Override public EventExecutor next() &#123; return executors[Math.abs(idx.getAndIncrement() % executors.length)]; &#125; &#125;&#125; 最终创建了PowerOfTwoEventExecutorChooser或者GenericEventExecutorChooser作为chooser。这里可以看出，如果传给chooser的EventExecutor数组是2的整数幂，那么next方法的执行效率会快很多。 这里有一个快速判断是个数是否是2的整数次幂的方法，学习到了吗，这里使用到了补码的性质。 Q&amp;A以及总结Q：NioEventLoopGroup是什么？ A：netty内部的线程池，用来管理netty内部的线程。 Q：NioEventLoop是什么？ A：包装了一个Thread，NioEventLoop本质是一个只有一个线程的线程池，但是比起线程池来说干了很多其他的事情，比如注册一些事件，注册Selector等功能。 Q：NioEventLoopGroup如何选出一个NioEventLoop？ A：使用chooser，chooser有两种，当NioEventLoop数量是2的整数幂的时候，使用与运算，否则使用取余从数组中取出NioEventLoop，但是两种方法都是轮询的取，去的顺序没有区别，只是前者更快。 Q：Thread和FastThreadLocalThread的区别？ A：FastThreadLocalThread使用的是FastThreadLocal，FastThreadLocal内部是线性的存取数据，而java原生的ThreadLocal使用的是hash，所以FastThreadLocal要快不少。FastThreadLocalThread中跑的Runnable是经过包装后的FastThreadLocalRunnable，在执行完run方法后，会主动清除FastThreadLocal中的数据。 Q：NioEventLoopGroup的创建过程是怎样的？ A：首先创建executor，最主要的作用是使用netty的ThreadFactory，保证创建的线程都是FastThreadLocalThread，然后根据nThread创建NioEventLoop数组，作为children持有，最后根据children创建一个chooser。 Q：NioEventLoopGroup持有的children是什么？ A：就是一个NioEventLoop数组，用来真正干活的线程组。 Q：bossGroup和workerGroup的区别： A：bossGroup用来监听客户端连接请求，连接之后就将其他的任务交给workerGroup了，所以bossGroup内部只有一个线程，workerGroup的默认大小是availableProcessors() * 2。","categories":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/tags/Netty/"}]},{"title":"从零手撸一个Rpc框架-4-Registry层、Config层","slug":"MyRpc-4","date":"2019-09-12T12:12:34.000Z","updated":"2021-06-25T13:47:33.059Z","comments":true,"path":"articles/Rpc/MyRpc-4/","link":"","permalink":"https://www.jelliclecat.cn/articles/Rpc/MyRpc-4/","excerpt":"","text":"上篇我们讲了重构后的transport层和Cluster层，这篇博客讲一讲Registry层和Config层，Registry层使用了Zookeeper的实现。 GitHub项目地址：susu 话不多说，我们直接开始看吧~ 一、Registry层registry层有两个基本接口：Registry和NotifyListener。 1. Registry1234567public interface Registry extends LifeCircle &#123; void register(URL url); void unregister(URL url); void subscribe(URL url, NotifyListener listener); void unsubscribe(URL url, NotifyListener listener);&#125; 2. NotifyListener123public interface NotifyListener &#123; void notify(URL registryUrl, List&lt;URL&gt; urls);&#125; 功能非常的明显。这里url作为统一的配置总线很让人疑惑，需要好好分析一下不同的方法传入的URL参数有什么不同： 调用register，一般来说是Server端调用的，Server端将所有的东西都准备好之后，将自己的URL注册到注册中心中，URL中至少需要包含一下内容： 服务的名称，即暴露的接口名，这个接口名字是包含包名全路径的。 服务所属的组，以后随着暴露出的接口越来越多，不同工程或者不同业务所暴露出来的接口需要分组管理。 服务版本，表示当前服务所提供的版本，客户端需要根据版本信息判断该服务能否提供服务。 URL中需要标识该URL是属于服务端的URL还是客户端的URL。 服务协议，客户端需要判断协议是否匹配 最后，需要该服务的ip地址和端口号。 调用subscribe，一般来说subscribe是client端调用的，用来订阅一个目录，那这里传入的URL是什么呢？是服务端的URL吗？我要订阅一个服务，那我传入一个服务端的URL，听起来没错，但是细想是有问题的，第一，客户端调用这个方法怎么知道服务端的url呢？第二，这里订阅一个目录需要URL吗？其实不需要，只需要目录名就行。那么问题来了，client端怎么获得目录名呢？ 这里需要先明确一下注册中心的目录结构，从上面Server端url的结构可以看出一些端倪，服务端目录结构至少由这几个层次：服务组，服务接口名（interface name），服务ip&amp;port。 / [server group] / [interface name] / [ip&amp;port&amp;settings] 那么client端需要订阅的其实只有服务组和服务名就可以了，上篇博客已经先简单的分析过URL的结构了，一组对应的Client和Server的URL都是有相同的服务接口名称的，这是必须的，服务接口名就是我们定义的服务接口的全路径名称。所以Client端是可以轻松拿到这两个字段的，至于组，直接在URL中设置就行了。 这么看来调用subscribe的时候，传入的url是客户端自己的url，然后程序根据client端的url订阅到具体的目录下。 这么看来，调用subscribe貌似没必要传入URL这种包含这么多信息的对象，只需要传入组名和服务名就可以了，这样的话程序逻辑就非常清晰了。但是dubbo除了单单subscribe以外，还干了一件事，就是同时将client端的url注册到了另一个目录下，这样做的目的我估计是两点：一，方便监控Client端的在线信息；二，Server端以至于其他任何终端，都可以发现Client端并主动与Client端通信。 好了，到这里就介绍完了Registry中两个主要的方法（register和subscribe）以及他们的参数URL需要怎么传。 在subscribe方法中还会传一个回调，这个回调就是NotifyListener，用来当订阅的节点目录发生变化时，通知这个NotifyListener，可以想象到，实现这个NotifyListener的类，需要能够知道服务端暴露信息的节点的变化，并拿到变化后的服务端的全量url，从而更新自己的服务列表，对了，有这个需求的对象就是Cluster，很明显Cluster需要知道服务端的变化，并动态更新自己的Invoker可用列表，加入新的可以用的服务并销毁不再可用的服务。 看了上篇博客的朋友们肯定知道，Cluster是继承了NotifyListener接口的。 这里有个小问题：这里发生了反向依赖，即cluster层依赖了更高层registry层的接口NotifyListener，但是NotifyListener接口其实可以不属于registry层，可以作为core层的基础接口，这样就解决了反向依赖的问题，但是还是有点不和谐，如果你们有更好的建议，可以给我留言或者提PR。 3. ZookeeperRegistry这个类实现了Zookeeper版本的注册中心的实现。 先贴一下目录： / [server group] / [interface name] / [ip&amp;port&amp;settings] 常用的Zookeeper有两种：zkClient和Curator，客户端有一些好处，它封装了Zookeeper的原生api，提供了更加方便的接口，并在内部做了一些重连重试等功能的封装。 dubbo将zookeeper的实现也进行了抽象，分别支持了不同的Zookeeper客户端，并可可以配置。motan就更加直接一些，直接使用了zkClient。我使用的是Curator。 在看这段代码之前，大家可能需要先熟悉一下zookeeper的使用和Curator的使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120public class ZookeeperRegistry implements Registry &#123; private static final String PROVIDERS = &quot;providers&quot;; private static final String CONSUMERS = &quot;consumers&quot;; private static final Set&lt;CuratorEventType&gt; interested = new HashSet&lt;&gt;(); static &#123; // 只关心创建节点和删除节点 interested.add(CuratorEventType.CREATE); interested.add(CuratorEventType.DELETE); &#125; private URL registryUrl; private CuratorFramework client; public ZookeeperRegistry(URL url) &#123; registryUrl = url; init(); &#125; @Override public void init() &#123; // todo: RetryPolicy 支持配置 RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 5); // todo : 账号密码支持 client = CuratorFrameworkFactory.builder() .connectString(registryUrl.getIpPortString()) .sessionTimeoutMs(10000) .retryPolicy(retryPolicy) .build(); client.start(); &#125; @Override public void destroy() &#123; if (client != null) &#123; client.close(); &#125; &#125; @Override public boolean isAvailable() &#123; if (client == null) &#123; return false; &#125; CuratorFrameworkState state = client.getState(); return state == CuratorFrameworkState.STARTED; &#125; @Override public void register(URL url) &#123; checkClientStatus(); String path = buildPath(url); if (!exist(path)) &#123; buildPath(path); &#125; path += SusuConstants.PATH_SEP + encodeUrl(url.getUrlString()); ephemeralPath(path); &#125; @Override public void unregister(URL url) &#123; checkClientStatus(); String path = buildPath(url) + SusuConstants.PATH_SEP + url.getUrlString(); delete(path); &#125; @Override public void subscribe(URL url, NotifyListener listener) &#123; checkClientStatus(); String path = buildServerPath(url); // 先同步的回调一次 try &#123; List&lt;String&gt; urls = client.getChildren().forPath(buildServerPath(url) + SusuConstants.PATH_SEP + PROVIDERS); listener.notify(this.registryUrl, urls.stream() .map(this::decodeUrl) .map(URL::parse) .collect(Collectors.toList())); &#125; catch (Exception e) &#123; throw new RegistryException(&quot;ZookeeperRegistry: getChildren error&quot;, e); &#125; // 注册监听器 CuratorListener curatorListener = ((client0, event) -&gt; &#123; if (interested.contains(event.getType())) &#123; if (event.getPath() != null &amp;&amp; event.getPath().startsWith(path)) &#123; System.out.println(event);// todo: 调试删除 List&lt;String&gt; urls = event.getChildren(); listener.notify(this.registryUrl, urls.stream() .map(this::decodeUrl) .map(URL::parse) .collect(Collectors.toList())); &#125; &#125; &#125;); client.getCuratorListenable().addListener(curatorListener); &#125; private void checkClientStatus() &#123; if (!isAvailable()) &#123; throw new RegistryException( &quot;ZookeeperRegistry: registry unavailable, url: &quot; + registryUrl.getIpPortString()); &#125; &#125; private String buildPath(URL url) &#123; String root = url.getString(URL_CONFIG.ROOT); String group = url.getString(URL_CONFIG.GROUP); String path = url.getPath(); String serverOrClient = url.getBoolean(URL_CONFIG.IS_SERVER) ? PROVIDERS : CONSUMERS; return root + SusuConstants.PATH_SEP + group + SusuConstants.PATH_SEP + path + SusuConstants.PATH_SEP + serverOrClient; &#125; ... // 略，具体代码见github&#125; 首先我们实现了LifeCircle中的三个方法，实现了registry的初始化，状态检查以及销毁，后面展示了两个主要方法的实现。 register方法首先做一下状态检查，然后检查服务路径是否存在，如果不存在这个服务的路径，则先创建一个永久服务路径，即： / [server group] / [interface name] 然后创建一个临时路径保存当前的url信息。这里要用临时节点，因为不是每次服务退出的时候都能保证去手动清理掉自己在注册中心注册的服务信息，比如服务突然断线，这样就没有时间让服务自己清理，这时候如果这个节点是永久节点，那客户端就会拿到一个已经下线的服务的url，从而造成服务失败。zookeeper可以在断线后自动清理掉临时节点。 本地测试，注册服务之前和注册之后： 服务root是/susu，组名是default，服务名是com.nowcoder.first.IService，ip&amp;port&amp;setting是下面经过编码后的url。 subscribe方法subscribe方法比较简单，首先将目录下的所有url读出来先回调一次NotifyListener，保证在调用subscribe方法的时候可以同步获取数据。然后通过Curator注册了一个zookeeper的watcher，用来通知NotifyListener节点的变化。 这里我们只关心两个事件：节点create和delete信息。注意这里订阅的节点层级，不能多不能少，不然获得的回调信息会有问题。 回调事件触发的时候，我们还需要检查触发的节点路径是否是和当前监听的Url想匹配的服务，如果不是将会忽略。 后面的几个方法register和unsubscribe等就不赘述了。 二、Config层config层太简单了，暂时还没啥好些的，嘻嘻~之后再补充吧。 三、总结这波代码更新一共2200行，应该说还是加了不少东西。 问题也有很多，目前大多数优化和修改都是在Client这边，Server那边仍然是最蠢的代码实现，比如多个服务同时暴露在同一个端口时如何路由等功能都还没有。 URL这个东西也是很闹心，感觉这个东西相当于传了一个map，一个map在一个框架里面从头到脚的作为一个参数去传太难受了，这个问题我要想办法解决一下。 日志目前还是一片空白，也还没有做。 Filter也还没有支持，没有想到要支持哪些东西，因为东西都太杂了太小了，没有大的功能需要支持了。 还有一个挺重要的，对Object的各种方法需要处理一下。 我想把URL、Config以及服务端的路由功能做了之后先测试一波，看看有没有明显的问题再说吧~ 如果你有好的建议欢迎提出来~ BTW，SPI这个东西暂时没有支持的打算了，感觉暂时不需要。 GitHub项目地址：susu","categories":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/categories/Rpc/"}],"tags":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/tags/Rpc/"}]},{"title":"从零手撸一个Rpc框架-3-Cluster层、代码重构","slug":"MyRpc-3","date":"2019-09-11T13:20:50.000Z","updated":"2021-06-25T13:47:33.048Z","comments":true,"path":"articles/Rpc/MyRpc-3/","link":"","permalink":"https://www.jelliclecat.cn/articles/Rpc/MyRpc-3/","excerpt":"","text":"GitHub项目地址：susu 之前我们可以说是直接了当的实现了传输层（netty）、编码层（susu协议）、代理层（动态代理），完成了一个rpc框架所需的最少代码，上次代码一共800多行，可以说非常“mini”了。 先看看上次遗留的一个小问题：demo中的client需要sleep一下，我们只用把NettyClient#open方法稍微修改一下就行了： 1234567891011121314151617181920new Thread(() -&gt; &#123; try &#123; ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 20880).sync(); clientChannel = future.channel(); clientChannel.closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;).start();// 改为：ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 20880).sync();clientChannel = future.channel();new Thread(() -&gt; &#123; try &#123; clientChannel.closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;).start(); 我们只用把connect操作从线程里面拿出来即可，这样在open方法退出时，可以保证client已经连上server了。当然，我现在对这部分逻辑进行了更加细致的操作，不再是new Thread了，请看最新代码： susu 这次更新，我加入了对zookeeper的支持，使用zookeeper做注册中心，做了服务注册和发现，并将项目做了分层和抽象，初步完成了配置层，以及最后同样写了一个例子，一起来看看吧~ 问题我们的mini版代码中，代码是严重耦合的，这里不再细致的探讨设计模式的思想，之后会专门写一篇博客探讨设计模式的思想。这里我们使用抽象和分层去解决耦合的问题，保证层与层之间单向依赖，并保证这种依赖是建立在接口上的，而不是实现上的。 之前的代码没有做任何可用性扩展，这里我定义了几个自定义异常去包装各种异常信息，并抽象出了一个LifeCircle接口，用来管理所有对象的生命周期。在dubbo和motan中，这个接口的名称是Node，也是用来管理生命周期的。 之前的代码客户端和服务端是直连的，没有配置，没有服务注册发现，也没有服务簇，这次通过加入Config层、Registry层、Cluster层开始着手去处理这些问题。 一、项目分模块目前susu项目分为5层，每层之间单向依赖，从下到上依次是： susu-core：核心模块，定义了一些基本接口、常量、异常、工具类以及一些基础类。 susu-transport：传输层，定义了传输层的接口、netty版本的实现以及编解码层的实现。这里将codec层和transport层合并了，因为这两层本质上都属于传输层的逻辑，之后如果需要独立出编解码层可以考虑拆开。 susu-cluster：服务簇，包装了传输层，管理传输层的生命周期，并完成了负载均衡功能。 susu-registry：注册层，定义了基本的注册接口，并实现zookeeper版本的注册中心。 susu-config：总设置层，定义了服务暴露和服务发现的接口和功能实现，是rpc框架的总入口。 对比与dubbo和motan的层次接口（系列博客第一篇有讲），我这里层次更少一些，原因目前还不需要这么多层。 接下来一层一层看吧，core模块不单独讲，因为各层都会或多或少的使用到core中的代码，所以我们直接从传输层开始看，看看在上篇博客的基础上，做了哪些改进。 在介绍具体代码之前我要先说一些我的设计思想：所有的设计均基于实际需求，而不是形式上的设计。 【插播！】这里我分享一个我自己的小经验：多数的设计是基于已有的架构遇到问题后在解决的过程中设计并完善的，所有的设计都不是无的放矢的。我自己最开始想去写一些抽象的接口的时候就会犯难，因为总是想着先去抽象一个什么什么接口再去实现，而结果往往是无从下手，不妨换一个思路，先去实现功能而不管实现的过程有多蠢，然后再review代码考虑该怎么优化以及抽象，由于你自己实现了一遍功能，在实现的过程中就能感受到哪些地方是可能重用的，可以抽出来甚至抽象成一个接口，所以这时候抽象出来的接口是真正基于功能抽象出来的。所有的抽象都应该基于功能而不是想象，想象出来的抽象往往很多地方是和实际功能相冲突的。当然，除了那些一眼就知道要怎么抽象的接口可以直接写之外。这里是有实际依据的，我看了spring1.0版的代码，那时候还不叫spring，叫interface21，然后也看了spring5.0的代码，发现很多抽象层次和接口是后来才扩展出来的，这说明是在开发过程中，发现有些地方可以或者说需要抽象成一个接口，然后再进行抽象的，而不是在spring最初版本就把所有的接口定义好了的。但随着接口和抽象的越来越熟练，在设计的时候就就可以提前写好很多的接口了，这时候的设计可能才开始从上到下设计，但在没那么的熟练之前，还是可以考虑由下到上的设计方式。 二、susu-transport我们需要思考一个问题，传输层其实是可能会需要支持不同的协议的，这里的传输层不等于七层网络中的传输层，这里的传输层单指网络传输，里面可能会包含一些应用层的协议，例如http等。所以我们需要抽象出一个传输层的api。传输层需要考虑到连接是否可用等可用性问题，所以需要进行生命周期管理。 1. Channel传输层说白了是管理端到端的连接用的，所以传输层的最基础的api应该是一个信道（或者说连接也行，后文使用信道这个词，代表客户端到服务端的一个通信通道），我们需要知道该信道是否打开或者关闭，需要有打开信道和关闭信道的方法，需要知道该信道上使用的编码协议，以及对于该信道的各种设置。我们就有下面所示的接口： 12345678910111213141516171819202122232425public interface Channel &#123; /** * 使用在该信道上的编解码协议 */ Codec getCodec(); /** * 该传输层的设置 */ URL getUrl(); boolean isOpened(); boolean isClosed(); /** * 打开信道 */ void open(); /** * 关闭信道 */ void close();&#125; Codec接口在上篇博客介绍过了，里面有两个方法，编码和解码，这里再稍微回顾一下： 1234public interface Codec &#123; byte[] encode(Object message) throws CodecException; Object decode(byte[] data) throws CodecException;&#125; 2. Client&amp;Server在Channel接口之后，我们需要分为客户端信道和服务端信道，客户端操作信道和服务端操作信道应该是有区别的，比如客户端需要有从信道发送信息给服务端并获得回复的功能： 123456public interface Client extends Channel &#123; Response invoke(Request request);&#125;public interface Server extends Channel &#123;&#125; 严格来说，Channel需要有读写信息的接口，这也是是一个信道的基础功能之一，实际上Dubbo就是这样抽象的，但是这里考虑到Server端不会主动推送信息给Client端，所以虽然我们使用的C/S模式，但实际是B/S模式，所以这里在Client中扩展了一个类似HttpServlet中的方法，Server接口中不具有任何读写的功能。再一个，我们需要考虑到读写功能是否需要提供给上层使用，这里的结论是上层不需要调用这么具体的读写功能，上层只需要调用Response invoke(Request request)对于我们的rpc框架来说已经足够了（目前足够）。 这里对比一下dubbo的设计（为了缩短篇幅我把注释都删了，dubbo命名没的说，不用注释也能看懂）： 1234567891011121314151617181920public interface Channel extends Endpoint &#123; InetSocketAddress getRemoteAddress(); boolean isConnected(); boolean hasAttribute(String key); Object getAttribute(String key); void setAttribute(String key, Object value); void removeAttribute(String key);&#125;public interface Endpoint &#123; URL getUrl(); ChannelHandler getChannelHandler(); InetSocketAddress getLocalAddress(); void send(Object message) throws RemotingException; void send(Object message, boolean sent) throws RemotingException; void close(); void close(int timeout); void startClose(); boolean isClosed();&#125; 在分享一下motan的Channel设计： 1234567891011public interface Channel &#123; InetSocketAddress getLocalAddress(); InetSocketAddress getRemoteAddress(); Response request(Request request) throws TransportException; boolean open(); void close(); void close(int timeout); boolean isClosed(); boolean isAvailable(); URL getUrl();&#125; InetSocketAddress getLocalAddress(); InetSocketAddress getRemoteAddress();motan中的这两个方法全项目没有任何地方用到，虽然看起来是两个Channel需要有的基本功能，但是可能根本用不到，这就是我上面说的要面向功能抽象。所以我自己的Channel中，稍微精炼了一下，剔除了没有用的方法。 这里有一个设计小细节：当我们在接口中定义一个方法是否需要抛出异常时，所有RuntimeException只需要以注释的形式写明即可，如果显示的抛出一个RuntimeException我个人感觉是很奇怪的，显示抛出异常的用意是告诉调用方需要显示catch，而显示catch的异常通常是Exception异常而非RuntimeException，如果说既需要显示catch，又要定义为RuntimeException异常，那本身就是矛盾的。 dubbo中就有这个问题： 1234567891011121314public interface Invoker&lt;T&gt; extends Node &#123; Class&lt;T&gt; getInterface(); // 这里的RpcException就是一个RuntimeException，但是却显示的抛出了。 /** * invoke. * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException;&#125; 我们看看jdk中的做法，拿Future接口的get方法举例： 123456789101112/** * Waits if necessary for the computation to complete, and then * retrieves its result. * * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting */V get() throws InterruptedException, ExecutionException; 这个方法会主动抛出三个异常，不出意外的，InterruptedException和ExecutionException都是Exception类型，而CancellationException是RuntimeException类型。 这是一个小细节，不知道是我自己的理解有问题还是dubbo有他自己的用意。否则的话，RuntimeException我建议写在方法注释里面。 3. AbstractEndpoint&amp;AbstractClient&amp;AbstractServer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859abstract public class AbstractEndpoint implements Channel, Codec &#123; private static final int UNKNOWN = -1; private static final int NEW = 0; private static final int OPEN = 1; private static final int CLOSE = 2; private Codec codec; private URL url; private volatile int CHANNEL_STATUS = 0; public AbstractEndpoint(Codec codec, URL url) &#123; this.codec = codec; this.url = url; &#125; @Override public Codec getCodec() &#123; return codec; &#125; @Override public URL getUrl() &#123; return url; &#125; public void setUrl(URL url) &#123; this.url = url; &#125; @Override public boolean isOpened() &#123; return CHANNEL_STATUS == OPEN; &#125; @Override public boolean isClosed() &#123; return CHANNEL_STATUS == CLOSE; &#125; @Override public void open() &#123; CHANNEL_STATUS = OPEN; &#125; @Override public void close() &#123; CHANNEL_STATUS = CLOSE; &#125; @Override public byte[] encode(Object message) throws CodecException &#123; return codec.encode(message); &#125; @Override public Object decode(byte[] data) throws CodecException &#123; return codec.decode(data); &#125;&#125; 封装了状态的迁移，并代理了Codec的功能，让其子类可以直接具有编解码的功能。 AbstractClient&amp;AbstractServer这两个类没有做更多的事情，继承了AbstractEndpoint并分别实现了Client接口和Server接口，AbstractClient保存了当前的任务和ResponseFuture的map。 里面比较重要的是支持了URL设置，URL在susu中承担的是配置总线的角色，不难想到AbstractClient&amp;AbstractServer的继承者中的各种配置信息都可以在URL中拿到。dubbo和motan也是用URL作为配置总线，后面我们会详细讨论URL这个类，这个类还是存在一些争议的，有一些坏味道。 4. NettyClient&amp;NettyServer分别继承于AbstractClient&amp;AbstractServer，里面实现了Channel中定义的open方法和close方法，close方法中完成了netty的优雅关机，以及做了一些异常处理工作。 NettyChannelHandler不出意外的被我们拆开成了两个内部类：ServerChannelHandler和ClientChannelHandler，分别存在于NettyServer和NettyClient中，其逻辑没有改变，跟上篇博客中介绍的一样。 好了，transport中的抽象就写到这里啦，总结一下就是，首先进行了抽象，然后完善了信道生命周期的管理。 三、susu-cluster从这层开始往上可以算作是服务治理的功能范畴了，首先要介绍的是配置总线URL以及对它设计的一些讨论，然后会简单介绍一些负载均衡算法，以后会开一篇博客写一写常用的静态负载均衡算法以及动态负载均衡算法，这里实现了最简单的一种：随机负载均衡，之后会逐渐完善各种负载均衡算法。 1. URLurl作为贯穿各层的配置总线的角色存在： 123456789101112131415161718192021222324252627public class URL &#123; /** * 协议 */ private String protocol; /** * host地址 */ private String host; /** * 服务端口 */ private int port; /** * 任务路径，等同于interfaceName */ private String path; /** * 通用设置 */ private Map&lt;String, String&gt; parameters;&#125; 具体的方法没有展示出来，但是从他的属性就能看出一些。对于rpc框架来说，其处理的对象本身就是各种各样的终端，客户端、服务端、注册中心、配置中心、监控中心等等，这些不同的终端无一不是依靠网络通信，既然是网络通信，就一定可以使用URL去描述一个网络资源。所以在RPC框架中使用URL作为一个终端的配置总线是水到渠成的事情，URL中封装了终端的协议类型，ip地址，服务端口，资源路径，以及各种自定义参数。 但这里面存在着坏味道—— URL太泛了，理解门槛较高，并有误用的风险，后面再讲config层的时候我们可以看到一些使用URL作为配置总线的问题，这里先看cluster中的内容。 2. LifeCircle服务治理层有自己的控制生命周期的接口：LifeCircle。 123456public interface LifeCircle &#123; void init(); void destroy(); boolean isAvailable();&#125; 所有与资源有关的接口都应该继承这个接口。 3. Invoker12345678public interface Invoker extends LifeCircle &#123; default URL getURL() &#123; return null; &#125; Response invoke(Request request);&#125; Invoker是上层对于底层一次RPC调用的抽象，其实现类用于管理底层（传输层）的实例。 一个Invoker代表一个可以调用的Channel。dubbo和motan都有自己的Invoker： dubbo： 12345678910111213141516171819public interface Invoker&lt;T&gt; extends Node &#123; /** * get service interface. * * @return service interface. */ Class&lt;T&gt; getInterface(); /** * invoke. * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException;&#125; 前面说过，Node的作用等同于LifeCircle，这里面的Invocation等同于我们的Request，Result等同于Response。 motan中没有Invoker接口，但有一个类似功能的Caller接口： 12345public interface Caller&lt;T&gt; extends Node &#123; Class&lt;T&gt; getInterface(); Response call(Request request);&#125; 可以看到除了名称不一样以外，其他的设计基本一样。 4. LoadBalance1234567891011121314151617181920public interface LoadBalance &#123; Invoker select(List&lt;Invoker&gt; invokers);&#125;public class RandomLoadBalance implements LoadBalance &#123; private Random random; public RandomLoadBalance() &#123; this.random = new Random(); &#125; @Override public Invoker select(List&lt;Invoker&gt; invokers) &#123; if(invokers.size() == 1) &#123; return invokers.get(0); &#125; return invokers.get(random.nextInt(invokers.size())); &#125;&#125; 非常简单的lb以及它的实现类，作用就是从一组可选的Invoker中，根据一定的算法挑选出这一次调用需要使用的Invoker。刚刚说了，Invoker是对一个Channel的封装，更准确的说是对Client的封装，所以一个Invoker在这里可以等同于一个Client来理解。一个Client对应的是一个Server，所以不同的Invoker实际上对应的是不同的Server，所以使用不同的Invoker其实就是将这次请求打到不同的Server，这也是负载均衡这个概念的核心。 5. DefaultInvoker1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DefaultInvoker implements Invoker &#123; private Client client; private URL url; public DefaultInvoker(URL url) &#123; this.url = url; Codec codec; // 检测传输层和编码层各用什么样的实现，如果没有使用默认实现代替 if(&quot;netty&quot;.equals(url.getString(URL_CONFIG.TRANSPORT))) &#123; if(&quot;susu&quot;.equals(url.getString(URL_CONFIG.CODEC))) &#123; codec = new SusuCodec(); &#125; else &#123; codec = new SusuCodec(); &#125; client = new NettyClient(codec, url); &#125; else &#123; client = new NettyClient(new SusuCodec(), url); &#125; &#125; @Override public Response invoke(Request request) &#123; // 先进行最简单的实现 return client.invoke(request); &#125; @Override public URL getURL() &#123; return url; &#125; @Override public void init() &#123; client.open(); &#125; @Override public void destroy() &#123; client.close(); &#125; @Override public boolean isAvailable() &#123; return client.isOpened(); &#125;&#125; DefaultInvoker是invoker的默认实现，里面根据URL中的配置决定使用什么样的传输层实现，我们默认使用SusuCodec和Netty的实现。 6. DefaultCluster12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class DefaultCluster implements Cluster &#123; private LoadBalance loadBalance; private List&lt;Invoker&gt; invokers; private List&lt;URL&gt; urls; private URL url; private volatile boolean init = false; /** * 没有传入urls, 会去registry中拿地址 */ public DefaultCluster(URL url) &#123; this.url = url; &#125; public DefaultCluster(URL url, List&lt;URL&gt; urls) &#123; this.urls = urls; this.url = url; &#125; @Override public Response invoke(Request request) &#123; if(!init) &#123; throw new SusuException(&quot;DefaultCluster: status error when invoke(), init: &quot; + init); &#125; if(invokers == null || invokers.size() == 0) &#123; throw new SusuException(&quot;DefaultCluster: invokers is empty&quot;); &#125; Invoker invoker = loadBalance.select(invokers); if(!invoker.isAvailable()) &#123; invoker.init(); &#125; return invoker.invoke(request); &#125; @Override public void init() &#123; // 初始化负载均衡策略 if(&quot;random&quot;.equals(url.getString(URL_CONFIG.LOAD_BALANCE))) &#123; loadBalance = new RandomLoadBalance(); &#125; else &#123; loadBalance = new RandomLoadBalance(); &#125; // 根据urls构建invoker if(urls != null &amp;&amp; urls.size() &gt; 0) &#123; invokers = urls.stream().map(this::getInvokerFromUrl).collect(Collectors.toList()); &#125; init = true; &#125; @Override public void destroy() &#123; for(Invoker invoker : invokers) &#123; if(invoker.isAvailable()) &#123; invoker.destroy(); &#125; &#125; init = false; &#125; @Override public boolean isAvailable() &#123; return init; &#125; @Override public void notify(URL registryUrl, List&lt;URL&gt; urls) &#123; this.urls = urls; &#125; /** * 创建Invoker的逻辑先独立出来再说，之后可能会有很复杂的创建逻辑。 */ private Invoker getInvokerFromUrl(URL url) &#123; return new DefaultInvoker(url); &#125;&#125; 持有lb的实现，以及Invoker的列表，Cluster本身也继承了Invoker接口，因为Cluster本身是一种特殊的Invoker，Cluster对于上层来说也是一个Invoker，只不过里面封装了一些请求过滤和负载均衡的工作，对于上层来说，Cluster和Invoker干的活是一样的，都是发起一次请求，获得一个返回。 Cluster管理了不同的Invoker的生命周期，并且使用了懒连接的方式：只有当一个Invoker真正被lb选中时才建立真正的连接。这样对于一致性哈希这样的负载均衡算法来说可以节约大量的连接资源—— 因为一致性哈希在原链接不出问题的情况下，永远会使用同一个连接，也就是同一个Invoker。 当上层像调用Invoker一样调用Cluster的invoke方法时，Cluster会先使用持有的lb从备选的Invoker组中选出一个，然后再进行真正的请求。 notify方法之后将Registry层的时候再细讲。 好了，Cluster层到这里也讲完啦~我实现了一个非常简单的Cluster层，我们来回顾一下Cluster层干了什么：首先使用Invoker去抽象底层的Channel，然后向上提供一个特殊的Invoker—— 一个Cluster去调用，Cluster会持有一个Invoker列表，一个Invoker映射一个Server，然后Cluster会根据负载均衡算法去调用真正的Invoker，将请求打到对应的Server上。 四、Registry层、Config层由于篇幅的关系，Registry层、Config层下篇博客再讲啦~ 总结一下，这篇博客讲了如何在上篇博客基本实现功能了的基础上，进行抽象、分层、扩展。可以看到，基于URL配置的方式可以在不同层非常方便是使用不同的策略去初始不同的实现，比如lb、codec、client、server。虽然每层接口我们都只提供了一种实现，但是扩展起来可以想象到会非常的方便，你甚至可以使用不同的client和server的传输层实现rpc，但是codec必须一样哦！ 本篇博客还讲了Channel和Cluster的接口是如何实现以及如何设计的，这两个接口分别对应transport层和cluster层的最高抽象接口。 LifeCircle的接口做了简单介绍，但是实现没有细讲，因为这部分看代码就好了。 下篇博客我会详细介绍Registry层、Config层，当然重点是Registry层。 最新项目地址：susu","categories":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/categories/Rpc/"}],"tags":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/tags/Rpc/"}]},{"title":"从零手撸一个Rpc框架-2-传输层、编码层、代理层","slug":"MyRpc-2","date":"2019-09-07T13:20:50.000Z","updated":"2021-06-25T13:47:33.047Z","comments":true,"path":"articles/Rpc/MyRpc-2/","link":"","permalink":"https://www.jelliclecat.cn/articles/Rpc/MyRpc-2/","excerpt":"","text":"这里我完成了最初始的Config层，Proxy层，Codec层，以及Transport层。 具体来说，我使用Netty作为Transport层，并进行了半包和粘包的处理；我自己定义了自己的通信协议：susu协议，协议头待会会介绍；使用Java原生的动态代理作为Proxy；Config层只写了最基础的代码。 GitHub项目地址：susu 这篇博客干货比较多，基本都是代码，前方高能： 一、测试程序Rpc服务接口： 123public interface IService &#123; String say(String name);&#125; Client代码（也叫consumer）： 1234567891011public class ClientTest &#123; public static void main(String[] args) throws Exception &#123; Reference&lt;IService&gt; reference = new Reference&lt;&gt;(); reference.setInterfaceClass(IService.class); IService service = reference.getRefer(); // Thread.sleep(1000); String result = service.say(&quot;zrj&quot;); System.out.println(result); &#125;&#125; Server代码（也叫Provider）： 123456789101112131415public class ServerTest &#123; public static void main(String[] args) &#123; Exporter&lt;IService&gt; exporter = new Exporter&lt;&gt;(); exporter.setInterfaceClazz(IService.class); exporter.setRef(new IServiceImpl()); exporter.export(); &#125; private static class IServiceImpl implements IService &#123; @Override public String say(String name) &#123; return &quot;from rpc &quot; + name; &#125; &#125;&#125; 这部分代码上篇博客最后已经介绍过了，这篇博客将底层的实现全部完成了，运行结果如下： 二、代码细节我先介绍两个类：Request和Response，这两个类封装了通信payload中的所有信息，我们的Rpc框架使用这两个类进行网络的信息交换，之后也会基于这两个类做序列化等工作。 Request：各个字段的说明写在注释里面了： 123456789101112131415public class Request &#123; // 每次请求唯一的id private long requestId; // 服务的接口名称，带包名 private String interfaceName; // 方法名 private String methodName; // 参数列表的类型，用英文逗号分隔，名称带包名 private String argsType; // 参数列表对应的参数值，会被序列化 private Object[] argsValue; /* getter &amp; setter */&#125; Response：1234567891011public class Response &#123; // 对应的是那个请求的id private long requestId; // 返回值 private Object returnValue; // 抛出了异常 private Exception exception; /* getter &amp; setter */&#125; 1、服务端：Exporter：Exporter代码超简单，调用export时直接打开了一个NettyServer： 12345678910111213141516171819 */public class Exporter&lt;T&gt; &#123; private T ref; private Class&lt;T&gt; interfaceClazz; public void setInterfaceClazz(Class&lt;T&gt; interfaceClazz) &#123; this.interfaceClazz = interfaceClazz; &#125; public void setRef(T ref) &#123; this.ref = ref; &#125; public void export() &#123; NettyServer nettyServer = new NettyServer(new Provider&lt;&gt;(ref, interfaceClazz)); nettyServer.open(); &#125;&#125; 这里面引入了两个个新的类：NettyServer、Provider，我们先看NettyServer。 NettyServer：1234567891011121314151617181920212223242526272829303132333435public class NettyServer extends ChannelDuplexHandler &#123; private Handler handler; public NettyServer(Handler handler) &#123; this.handler = handler; &#125; public void open() &#123; NioEventLoopGroup bossGroup = new NioEventLoopGroup(1); NioEventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(&quot;decoder&quot;, new NettyDecoder()); pipeline.addLast(&quot;encoder&quot;, new NettyEncoder()); NettyChannelHandler channelHandler = new NettyChannelHandler(handler); pipeline.addLast(&quot;handler&quot;, channelHandler); &#125; &#125;); serverBootstrap.childOption(ChannelOption.TCP_NODELAY, true); serverBootstrap.childOption(ChannelOption.SO_KEEPALIVE, true); try &#123; ChannelFuture f = serverBootstrap.bind(20880); f.syncUninterruptibly(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 一个最基本的Netty服务，里面接受一个参数：handler，这是一个通用接口，用来处理具体逻辑，当NettyServer接受到请求后，最终的处理逻辑会委托给handler。 Handler：12345678/** * 传输层获得数据后，交给具体的处理方法 * * @author zrj */public interface Handler &#123; Object handle(Object message);&#125; NettyServer代码中出现了几个新类：NettyDecoder、NettyEncoder、NettyChannelHandler，这里先简单介绍一下：NettyDecoder用来解决半包粘包问题，NettyEncoder没什么用，NettyChannelHandler是一个标准的Netty的ChannelHandler，用来处理各种网络事件，待会会仔细的看这几个类，现在先简单介绍一下有个印象。 当我们创建完NettyServer后，会启动20880接口去监听服务并阻塞等待。 NettyChannelHandler：这个类是一个标准的ChannelHandler类，用来处理网络事件，Client端和Server端共用这个类，之后如果Client端和Server端的代码差异增加，这个类可以拆开成两个ChannelHandler，分别用于Client端和Server端，这里我偷懒就直接写成一个了，继承了ChannelDuplexHandler，这里我们先看怎么处理Request的部分逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class NettyChannelHandler extends ChannelDuplexHandler &#123; private Codec codec; private Handler handler; public NettyChannelHandler(Handler handler) &#123; this.codec = new SusuCodec(); this.handler = handler; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; Object object = codec.decode((byte[]) msg); if (!(object instanceof Request) &amp;&amp; !(object instanceof Response)) &#123; throw new SusuException(&quot;NettyChannelHandler: unsupported message type when encode: &quot; + object.getClass()); &#125; if (object instanceof Request) &#123; processRequest(ctx, (Request) object); &#125; else &#123; processResponse(ctx, (Response) object); &#125; &#125; private void processRequest(ChannelHandlerContext ctx, Request msg) &#123; Object result = handler.handle(msg); Response response = new Response(); response.setRequestId(msg.getRequestId()); if(result instanceof Exception) &#123; response.setException((Exception) result); &#125; else &#123; response.setReturnValue(result); &#125; sendResponse(ctx, response); &#125; private void processResponse(ChannelHandlerContext ctx, Response msg) &#123; handler.handle(msg); &#125; private ChannelFuture sendResponse(ChannelHandlerContext ctx, Response response) &#123; byte[] msg = codec.encode(response); if (ctx.channel().isActive()) &#123; return ctx.channel().writeAndFlush(msg); &#125; return null; &#125;&#125; 可以看到，当我们收到msg后，直接调用了Codec进行解码，这里msg一定是byte[]，这一点是由NettyDecoder保证的，之后在讲半包粘包问题时会介绍到这部分代码。 解码之后，如果是Request，则委托给handler去执行具体的代码，这里的Handle是我们创建NettyServer的时候传进来的，是一个Provider实例，下面会介绍Provider。Provider返回给我们一个结果，我们先判断结果是否是一个异常，并创建一个Response填充具体的字段，最后我们使用sendResponse方法将这个Response返回给客户端，当然返回之前还是要先编码为byte[]。 到这里，一个完整的过程已经很清晰了，我们剩下需要关心的是两件事情，一个是如何编解码，一个是Provider具体干了什么，编解码对于这部分逻辑是透明的，你只用知道byte[]被转换成了Request或者Response就可以了，所以编解码部分最后再讲。 下面我们看看Provider。 Provider：可以看到，在我们创建NettyServer的时候传入了一个Provider实例，这个实例实现了Handler接口，看看里面干了什么： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * @author zrj CreateDate: 2019/9/5 */public class Provider&lt;T&gt; implements Handler &#123; protected Map&lt;String, Method&gt; methodMap = new ConcurrentHashMap&lt;&gt;(); private T ref; private Class&lt;T&gt; interfaceClazz; /** * 找到所有interfaceClazz可以调用的方法，并缓存下来，缓存名字要保留参数类型的完整名称，防止函数重载 */ public Provider(T ref, Class&lt;T&gt; interfaceClazz) &#123; if(!interfaceClazz.isInterface()) &#123; throw new SusuException(&quot;Provider: interfaceClazz is not a interface!&quot;); &#125; this.ref = ref; this.interfaceClazz = interfaceClazz; List&lt;Method&gt; methods = ReflectUtils.parseMethod(interfaceClazz); for(Method method : methods) &#123; String methodDesc = ReflectUtils.getMethodDesc(method); methodMap.putIfAbsent(methodDesc, method); &#125; &#125; @Override public Object handle(Object message) &#123; if(!(message instanceof Request)) &#123; throw new SusuException(&quot;Provider: handle unsupported message type: &quot; + message.getClass()); &#125; Request request = (Request) message; String methodName = ReflectUtils.getMethodDesc(request.getMethodName(), request.getArgsType()); Method method = methodMap.get(methodName); if(method == null) &#123; return new SusuException(&quot;Provider: can&#x27;t find method: &quot; + methodName); &#125; try &#123; return method.invoke(ref, request.getArgsValue()); &#125; catch (Exception e) &#123; return new SusuException(&quot;Provider: exception when invoke method: &quot; + methodName, e); &#125; catch (Error e) &#123; return new SusuException(&quot;Provider: error when invoke method: &quot; + methodName, e); &#125; &#125;&#125; 可以看到，构造函数中，首先找到了interfaceClazz的所有可以被调用的Method对象，这里只保留了限定符为public的方法，并将这些方法全部缓存到本地，Key用的是方法签名，方法签名包括参数列表，防止有重载的方法。 当调用handler的时候，将message转成Request类型（这个在调用方保证），然后拿到Request中的调用的方法和参数信息组装成Key，通过Key拿到对应的Methed，然后通过反射调用具体的方法，最后返回调用的结果，如果调用出错则抛出异常。 好了，到这里看看我们完成了什么功能，首先我们使用Netty开了一个端口监听请求，请求到来之后经过最后扔进了Provider中调用具体的方法，并返回调用结果。 当然，Netty传过来的数据是二进制数据，需要反序列化。 其实服务端的代码到这里就介绍完了，是不是很简单！ 回顾一下主要是三个类， NettyServer，用来启动一个Netty服务监听网络。 NettyChannelHandler，用来接收网络请求，并将二进制请求反序列化为Request对象，然后调用Provider获取结果，包装成Response返回给客户端。 Provider，持有服务接口的实现的引用，并使用反射解析服务接口的各种方法，当Request对象到来时，根据Request中的信息得到具体需要调用的方法，使用反射调用后获取结果，返回给NettyChannelHandler。 好了服务端的代码先到这，接下来看看客户端的代码，客户端也就是Rpc的调用方。 2、客户端Reference：Reference也很简单，使用默认的ProxyFactory创建一个代理： 123456789101112131415161718192021public class Reference&lt;T&gt; &#123; private ProxyFactory&lt;T&gt; proxyFactory; private Class&lt;T&gt; interfaceClass; public Reference() &#123; this.proxyFactory = new ProxyFactory&lt;&gt;(); &#125; public T getRefer() &#123; return proxyFactory.getProxy(interfaceClass); &#125; public Class&lt;T&gt; getInterfaceClass() &#123; return interfaceClass; &#125; public void setInterfaceClass(Class&lt;T&gt; interfaceClass) &#123; this.interfaceClass = interfaceClass; &#125;&#125; ProxyFactory：123456public class ProxyFactory&lt;T&gt; &#123; @SuppressWarnings(&quot;unchecked&quot;) public T getProxy(Class&lt;T&gt; clazz) &#123; return (T) Proxy.newProxyInstance(clazz.getClassLoader(), new Class[]&#123;clazz&#125;, new ProxyHandler()); &#125;&#125; 创建了一个代理，重点在于ProxyHandler，看看ProxyHandler干了什么。 ProxyHandler：123456789101112131415161718192021222324252627282930313233343536373839public class ProxyHandler implements InvocationHandler &#123; private NettyClient client; public ProxyHandler() &#123; this.client = new NettyClient(); client.open(); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Request request = new Request(); request.setInterfaceName(method.getDeclaringClass().getName()); request.setMethodName(method.getName()); request.setArgsType(getArgsTypeString(args)); request.setArgsValue(args); Response response = client.invoke(request); if(response.getException() != null) &#123; throw response.getException(); &#125; return response.getReturnValue(); &#125; private String getArgsTypeString(Object[] args) &#123; if(args.length &lt;= 0) &#123; return &quot;&quot;; &#125; StringBuilder sb = new StringBuilder(); for(Object object : args) &#123; sb.append(object.getClass().getName()).append(&quot;,&quot;); &#125; if(sb.length() &gt; 0) &#123; sb.setLength(sb.length() - &quot;,&quot;.length()); &#125; return sb.toString(); &#125;&#125; 可见这个类是整个客户端的重点，首先，ProxyHandler构造时，首先创建了一个NettyClient并持有。当代理类的方法被调用的时候，首先根据调用的运行时信息创建Request，然后调用Response response = client.invoke(request)获取Response，然后返回具体的结果，抛出异常或者正常返回。 具体的调用工作交给了NettyClient。 NettyClient：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class NettyClient &#123; private io.netty.channel.Channel clientChannel; private Codec codec = new SusuCodec(); private Map&lt;Long, ResponseFuture&gt; currentTask = new ConcurrentHashMap&lt;&gt;(); public Response invoke(Request request) &#123; byte[] msg = codec.encode(request); ResponseFuture response = new DefaultResponseFuture(); currentTask.put(request.getRequestId(), response); clientChannel.writeAndFlush(msg); try &#123; return (Response) response.getValue(); &#125; catch (Exception e) &#123; Response response1 = new Response(); response1.setRequestId(request.getRequestId()); response1.setException(new TransportException(&quot;NettyClient: response.getValue interrupted!&quot;)); return response1; &#125; &#125; public void open() &#123; Bootstrap bootstrap = new Bootstrap(); NioEventLoopGroup nioEventLoopGroup = new NioEventLoopGroup(); bootstrap.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 1000); bootstrap.option(ChannelOption.TCP_NODELAY, true); bootstrap.option(ChannelOption.SO_KEEPALIVE, true); bootstrap.group(nioEventLoopGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(&quot;decoder&quot;, new NettyDecoder()); pipeline.addLast(&quot;encoder&quot;, new NettyEncoder()); pipeline.addLast(&quot;handler&quot;, new NettyChannelHandler( message -&gt; &#123; Response response = (Response) message; ResponseFuture future = currentTask.remove(response.getRequestId()); future.onSuccess(response); return null; &#125; )); &#125; &#125; ); new Thread(() -&gt; &#123; try &#123; ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 20880).sync(); clientChannel = future.channel(); clientChannel.closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 当调用open之后，同样很简单的创建了一个Netty客户端，不过这里 bootstrap.connect(&quot;127.0.0.1&quot;, 20880).sync();方法在另外一个线程中调用，不然会阻塞我们的Main方法，之后的代码无法运行。 在里面创建客户端时，同样加入了NettyDecoder，NettyEncoder，NettyChannelHandler以及一个匿名的Handler，这个Handler用来通知ResponseFuture，服务端已经返回结果了。 ResponseFuture是一个Future，用来异步获取Netty服务返回的结果。 ResponseFuture：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DefaultResponseFuture implements ResponseFuture &#123; private static final int NEW = 0; private static final int SUCCESS = 1; private static final int CANCEL = 2; private static final int FAILED = 3; private final Object lock = new Object(); private volatile int status; private Response value; public DefaultResponseFuture() &#123; this.status = NEW; &#125; @Override public void onSuccess(Response response) &#123; synchronized (lock) &#123; value = response; status = SUCCESS; lock.notifyAll(); &#125; &#125; @Override public void onFailure(Response response) &#123; synchronized (lock) &#123; value = response; status = FAILED; lock.notifyAll(); &#125; &#125; @Override public Object getValue() throws InterruptedException &#123; if (status &gt; 0) &#123; return value; &#125; synchronized (lock) &#123; if (status &gt; 0) &#123; return value; &#125; lock.wait(); &#125; return value; &#125;&#125; 可以看到，当我们调用getValue()方法时，如果结果还没有准备好，会挂起当前调用的线程，直到onSuccess方法被调用，设置进来结果后，才会唤醒所有等待的线程。onSuccess方法刚刚已经看到了，这个方法被注册进了NettyChannelHandler，当Netty服务端返回时，onSuccess就会被回调。 最后看看NettyClient中的invoke方法，这个方法超级简单，首先序列化Request请求，然后创建一个DefaultResponseFuture用来异步获取结果， 并将当前的请求放入本地的缓存中，方便异步返回时配对，然后调用clientChannel.writeAndFlush(msg);，将请求发给服务端，最后调用DefaultResponseFuture.getValue阻塞等待结果。 3、编解码，susu协议编解码器的接口： 123456789/** * 编解码器 * * @author zrj CreateDate: 2019/9/5 */public interface Codec &#123; byte[] encode(Object message) throws CodecException; Object decode(byte[] data) throws CodecException;&#125; susu协议编解码器： 123456789101112131415/** * 编解码核心类： * * 协议头： * * | magic 16bit | version 8bit | type flag 8bit | * | content length 32 bit | * | request id 64 bit | * | request id 64 bit | * | content ... | * * * @author zrj CreateDate: 2019/9/5 */public class SusuCodec implements Codec &#123; 不用多解释了，协议头写在注释里面啦！ 至于具体的编解码过程没什么好说的，就是硬编码，感兴趣的朋友们看Github上的源码，GitHub项目地址：susu。 除了协议头之外，还有对Request和Response对象的序列化，我使用的是FastJson序列化框架： 1234567891011121314151617public class FastJsonSerialization implements Serialization &#123; @Override public byte[] serialize(Object object) throws IOException &#123; SerializeWriter out = new SerializeWriter(); JSONSerializer serializer = new JSONSerializer(out); serializer.config(SerializerFeature.WriteEnumUsingToString, true); serializer.config(SerializerFeature.WriteClassName, true); serializer.write(object); return out.toBytes(&quot;UTF-8&quot;); &#125; @Override public &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; clazz) throws IOException &#123; return JSON.parseObject(new String(bytes), clazz); &#125;&#125; 4、半包与粘包半包与粘包发生在TCP传输中，由于TCP是面向流的协议，TCP本身不知道如何去截断有完整语义的数据包，所以在客户端看来是分离的单独语义的数据包经过TCP传输后可能有的数据包被截断了，有的数据包被连在一起了，这是需要我们自己设计协议去解析数据流，将我们自己定义的数据包从TCP流中识别出来。 最常用的方法就是在我们自定义的协议头中加入content length字段，标识这段数据包有多少数据。 在netty中，netty提供了方便的用于处理半包粘包问题的入口。 我们可以继承ByteToMessageDecoder，每次轮询到TCP中有未读数据后，会调用decode方法，decode方法会让你有机会先”检视“一次数据，如果数据不完整（发生了半包）的话，就直接return，等待TCP的下次轮询，当有足够的数据之后，我们可以根据自己的规则，将数据写入到List&lt;Object&gt; out参数中，告诉netty我们有足够的数据了，可以继续进行下面的步骤了。 NettyDecoder：12345678910111213141516171819202122232425262728293031public class NettyDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; // 数据比协议头小，直接返回 if (in.readableBytes() &lt;= CodecConstants.HEADER_SIZE) &#123; return; &#125; // 标记初始位置 in.markReaderIndex(); short magic = in.readShort(); if(magic != CodecConstants.MAGIC_HEAD) &#123; in.resetReaderIndex(); throw new TransportException(&quot;NettyDecoder: magic number error: &quot; + magic); &#125; in.skipBytes(2); int contentLength = in.readInt(); if(in.readableBytes() &lt; contentLength + 8/* requestId 8 byte */) &#123; in.resetReaderIndex(); return; &#125; // 全部读取 in.resetReaderIndex(); byte[] data = new byte[CodecConstants.HEADER_SIZE + contentLength]; in.readBytes(data); out.add(data); &#125;&#125; 首先检查数据大小是否大于协议头，大于协议头我们才继续。 由于大于协议头，所以后面的16个字节的数据我们可以放心的读出，而不用担心越界异常。我们先检查了一下Magic头，看看是不是我们协议的数据，然后去读contentLength字段，我们就知道了这个数据头所携带的数据包有多大，然后看看ByteBuf中是否有足够的数据，如果没有直接返回，等待下次轮询，如果有了足够数据，则直接取出这个数据包中的所有数据，加入到out中。 千万要注意，这里只能读出本数据包中的数据，由于可能发生粘包，如果将ByteBuf中的数据全部读出来，可能会读到下个数据包的部分数据，导致真正要处理下个数据包的时候，读不出完整的数据，从而导致报错或者一些意想不到的错误，甚至死循环。 三、总结我们进行了最最简单的编码，直奔最终的结果，去完成一次最简单的RPC调用，这些代码写完的时间非常短，所以里面可能有大量大量的隐藏问题。这段代码暂时仅用于学习和理解RPC框架流程，随着之后的完善，不排除用于生产环境的可能。 代码在这。 GitHub项目地址：susu 之后会引入Zookeeper作为注册中心，支持Cluster和负载均衡部分，并完善代码逻辑，加入各种设置（本文中都没有设置入口，端口和ip全都写死的）。 如果要运行，请将Client中的sleep代码放出来，因为有可能调用的时候，Client和Server的TCP还没链接，之后也会修复这个问题。","categories":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/categories/Rpc/"}],"tags":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/tags/Rpc/"}]},{"title":"从零手撸一个Rpc框架-1-Dubbo和Motan","slug":"MyRpc-1","date":"2019-09-06T14:47:50.000Z","updated":"2021-06-25T13:47:33.063Z","comments":true,"path":"articles/Rpc/MyRpc-1/","link":"","permalink":"https://www.jelliclecat.cn/articles/Rpc/MyRpc-1/","excerpt":"","text":"Dubbo和Motan这个Rpc博客系列的重点主要是记录我自己从零开发一款Rpc框架的过程，所以不会详细去介绍市面上已有的框架，但是在我们正式开始之前，还是不得不介绍一下市面上有代表性的Rpc框架，这里选了两款，dubbo和motan，dubbo是阿里研发的，已经捐献给了Apache；motan是微博的于2016年开源。 先说一下Rpc框架的分类，大致可以分为两类，这两类代表了两个不同的发展方向： 服务治理型 跨语言型 dubbo和motan框架都属于服务治理型框架，在具备基础的Rpc调用功能之上，提供了集群容错、路由、负载均衡、服务注册发现等具有集群治理属性的功能。而跨语言型Rpc框架，顾名思义是为了不同语言之间的服务能够互相调用彼此的服务，比较有名的有ICE，Thrift等，这些服务一般提供一种更加抽象的描述语言，这种语言用来抽象一个服务接口，然后根据不同的语言类型转化为不同的具体代码，这种框架不是我们要讨论的重点。 目前Java开发的Rpc框架更加侧重于服务治理型，这里再说一下Spring Cloud，Spring Cloud实际上属于微服务框架，Rpc只是Spring Cloud提供的其中一个功能，所以Spring Cloud是Rpc框架的更加先进的版本，但是Spring Cloud太庞大，其中集成的框架过于繁多，而dubbo和motan属于轻量型框架。 dubbo和motan本身非常的轻巧，dubbo和motan分别只含有13.6W行和3.5W行代码（包含测试代码），要知道SpringFramework有60W行代码。dubbo的代码稍多一下，因为dubbo对于不同的层提供了不同的实现，举个例子，dubbo在服务注册发现层，提供了consul、redis、default、multicast、nacos、sofa、zookeeper、etcd3这n种实现，在实际使用过程中，只会用得着其中一个，并且里面有些实现并没与太大的用处，可能仅供学习，比如没人能拿redis去做服务注册。相对来说motan的实现就轻巧很多，服务注册只支持了zookeeper和consul这两种最常用的框架。 两个框架的区别 dubbo在代理层使用了javassist框架作为代理生成器，javassist框架可以动态编译加载代码，这使得有些地方看起来十分容易让人疑惑，motan更加直接的使用了Java原生的动态代理，看起来更加亲切一些。 dubbo对于很多调用都抽象成了Invoke这个接口，然后这个接口上通常都会包一层Proxy，有的时候看起来给人感觉有点强行设计的感觉，没那么明了，motan的调用更加清晰一些。 dubbo提供了配置中心，而motan没有。 dubbo提供了大而全的各层的实现，motan只提供了最常用的实现。 一些细节的实现不同，比如dubbo过期使用了哈希轮转算法（代码是复制的netty的代码），motan使用了最朴素的实现方式。 dubbo提供了更丰富的请求重发策略。 dubbo提供了monitor模块。 motan使用了连接池，dubbo的dubbo协议使用单一链接。 两个框架的相同点：看过源码就会发现，motan简直就是dubbo的精缩版，两个框架不仅在架构分层上惊人的相似，就连很多类的命名都一样，两者的设计几乎如出一辙。 dubbo: config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool [来源]：dubbo框架设计 motan相对应的层: config 几乎一样 proxy 几乎一样，使用的Java动态代理而不是javassist registry 几乎一样，支持了zookeeper和consul cluster 没有Directory和Router，提供了Cluster和LoadBalance接口 没有moniter，但是提供了Switcher，可以实现简单的熔断功能 protocol 使用了motan协议 没有exchange，但提供了rpc层，用来封装底层的通信 transport 几乎一样，提供了netty和netty4的实现 serialize 几乎一样，提供了fastjson、Hessian2和Java原生实现 在其他设计方面，两者都是用自定义的URL作为整个通信的总线，都是用SPI作为扩展接口，并都实现了ExtensionLoader，两者底层都使用netty作为传输层，当然dubbo支持其他的协议例如http等，两者都没有写什么代码注释，两者相似的地方还有很多很多，不一一列举了。 这里有关于motan更加详细的介绍：从motan看RPC框架设计 关于两个框架更加详细的内容就不再继续介绍了，以后可能会专门写系列博客分析他们的代码，但是不是本系列的重点。 比较的目的我们比较了半天这两个框架，主要的目的是为了学习和弄明白一个Rpc框架需要哪些层次结构，或者说，一次Rpc调用需要经过哪些步骤，弄清楚了这些，一个Rpc的蓝图就已经在脑海里面了，之后要做的事情就是使用自己编程技巧将自己理解的Rpc框架写出来。 在开始敲代码之前，我们看看一次Rpc调用要经过哪些具体的步骤，一个Rpc框架需要分为Client端和Server端两边来看：Client端需要拿到接口的引用，Server端需要给Client暴露服务： 1.Client端要拿到引用例如我们有一个接口： 123public interface IService &#123; String say(String name);&#125; 那我们的Client端的代码希望是这样的（具体的步骤我们写在代码注释里面了）： 1234567891011121314public class ClientTest &#123; public static void main(String[] args) throws Exception &#123; // 定义一个引用 Reference&lt;IService&gt; reference = new Reference&lt;&gt;(); // 定义我们需要拿到的服务接口 reference.setInterfaceClass(IService.class); // 获取服务引用 IService service = reference.getRefer(); // 调用服务的方法 String result = service.say(&quot;zrj&quot;); // 获得返回 System.out.println(result); &#125;&#125; Client端是没有IService的具体实现的，具体实现在Server端，所以可以想象的到，在调用IService service = reference.getRefer();时，我们返回的应该是IService的一个动态代理对象，这个对象里面封装了调用方法时具体执行的步骤，在调用String result = service.say(&quot;zrj&quot;);方法时，获取这次方法调用的各种参数、具体的方法信息等元数据，然后将这些元数据封装成一个请求，最后将这个请求序列化为byte数组，然后调用传输层去连接Server，并将请求发送给Server。最后Server返回一个封装后的结果，Client端收到这个结果后，获取结果并返回。 2.Server端要暴露服务在Client端调用之前，服务端必须先暴露自己的服务，我们希望服务端这样暴露服务： 1234567891011121314151617181920public class ServerTest &#123; public static void main(String[] args) &#123; // 定义一次暴露 Exporter&lt;IService&gt; exporter = new Exporter&lt;&gt;(); // 设置要暴露的服务接口，对应Client端 exporter.setInterfaceClazz(IService.class); // 设置服务接口的具体实现类 exporter.setRef(new IServiceImpl()); // 暴露服务 exporter.export(); &#125; // IService接口的实现 private static class IServiceImpl implements IService &#123; @Override public String say(String name) &#123; return &quot;from rpc &quot; + name; &#125; &#125;&#125; Server端需要根据Client端传过来的参数确定需要调用哪个服务的哪个方法，所以当我们调用exporter.setInterfaceClazz(IService.class);时，就使用反射的方法，找到这个接口中所有的方法签名，并缓存在Map中。当我们调用export的时候，实际上底层肯定是开启了一个端口去监听网络，如果收到了网络请求，那么就先反序列化，然后从请求中拿到需要调用的方法的类和名称，以及方法参数的值，然后去调用本地IServiceImpl中的具体方法，得到结果封装成一个类，然后序列化后通过传输层放回。 这就是Client端和Server端需要做的最基本的工作了。 可以看到，我们至少需要四个层次：Exporter&amp;Reference是最上层的Config层，Proxy代理层用来代理接口并封装底层的网络传输，Transport层用来封装网络传输，Serialization用来封装序列化和反序列化的相关操作。 3.协议设计当我们在传输数据之前，需要写入额外的信息到数据包中，也就是所谓的协议头，这个协议头需要我们自己来定义。协议头中放入了一些基本的协议信息，例如MagicNumber、协议版本、传输数据类型、数据长度、请求Id等。之后会看到我自己设计的网络协议。 总结：最终我按照这条思路进行了简单的实现，下章会具体讲解。 通过看dubbo和motan两个框架的源码，我们弄懂了一个Rpc框架的内部原理，并对基本功能做了一个简单梳理。但是我们还差很多很多的功能以及面临很多的问题： 请求重发怎么做 请求失败后的策略怎么抽象 Cluster怎么封装，负载均衡怎么做 在Transport层一个Client对一个Server是一个连接还是多个连接，是长连接还是短连接 各种设置如何从最上层传递到最下层，不同层的设置怎么区分 缓存怎么做 异步怎么做 服务注册发现怎么做 生命周期如何管理 这些问题都会在之后的博客中一步一步解决。 GitHub项目地址：susu","categories":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/categories/Rpc/"}],"tags":[{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/tags/Rpc/"}]},{"title":"针对基本有序数列的改良冒泡排序","slug":"OooooSort","date":"2019-09-02T11:51:50.000Z","updated":"2021-06-25T13:47:33.053Z","comments":true,"path":"articles/Java/OooooSort/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/OooooSort/","excerpt":"","text":"我把这个排序称为OooooSorthahahaha虽然没有Java自带的TimSort高效，但也只是稍稍逊色，这是一个闲暇时做的小玩意~可以叫做双向冒泡法，或者改良冒泡法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 双向冒泡，不需要额外存储空间，速度稍慢于tim sort * @author zrj CreateDate: 2019/8/4 */public class OooooSort &#123; public static &lt;E&gt; void sort(ArrayList&lt;E&gt; list, Comparator&lt;E&gt; comparator) &#123; if(list == null || list.size() == 0) &#123; return; &#125; int maxSorted = 0; boolean hasSwap; E last; int j = 0; do &#123; hasSwap = false; last = list.get(maxSorted); for(int i = 1; i &lt; list.size() - j; i ++ )&#123; E cur = list.get(i); if(comparator.compare(last, cur) &gt; 0) &#123; hasSwap = true; list.set(i - 1, cur); list.set(i, last); E innerLast = list.get(i - 1); for(int k = i - 2; k &gt;=0; k--) &#123; E innerCur = list.get(k); if(comparator.compare(innerCur, innerLast) &gt; 0) &#123; list.set(k + 1, innerCur); list.set(k, innerLast); &#125; else &#123; break; &#125; &#125; &#125; else &#123; if(!hasSwap) &#123; maxSorted = i; &#125; last = cur; &#125; &#125; j++; &#125; while (maxSorted &lt; list.size() &amp;&amp; hasSwap); &#125;&#125; 对于基本有序的数列，快排的效率是非常低的，相对来说，冒泡的潜力要更高一些，但是冒泡做了很多无用的工作，所以我稍稍改进了一下，每次冒一次泡后，都回头对刚刚换下去的数据进行一下反向冒泡（沉底），这样，每次向上冒一次泡之后，身后的数据都已经是全局有序的了，还有一个优化点，冒泡的时候可以记录下最长未发生交换的位置，应为没有发生过交换，所以这批数据是已经有序的，上面的代码中maxSorted就是用来干这个的，这样下轮冒泡就减少了很多工作。 如果数据基本有序，效率可以逼近O（n），突破排序的算法理论极限了有木有，好了当然不是，算法理论极限是通用情况，这里是基本有序。 但是Java提供的TimSort性能更加优秀。","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"排序","slug":"排序","permalink":"https://www.jelliclecat.cn/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"Java高性能编程串讲-IO读写的那些细节","slug":"Performance-3","date":"2019-09-01T13:44:50.000Z","updated":"2021-06-25T13:47:33.058Z","comments":true,"path":"articles/Java/Performance-3/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/Performance-3/","excerpt":"","text":"〇、前言（碎碎念）磁盘的读写也同样是一个非常容易被忽略的点，在生产环境中也出现过由于磁盘读写代码编写不当造成的线上服务不可用，待会我会讲一下这个案例。磁盘是系统中最慢的IO之一，不当的编码对性能的影响非常大。 磁盘篇一、JVM堆内内存和堆外内存首先讲一下堆外内存，堆外内存是啥呢？比如我们new出来的对象，全部在JVM的堆内存中，我们写的绝大多数程序也都使用的是JVM的堆内存，当然堆内存在JVM中又被划分为很多块（Eden，S1，S2，Old等等），但这不是今天的重点，相信大家对堆内存还是非常熟悉的。那堆外内存是什么呢？就是非JVM管理的内存，是不是很神奇，Java是可以操作JVM内存以外的内存的，通过sun提供的UNSAFE类，可以通过UNSAFE.allocateDirect分配堆外内存（也可以用过ByteBuffer使用堆外内存），之所以叫UNSAFE类，是因为这部分内存需要我们自己管理，JVM不负责这块内存的管理（虽然FullGC对这块内存还是有效的），这块内存需要我们自己清理释放，使用起来没有JVM内存方便，但是堆外内存有非常多的优点是堆内存不具有的，其中非常重要的一点以及使用堆外内存的主要因素就是：堆外内存的IO速度优于堆内存的IO速度，但是缺点就是，分配堆外内存的速度是明显慢于堆内存的。 二、IO读写传统做法试想有这样一个应用：将本地磁盘中的一个文件通过网络发送给客户端。 习惯的想到使用InputStream和OutputStream，首先使用InputStream从本地磁盘读取文件，然后用一个buffer存在内存中，然后用OutputStream把buffer中的数据发送给客户端。 看起来是一个非常自然的过程，我们分析一下这个过程中的一些细节：数据从磁盘到我们的buffer都经历了些什么呢？ 首先，我们调用InputStream的read方法的时候，read方法最终调用了JVM的native方法，而native方法中的read方法最终会调用系统调用read方法（linux自身的read方法），这个系统调用会导致系统从用户态切换到内核态，然后DMA（待会介绍DMA）把数据从磁盘搬到内核内存空间，然后CPU再将内核空间的数据拷贝到堆外用户内存，系统调用到这里结束，接下来的工作要交给JVM，所以需要从内核态切换为用户态，最后CPU还要将堆外内存拷贝进堆内存的buffer中，这时，我们才在buffer中拿到我们从磁盘读取的数据。 上面这个过程非常重要，仔细看一下，我们发现使用InputStream从磁盘中读取数据做了非常多的事情： 一次磁盘读取 两次内存拷贝（内核空间到堆外用户空间，堆外到JVM堆内） 两次系统状态切换 系统转态切换是非常耗时的，需要保存当前转态的上下文，并载入要转换转态的上下文，如果频繁的切换系统转态带来的开销也将非常可观。 到现在数据才读到我们的堆内存中，我们接下来还要将buffer中的数据通过OutputStream发送给客户端，这时我们同样进行了两次内存拷贝（堆内到堆外，堆外到内核空间），两次系统转态切换，以及一次网络IO。所以我们一共进行了4次内存拷贝，4次系统转态切换。 怎么样，是不是贼费事，我们看看有没有改进办法，我们将数据千辛万苦读到buffer中，然后又千辛万苦从buffer中扔给网络IO，其实完全没有必要从内核中读到堆内，这一步是多余的。 mmap为了优化这种情况，linux推出mmap系统调用代替read系统调用，该系统调用会将磁盘中的文件地址映射到内核空间中的地址，然后再将内核空间中的地址映射到用户空间中的一个地址，使得用户空间和内核空间共享一份数据，对于Java来说，JVM还会把堆外的用户空间映射到堆内存中，但是这是JVM的扩展行为，不属于mmap系统调用，所以JVM不是真正的共享，其中还是会发生拷贝。 Java中可以通过FileChannel#map方法调用mmap，通过使用mmap我们再看一下读取数据需要经过哪些过程： 一次磁盘读取 一次内存拷贝（内核空间和堆外用户空间共享了，没有拷贝，JVM从堆外拷贝到堆内） 两次系统状态切换 这样，我们读取数据就节约了一次内存到内存的拷贝，但是发送给网络IO无法使用mmap，仍然需要两次内存拷贝。所以使用mmap代替read之后，我们需要3次内存拷贝，4次系统转态切换。 DMA（插个队）我们继续之前，可以先看一下DMA。DMA（Direct Memory Access，直接内存访问）是个什么东西呢？这个东西就很牛逼了，它是专门用来给内存“搬数据”的，可以称得上是内存专用的数据搬运工。为什么需要它呢，因为CPU忙啊，如果要从磁盘中搬个几百兆的数据到内存中，如果只依靠CPU去寻址，然后去搬数据，那要搬到什么时候啊，况且CPU是个大忙人啊，不能把宝贵的CPU资源用来搬数据，那岂不是太大材小用了，所以就设计了DMA这个东西，DMA是主板上的一个专门的芯片，它也可以对内存以及各种IO设备进行寻址、读数据、写数据，并且效率比CPU还要高，有了DMA的存在，CPU接到一个搬数据的任务的时候，只需要告诉DMA（快给忙人让路，费德罗！），从哪个设备的哪个地址，搬多少数据到哪个设备的哪个地址，一共三个参数，起始地址，数据长度，目标地址，然后DMA会获取一部分的总线控制权（注意是一部分哦，不是独占总线，不然CPU又没事情做了，DMA会和CPU时分复用总线，据一些大神实验，STM32某款CPU是 CPU:DMA 为3:2的比例分配总线占用时间的，不同的设备可能设置不一样吧，但是一定是同时使用的，不是某个设备独占），DMA完成数据搬运工作之后，会给CPU发送中断，通知CPU任务已经完成了。所以前面提到的从磁盘搬数据到内核空间，没错，就是DMA干的。现在的DMA已经更加厉害了，不仅仅能从磁盘搬数据到内存，也能直接作为其他外设IO和内存交换数据的桥梁。 求教DMA与CPU的同时工作问题 sendFile针对这么多的拷贝和系统转态切换，实在繁琐了，能不能进一步优化呢？DMA不正好是干这个的吗？核心思想就是现在不是要把磁盘的数据发送到网络IO吗，那我们直接使用DMA将磁盘的数据搬到内核空间，然后CPU将内核空间中的数据搬到网络IO的buffer中，再使用DMA把数据从buffer搬到网络IO，不就可以了吗？sendFile就这样诞生了，这样，我们只需要一次系统调用，就可以同时完成读写两个功能，这样，我们一共只需要一次内存拷贝，两次转态切换。sendFile的本质其实是直接沟通两个不同的外设IO，通过DMA将内存作为中继站。 Java中也可以使用sendFile，通过FileChannel#transferTo方法。这个方法需要传入另一个FileChannel，意味着将这两个FileChannel链接起来，数据可以在这两个FileChannel中透传。 零拷贝好了，可以说说零拷贝了，刚刚说了，CPU反复在不同的内存空间中来回搬运数据是低效的、不必要的，所以我们希望尽可能的在数据传输过程中，不要出现内存拷贝，这就是所谓的零拷贝，sendFile和mmap都实现了零拷贝，如果直接使用C语言确实就是这样，如果使用Java语言，mmap还是会有一次内存拷贝，堆外用户空间和堆内空间的互相拷贝，而sendFile即使在Java中也是没有内存拷贝的。 三、Java中的优化Java已经对InputStream和OutputStream这些传统IO进行了优化，对于File的读写底层都已经改用了FileChannel，但是我们还是推荐自己使用FileChannel，那样会更加明白一些。 FileChannel还提供了write和read方法，这两个方法底层做了优化，有人测试，这两个方法已经能够满足绝大多数的使用需求了，只有对性能要求极其苛刻的情况下，或者在一些特殊场景下，才用去考虑是否使用map和transferTo方法。 四、总结其实还有一些问题，如果磁盘文件非常大，内存装不下，传统io、mmap、sendfile在Java中会分别怎么表现呢？ 如果使用传统IO读一个内存装不下的文件，会抛出OOM异常（因为你要先new一个buffer啊）。 mmap本质是对地址的映射，当文件过大时，mmap只会将文件的一部分数据映射到内存，当要访问的数据超出范围时，mmap会根据一些算法对内存中的数据和磁盘进行置换，有点类似换页算法。所以不会有OOM异常，但是如果访问文件跨度跳跃很大很频繁的话，mmap的性能会明显下降。 sendFile的话，由于它是直接沟通两个IO，如果内存不够，会分批搬运数据，所以也不会有OOM异常。 sendFile的缺点也非常明显，那就是数据只能透传，不能由程序介入访问数据，因为整个数据的搬运过程全部是在内核态下完成的，如果是透传数据，例如客户端需要下载一个服务器上的文件，那么可以使用sendFile，但是如果程序要对数据进行访问之后再给客户端，sendFile是做不到的。 大家有兴趣可以研究一下市面上流行的消息中间件框架，看看各种不同的框架是如何设计存储结构以及对应使用什么方法读写磁盘的，相信你会有很大的收获。 五、用例分析之前出现一个事情，机器表现如下： 一些普通的接口调用时长突然变长，一个很简单的接口要数秒甚至数十秒的时间才能返回。 CPU比平时稍高，但是不易察觉。 内存占用稳定，没有变化。 ps看了服务进程还在。 业务没有抛出任何异常 到机器上打印一下日志，发现出现了大量的FullGC，由于机器上部署了不止一个服务，所以也没有马上确定内存是否超出JVM的堆内存，但是无疑是由于FullGC引起的服务假死。 看服务log，发现在出现这个现象的时间点上，有用户调用了一些批量下载任务，这个任务会批量返回一批PDF，这些PDF在另外的服务器上，本服务器会先去上游服务上下载这些PDF，然后再打包，最后返回给用户。 由于用户连续点击了几次大规模的下载任务，后端不断下载PDF后，堆内存逐渐消耗殆尽，并触发FullGC，但是FullGC之后又腾出一些空间，然后又下载了数个PDF，然后没过多久又触发了FullGC。 后来同事优化了，原因是同事一直使用的是InputStream将数据读到了堆内存中，用堆内存进行压缩操作，这次的任务量特别的多，超出了堆内存的限制，所以引起了程序的假死。 今天分析之后呢，相信你一定知道了，这个下载任务其实是从一个网络IO到另一个网络IO的数据透传，完全可以使用sendFile，这样，不用担心堆内存不足的问题，也不会引起任何GC，并且效率要高得多。 当然，中间有打包操作，可以借助Java对命令的操作，调用shell命令进行数据打包，中间存一下磁盘，整个过程还是只使用了sendFile以及内核内存空间。 这里JVM参数其实设计的也不合理（使用的是什么收集器我忘了，大概是CMS吧），JVM默认的是在98%的时间内没有释放2%的内存，才会报OOM异常，这里我们应该设置一个FullGC频率参数，超过一定频率就抛出OOM异常，让请求返回。 [参考]（里面有帮助理解的好看的图片，建议大家看看）： java NIO 缓存区之内核空间、用户空间和虚拟地址 sendfile:Linux中的”零拷贝”","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"性能","slug":"性能","permalink":"https://www.jelliclecat.cn/tags/%E6%80%A7%E8%83%BD/"},{"name":"DMA","slug":"DMA","permalink":"https://www.jelliclecat.cn/tags/DMA/"}]},{"title":"Java高性能编程串讲-CPU缓存优化","slug":"Performance-2","date":"2019-09-01T05:13:50.000Z","updated":"2021-06-25T13:47:33.060Z","comments":true,"path":"articles/Java/Performance-2/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/Performance-2/","excerpt":"","text":"〇、前言（碎碎念）上篇讲了内存利用率的问题，但其实Java的内存调优很多时候其实是JVM调优，这个内容也是一个老生常谈的问题了，需要一定的篇幅和案例，之后再讲吧~ CPU篇先看一段代码： 这段代码来自Disruptor，Disruptor是一个基于内存的高性能异步处理框架。这段代码是啥子意思呢？ 这还要从CPU缓存讲起。 假设CPU有三级缓存L1、L2、L3，并且CPU有2个核心，那么，两个核心中都有各自的L1、L2，也就是说不同核心使用的是不同的L1、L2缓存，既然使用了不同的缓存，那肯定就涉及到了数据一致性的问题，这里暂不探讨CPU的数据一致性协议（MESI协议），但一致性协议会带来性能问题，之后会简单介绍一下：伪共享问题。 不同Cache的速度不一样，L1&gt;L2&gt;L3&gt;内存，他们的速度比如下： 当L1miss了之后，会访问L2，如果L2命中，会将L2要访问的数据，以及该数据之后的一部分数据一起加载到L1中来，因为根据程序的局部性原理，该数据周围的数据大概率会在接下来的程序中被访问。 那么一次究竟加载了多大的数据到内存中呢？ 64B，每次从更慢的缓存中都会以64B大小的数据块为单位加载到更快的缓存中。 伪共享问题所谓的伪共享问题，是由于CPU的一致性协议引起的。由于每个CPU核心拥有自己的L1、L2缓存，但是由于数据是以64B为单位从低级缓存中加载过来的，所以，这64B的数据可能同时包含两个不同核心需要访问的数据，那么，当一个CPU核心修改了其中的某些数据，而另一个CPU核心是从自己的缓存中读取数据，那就会出现数据不一致问题。为了让数据保持一致，如果一个CPU核心修改了被共享到不同缓存中的数据，那么所有拥有这块64B数据的缓存就会被通知无效，在下次访问这块数据时，CPU发现这是一块无效数据，就会直接从内存中读取。 由上面的表可以看出，内存的访问速度比L1慢两个数量级，比L3也要慢一个数量级，如果在高并发场景下频繁发生伪共享问题，导致CPU频繁直接从内存中拿取数据的话，就会导致系统性能下降。 有什么好的解决办法没有呢？有，请看文章开头的代码。 1234567891011121314class LhsPadding&#123; protected long p1, p2, p3, p4, p5, p6, p7;&#125;class Value extends LhsPadding&#123; protected volatile long value;&#125;class RhsPadding extends Value&#123; protected long p9, p10, p11, p12, p13, p14, p15;&#125; 这段代码保存了一个long数据并为了避免伪共享做了一件暴力的事情，那就是加入Padding数据，前后各加入了7个long，加上自己前后刚好就是64B的大小，这样就能保证这个long值不与其他的值共享缓存，这样就避免了伪共享问题。但是，避免伪共享并不代表着cache可以100%命中这个数值而不用去访问内存，因为在这个字段自己被并发访问时，仍需要与内存进行数据同步，保证该字段的可见性（该代码中就加入了volatile字段保证了可见性）。 不要混淆伪共享和可见性，伪共享是不同核心访问同一个Cache块中的其他数据引起的缓存失效，而可见性是为了保证不同线程对于同一数据的范围具有数据一致性。说白了，伪共享问题是和自己同一数据块的其他数据被修改引起的，自己是被牵连的，而可见性问题是自己本身被修改了，需要告诉其他可以访问自己的线程，本质上是两个完全不同的问题，只不过现象都是缓存失效。这段代码只是针对解决伪共享问题，对于可见性还是只能老老实实的加上了volatile字段。 番外1，演示一下CPU缓存命中与不命中的性能差异123456789101112131415161718192021222324252627282930313233343536373839404142434445public static int length = 32 * 1024 * 1024;public static long[][] longs;public static void main(String[] args) throws InterruptedException &#123; longs = new long[length][]; for (int i = 0; i &lt; length; i++) &#123; longs[i] = new long[6]; for (int j = 0; j &lt; 6; j++) &#123; longs[i][j] = 1l; &#125; &#125; hitCache(); catchMiss();&#125;/** * 演示缓存命中 */public static void hitCache() &#123; long start = System.currentTimeMillis(); int sum = 0; for (int x = 0; x &lt; length; x++) &#123; for (int y = 0; y &lt; 6; y++) &#123; sum += longs[x][y]; &#125; &#125; System.out.print(&quot;hitCache: &quot;); System.out.println(System.currentTimeMillis() - start);&#125;/** * 缓存位未命中 */public static void catchMiss() &#123; long start = System.currentTimeMillis(); int sum = 0; for (int y = 0; y &lt; 6; y++) &#123; for (int x = 0; x &lt; length; x++) &#123; sum += longs[x][y]; &#125; &#125; System.out.print(&quot;catchMiss: &quot;); System.out.println(System.currentTimeMillis() - start);&#125; 运行结果： 上图中用了6个long去填充一个缓存块（为啥是6个呢？因为还有对象头呀，不过这里代码写错了一点，数组对象头有24B，所以应该只有5个long就可以去填充一个缓存块了，但是没有太大关系，还是可以看出明显的效果）。 是不是很神奇，同一个数组不同的访问顺序，性能上有4倍的差别。 番外2，MESI协议每个64B的缓存块都有一个2bit标志位，用于标识四种状态： modify：当前CPU cache拥有最新数据（最新的cache line），其他CPU拥有失效数据（cache line的状态是invalid），虽然当前CPU中的数据和主存是不一致的，但是以当前CPU的数据为准； exclusive：只有当前CPU中有数据，其他CPU中没有改数据，当前CPU的数据和主存中的数据是一致的； shared：当前CPU和其他CPU中都有共同数据，并且和主存中的数据一致； invalid：当前CPU中的数据失效，数据应该从主存中获取，其他CPU中可能有数据也可能无数据，当前CPU中的数据和主存被认为是不一致的； 对于invalid而言，在MESI协议中采取的是写失效（write invalidate）。 后面具体的情况就不一一分析了，我自己也没有仔细看完（逃 CPU中的cache结构以及cache一致性 总结：今天简单的讲了一下CPU的缓存，告诉大家：Java也是可以做CPU优化的！虽然这种优化只在非常极端的情况下会被用到，但是在今天架构满天飞，中间件崛起的大环境下，Java跟高性能这个话题的关系越来越密切，市面上出现了很多Java的高性能框架，例如netty，netty中也用到了今天讲的优化方法： 12345// InternalThreadLocalMap// Cache line padding (must be public)// With CompressedOops enabled, an instance of this class should occupy at least 128 bytes.public long rp1, rp2, rp3, rp4, rp5, rp6, rp7, rp8, rp9; 这是netty中的一段代码，是不是会心一笑。 如今大量的开源框架都使用netty作为传输层框架，例如hadoop，dubbo等等，netty的性能和可用性都到达了一个巅峰，netty的作者也曾说过：“netty的每一个细节都经过了精心的设计”。 我想说的是，也许作为一名Web工程师，这些优化方法离你非常的远，可能几乎不会用到，你的目光可能更多的集中在SQL的优化或者业务代码上，但是，如果想更近一步做一个架构师，或者中间件专家等等，都需要掌握计算机系统底层原理甚至是硬件原理，以及掌握自己使用的语言是如何与系统相互作用的，并逐渐精通。我自己也在往这方面努力，希望能和大家共同进步。 下一节会介绍一下Java对于磁盘的操作~ 哦对了，你知道为什么说二分法的性能不好了吗？","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"性能","slug":"性能","permalink":"https://www.jelliclecat.cn/tags/%E6%80%A7%E8%83%BD/"}]},{"title":"Java高性能编程串讲-容易忽略的对象头","slug":"Performance-1","date":"2019-08-31T13:45:50.000Z","updated":"2021-06-25T13:47:33.044Z","comments":true,"path":"articles/Java/Performance-1/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/Performance-1/","excerpt":"","text":"〇、前言（碎碎念）哇好久没写博客了，不是我忘了，只是这段时间实在太忙了，再一个也想多积累积累，这样写出来的东西更厚实一点，这段时间看了netty和dubbo的一些源码（当然spring的一些其他的代码也有看），有空给大家分享一下。 这次主要讲下java的性能优化，涉及多线程，内存，磁盘，CPU等，不成体系，都是一些用到的小点，在这里做个记录。 内存篇最近有一个需求，在业务中需要频繁的判断某些用户是否属于活跃用户，并找出非活跃用户，用户用id唯一标识，id是一个long，并且这批用户需要实时更新，因为离当前时间点越近操作过的用户越活跃。 这个问题可以转换为，n个long在内存中实现快速查找，并实现快速更新。 很快就能想到，用一个Set&lt; Long&gt;对所有活跃用户的id进行缓存，Set的查找速度非常之快，并且接口十分方便我们进行查找和添加操作，看起来是一个最优的选择。 真的如此简单吗？这一个学Java半天的程序员也能解决吧？ 当然没这么简单，对于Set来说，如果这批用户量比较小，只有几W，那也没有什么问题，但是活跃用户量可能达到100W级别（数字脱敏），并根据不同的时间尺度数量级会发生很大的变化，时间尺度越大，人数可能更多。那放在Set里面有什么问题呢？ 到linux服务器上，java -version，一般来说现在都是使用64位的JDK，64位的JDK有16B的对象头（数组对象有24B的对象头，多一个字节保存数组长度），HashSet本质上是一个value是一个固定的Object引用的HashMap，HashMap使用的是一个Entry&lt;K, V&gt;[]存储数据，那么100W个数据，就有100W个Entry对象，一个Entry对象占用多少内存呢？看一下源码： 1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; ...&#125; int hash4B K key是一个对于Long的引用，64位下占用8B，同时上面的hash内存对齐，hash实际占用8字节 V value是一个对于Object的引用（见Set源码），占用8字节 next是一个对Node的引用，占用8B long被包装成了Long，占用16B的对象头+8字节的long value 你以为这就完了吗？naive，JDK8之后，hashmap会自动转换成红黑树，所有的Node数据结构也被转为TreeNode，TreeNode继承自LinkedHashMap.Entry，我们来看看这两个东西： 123456789101112131415// LinkedHashMap.Entry static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125; &#125; static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; &#125; 继续来看内存占用情况： before, after两个引用占16B parent, left, right, prev 四个引用占32B red虽然内存边界是对的，但是整体数据结构需要内存对齐，故也占用8B 好来统计一下，Set里面装一个long需要多少字节呢？答案是128B，内存利用率是 8/128 = 6.25%。鼻血是不是都要出来了，那100W个数据需要多少内存呢？就是128MB，这显然是不能接受的。（你硬要说能接受也行8，内存大也没毛病） 好了，那用Set行不通了，怎么办呢，这么多对象头，这么多引用，太浪费了，直接用一个long[]不就搞定了吗？long[]只有一个对象，所以只有一个对象头，要查找的话，100W个数据在内存中二分查找的效率也是非常棒的（稍逊色于HashSet）。其实这已经可以当做是一个可选方案了（后面我们会讨论二分的效率问题），我们只需要8M的内存就解决了问题，并且效率也非常不错，但是添加数据会比较麻烦。 有没有更好的方法呢？仔细审题，我们重点是要找出非活跃用户，但其实这里没那么严格，100W个用户少找出10来非活跃用户个不会有任何区别，基于这个特点，我的脑海中浮现出了一个神奇的算法，叫做布隆过滤器。 布隆过滤器 布隆过滤器的原理大致讲一下，布隆过滤器用一个bit数组存储数据，对于一个加入布隆过滤器的元素，会进过k个哈希函数，然后布隆过滤器把k个散列的结果位都置为1，当要判断一个元素是否在布隆过滤器中时，先对这个元素进行k次散列，然后检查所有的散列结果在bit数组中的值是否全为1，如果都为1，则这个元素可能在布隆过滤器中，如果不都为1，则这个元素一定不在布隆过滤器中。 好了怎么用呢？目前实现比较好的布隆过滤器算法是guava，建议使用27版本以上，因为布隆过滤器一直被标位开发中，但是27版本以上的实现已经相当完备了，例如ThreadSafe和持久化都做了支持。 12private static BloomFilter&lt;Long&gt; BLOOM = BloomFilter.create( Funnels.longFunnel(), 1000000, 0.001); 这段代码的意思是说，预计有100W个元素会进入布隆过滤器，误判率为0.1%，这样，布隆过滤器会根据自身的算法计算出hash函数的最佳个数以及存储需要的bit数组，这里不做推导，虽然我会，嘻嘻~ 1234// 1) Optimal k = b * ln2// 2) p = (1 - e ^ (-kn/m))^k// 3) For optimal k: p = 2 ^ (-k) ~= 0.6185^b// 4) For optimal k: m = -nlnp / ((ln2) ^ 2) k代表hash函数的个数 b代表m/n m bit数组的大小 n 我们传入的100W p 误判率 所以可以直接算出m的大小为不到146W，也就是说，内存占用量只用了1.8MB。并且其写入性能要稍优于HashSet，查询性能也非常快，只计算k个hash函数以及读几个bit位，guava使用的是murmur哈希算法，这个算法目前是性能以及散列效果最好的一个算法，这里不多介绍。 总结：对于Java内存的使用，对象头是一个很容易忽略的细节，对于这种大量小数据结构的数据来说，使用HashSet是非常奢侈的，还有一个点，二维数组也是有n多个对象头的，long[1000][10]这种数组有1000个对象头，并且数组的对象头比非数组要多出8个字节（32位是4个），但是long[10][1000]只有10个对象头。所以这种多维数组还是要悠着点，不然可能连对象头都装不下。 二分法的搜索的性能问题下章会讲。","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"性能","slug":"性能","permalink":"https://www.jelliclecat.cn/tags/%E6%80%A7%E8%83%BD/"}]},{"title":"Java多线程：深入理解volatile关键字以及线程可见性","slug":"volatile","date":"2019-06-14T10:35:50.000Z","updated":"2021-06-25T13:47:33.051Z","comments":true,"path":"articles/MutiThread/volatile/","link":"","permalink":"https://www.jelliclecat.cn/articles/MutiThread/volatile/","excerpt":"","text":"一、volatile关键字我们先看一个例子： 12345678910111213141516171819202122232425262728public class VisableTest &#123; private int weight = 200; public static void main(String[] args) &#123; new VisableTest().test(); &#125; public void test() &#123; Thread A = new Thread(() -&gt; &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; weight = 1; &#125;); Thread B = new Thread(() -&gt; &#123; while (true) &#123; if (weight != 200) &#123; System.out.println(&quot;visable&quot;); break; &#125; &#125; &#125;); A.start(); B.start() &#125;&#125; 结果输出什么呢？答案是什么也不输出。 这涉及到内存可见性的问题。每个线程启动的时候回分配一个”工作空间”，”工作空间”包含一些数据的副本，包括类中的变量等，线程在修改这些数据的时候，修改的是自己”工作空间”中的数据，这些数据什么时候被写回主存取决于JVM，例如上面的例子，在我的本地测试环境，线程A修改的weight = 1，永远不会被写入主存中，所以线程B什么也不会打印。 volatile关键字就是干这个活的： 1private volatile int weight = 200; 在weight前面加上volatile关键字后线程A修改weight的时候，会强制写回主存中，B读取weight的时候也会强制从主存中读取，这样就保证了A修改的weight和B读取的weight是用一份值。 二、 volatile隐患很多专家不建议使用volatile关键字。 初期synchronized性能较差，对于上面代码中的这种情形下，使用synchronized加锁保证可见性会带来很大的性能问题，而且非常大材小用，并且上述代码中没有原子性问题（原子性问题在synchronized和volatile两个关键字中很容易造成疑惑，后面会解释），于是针对这种情况的优化目的，加入了volatile关键字，使得被volatile关键字修饰的变量可以保证可见性。 在现在的JDK版本下（1.6版本synchronized关键字被大幅优化后，以及JUC包的推出），不再推荐使用volatile关键字，因为volatile关键字确实在某种程度上给人造成疑惑。 我认为造成疑惑的罪魁祸首是volatile只提供可见性但是不提供原子性，例如weight++操作会在并发场景下失败，即使weight使用volatile修饰，这是一个经典的例子，weight++实际上是三个操作：取出weight、weight递增、写回weight。这三个操作如果不能够保证原子性，某些线程的操作可能会被覆盖掉，因为某些线程可能读出了正处于修改过程中的weight（发生了脏读，参考事务隔离级别、CAP理论、BASE理论）。锁具有两个主要特性：原子性和可见性，而volatile看起来像半个锁，但是因为volatile足够轻量，性能足够好，这就诱导大家面对并发问题时优先考虑volatile，而同时可见性和原子性是两个复杂的概念，在一个复杂的系统中，即使是一个老手也需要一些时间去分辨某些变量是否需要可见性和原子性，这就极其容易造成volatile关键字的误用和滥用。 推荐的做法（在成为一个真正的高手之前）： 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 也就是说，对于存在竞争的变量，仅当变量的状态与系统中任何变量（包括自己）无关时，可以使用volatile，并只做最简单的赋值和读取。简单说，只在系统标志位中使用volatile变量。 在判断原子性是否需要时，要仔细核对：即使weight=1如此简单的赋值操作也允许被打断去执行其他线程的内容，而不会对系统造成任何影响，那就说明不需要原子性。 如果可见性和原子性都不能确定，但是你还心存担心的话，那么直接使用锁或者原子类去同步吧，这样可以睡个好觉： 12345678910111213141516171819202122232425262728public class VisableTest &#123; private AtomicInteger weight = new AtomicInteger(200); public static void main(String[] args) &#123; new VisableTest().test(); &#125; public void test() &#123; Thread A = new Thread(() -&gt; &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; weight.set(1); &#125;); Thread B = new Thread(() -&gt; &#123; while (true) &#123; if (weight.get() != 200) &#123; System.out.println(&quot;visable&quot;); break; &#125; &#125; &#125;); A.start(); B.start() &#125;&#125; 三 、 结论在使用volatile变量去达到自己想要达到的目的时，必须100%确认你已经明白它会怎样运作，否则还是使用同步锁或JUC包下的原子类代替。 另外，通过上面的分析，其实volatile的适用场景非常的有限，如果在一个系统中发现大量的变量都加上了volatile关键字，那么你要小心了，因为要么volatile被滥用了，要么作者的某些目的无法通过众多的volatile去达到。 如有错误，欢迎指正~","categories":[{"name":"MutiThread","slug":"MutiThread","permalink":"https://www.jelliclecat.cn/categories/MutiThread/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.jelliclecat.cn/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"事务隔离级别、CAP理论、BASE理论","slug":"CAP-BASE","date":"2019-06-11T10:35:50.000Z","updated":"2021-06-25T13:47:33.046Z","comments":true,"path":"articles/DCS/CAP-BASE/","link":"","permalink":"https://www.jelliclecat.cn/articles/DCS/CAP-BASE/","excerpt":"","text":"〇、 ACIDACID是计算机领域一个耳熟能详的术语，讲的是事务的四大特性：原子性（Atomicity），一致性（Consistency），隔离性（Isolation），持久性（Durability）。 1. 原子性指一个事务要么全部成功，要么全部失败，不允许出现中间状态。 2. 一致性指多个事务并发的情景下，系统必须如同串行执行所有的事务一样，不管并发的过程中具体如何调度，最终的结果都应该符合逻辑预期的结果，这个逻辑预期的结果等于串行执行所有事务的结果。 3. 隔离性多个事务并发的环境中，每个事务在执行的生命周期里面，都好像是在独占系统运行，不用的事务之间不会感知到彼此的存在，这种感知指的是数据的变化，即对于每个事务操作的数据，都不会受其他事务操作的影响。 4. 持久性指事务执行完后，该事务对数据的更改便持久存储在数据库中，不会被回滚。 二、 事务隔离级别标准SQL规范中，定义了4个事务隔离级别：Read Uncommitted、Read Committed、Repeatable Read、Serializable，隔离级别严格性从低到高。 说道隔离界别，那就先说说脏读、不可重复读、幻读。 1. 脏读有两个事务：A和B。有数据n=500。 事务B开启事务并Write——n=300 事务A开启事务并Read——n=300 事务B Commit or Rollback 这时候A读到的n=300就是脏读，应为事务B还没有提交，A读到了B还没有提交的数据，这个数据可能被B回滚了，所以可能是一个无效数据，也可能是一个中间数据。 2. 不可重复读有两个事务：A和B。有数据n=500。 事务A开启事务并Read——n=500 事务B开启事务并Write——n=300 事务B Commit 事务ARead——n=300 A在自己的事务周期中连续读了两次n，第一次读取的是500，第二次读取的是300。 注意，不可重复读和脏读的区别在于事务B是否提交，如果B在A第二次读取的时候已经提交了修改，那就是不可重复读，脏读更侧重与读到其他事务还没有提交的数据。 3. 幻读有两个事务：A和B。有数据n0=100，n1=200。 事务A开启并ReadAll——n0=100，n1=200 事务B开启并Write—–n0=100，n1=200，n2=300 事务B Commit 事务A ReadAll——n0=100，n1=200，n2=300 A两次查询得到了新插入的数据，而旧的数据没有被改变。 不同的隔离级别解决了不同的问题： 隔离级别 脏读 不可重复读 幻读 Read Uncommitted √ √ √ Read Committed × √ √ Repeatable Read × × √ Serializable × × × 二、 CAP理论CAP同样指的是三个字母：一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance），CAP理论指的是，一个系统中，不可能同时满足这三个条件。注意这里不需要强调是分布式系统，因为分区容错性就隐喻着系统是分布式系统。 分区容错性是分布式系统的基本特性，指当一个节点挂掉的时候，总是有备用的节点顶替故障节点，继续对外提供服务。分区容错性是分布式系统中不可以放弃的条件，放弃了分区容错性就意味着无法保证系统不间断的提供对外的服务。 可用性是指系统需要在限定时间内返回结果，例如在淘宝上添加一个商品到购物车，网站的期待响应时间是300ms，再例如使用HIVE查询海量数据，一条SQL的查询时间应该在分钟级别。这些服务的响应时间都不应该超过用户的心理预期或者逻辑预期，并且需要返回逻辑正确的结果，这就称之为服务可用。 一致性是指对于不同的子节点，任意一个节点对于数据的修改对其他所有节点都是立刻可见的，也就是说，比如在A节点修改了一条数据，那么B节点应该能马上读到这条修改过的数据。 为什么说这三条不能全部同时满足呢？没有严谨的逻辑证明，我只说说我自己的理解。 首先分区容错性是必须存在的，这是分布式系统的基本特性，必须满足。反过来说（反证法），假设不用保证分区容错性，则系统就是单点系统，虽然不存在一致性的问题，但是单点系统有严重的可用性问题，所以可用性依赖于分区容错性的，换句话说，没有分区容错性就不能保证可用性，所以分区容错性无论如何必须满足。对于一致性和可用性，我们期待对一致性的保证不会对可用性造成影响，但这是不可能的。为了严格保证一致性，节点必须暂停服务，去完成和其他节点的数据同步，这个数据同步工作是同步完成的，同步意味着阻塞（并且阻塞时间是不可预期的），阻塞意味着服务不可用，如果异步同步数据，则无法严格保证数据的一致性，因为异步同步的过程依赖于系统调度，同步数据之前完全可能有数据查询请求打过来。 三、BASE理论如上文说，CAP不可能在一个系统中同时得到保证，但是CAP的每一个条件都是不可以完全放弃的，所以工程师只能在CAP的三个条件中寻找平衡。 分区容错性是没有退路的，所以往往在可用性和一致性之间寻找平衡。这就有了BASE理论。BASE理论指的是： Basically Available （基本可用） Soft State （软状态） Eventually Consistent （最终一致性） 基本可用讲的是分布式系统允许损失部分可用性： 响应时间：正常情况下一个请求的响应时间为200ms，但是少数情况下（节点故障恢复、切换故障节点等情况），响应时间达到了1s，这是还是认为系统可用。 功能损失：例如在电商网站促销高峰，为了保护系统，将部分用户引导到一个降级页面分流，着也可以看做系统基本可用，虽然没有完全满足用户的预期，但是也及时给予用户一个合理的答复。 软状态是指系统允许存在中间状态，但是不影响最终的结果。例如，两个窗口在出售同一张火车票，现在还剩1张，两个窗口看到的余票都是1张，这是有一个窗口已经卖出了这一张火车票，另一个窗口还没来得及更新数据，这时候旅客看到了余票就去购买，但是最终会购买失败。这就是所谓的可以存在中间状态，但是不影响最终结果。 最终一致指的是数据的状态可以在某些时候不一致，但是最终数据都会达到一直。 这篇算是一个铺垫，之后会介绍2PC算法，3PC算法，Paxos算法等。 如果有什么问题，欢迎指出~","categories":[{"name":"DCS","slug":"DCS","permalink":"https://www.jelliclecat.cn/categories/DCS/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://www.jelliclecat.cn/tags/Zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"https://www.jelliclecat.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"spring-beans包源码阅读-4-BeanFactory","slug":"spring-beans-4","date":"2019-06-01T10:16:50.000Z","updated":"2021-06-25T13:47:33.055Z","comments":true,"path":"articles/Spring/spring-beans-4/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/spring-beans-4/","excerpt":"","text":"前置Spring阅读前言-里面讲了一些心路历程 spring-beans包源码阅读-2-BeanWrapper spring-beans包源码阅读-3-BeanDefinition 终于到重点啦！由于BeanFactory太复杂了，这次我们会用单元测试调试跟踪源码。 一. BeanFactory和FactoryBean先聊一聊BeanFactory和FactoryBean，期初我看源码的时候，看到这两个接口真是异常懵逼，他们的方法还很相似，都是获取一个Object。其实这两个接口八竿子打不着，九杆子能打着一点，这里就先讲一讲这两个接口各是干什么的。 1. BeanFactoryspring的总工厂，所有的bean的实例都保存在这个工厂中，并提供了各种不同的方法去获取各种的bean的实例。这个接口没啥好多说的，最核心的接口，等下我们会重点分析这个接口。 2. FactoryBean从名字来看，首先这是一个Bean，然后这是一个工厂，其部分注释如下： 123456789101112131415* If a bean implements this* interface, it is used as a factory for an object to expose, not directly as a* bean instance that will be exposed itself.** &lt;p&gt;&lt;b&gt;NB: A bean that implements this interface cannot be used as a normal bean.&lt;/b&gt;* A FactoryBean is defined in a bean style, but the object exposed for bean* references (&#123;@link #getObject()&#125;) is always the object that it creates.public interface FactoryBean&lt;T&gt; &#123; @Nullable T getObject() throws Exception; ...&#125; FactoryBean才是真正的我们熟悉的”工厂方法模式”，其实命名为Factory会更好，但是在spring中，所有的实体都是Bean，一个Factory也不例外是一个Bean，所以就命名为了FactoryBean。实现了这个接口的类就是一个工厂类，里面需要实现获取具体对象的逻辑。 3. FactoryBean，工厂方法模式这里不会详细介绍什么是工厂模式，因为在进行spring源码阅读的时候会假定已经掌握了各种常用的设计模式。 那么FactoryBean是怎么使用工厂方法模式的呢？ FactoryBean有一个直接实现类：AbstractFactoryBean，里面实现了T getObject() throws Exception方法： 12345678910111213141516171819202122232425/** * Expose the singleton instance or create a new prototype instance. * @see #createInstance() * @see #getEarlySingletonInterfaces() */@Overridepublic final T getObject() throws Exception &#123; if (isSingleton()) &#123; return (this.initialized ? this.singletonInstance : getEarlySingletonInstance()); &#125; else &#123; return createInstance(); &#125;&#125;/** * Template method that subclasses must override to construct * the object returned by this factory. * &lt;p&gt;Invoked on initialization of this FactoryBean in case of * a singleton; else, on each &#123;@link #getObject()&#125; call. * @return the object returned by this factory * @throws Exception if an exception occurred during object creation * @see #getObject() */protected abstract T createInstance() throws Exception; 最后扔给了一个模板方法createInstance()去完成具体的实例的创建工作，这就是一个标准的工厂模式。 二. How getBean() works.BeanFactory接口的集大成者就是DefaultListableBeanFactory，整个Bean的实例化过程、实例化策略等等内容，都在DefaultListableBeanFactory以及其父类AbstractAutowireCapableBeanFactory和AbstractBeanFactory中，故也是我们研究的重点对象。 这个继承关系也是没谁了。。 1. AliasRegistry &amp; SimpleAliasRegistrybean可能有各种别名，这个接口用来提供给一个Bean添加一些别名，并提供根据某个别名查找一个Bean的逻辑。所有的别名引用关系保存在一个map中，取的时候是递归算法： 1234567891011121314// SimpleAliasRegistry.java/** * Transitively retrieve all aliases for the given name. * @param name the target name to find aliases for * @param result the resulting aliases list */private void retrieveAliases(String name, List&lt;String&gt; result) &#123; this.aliasMap.forEach((alias, registeredName) -&gt; &#123; if (registeredName.equals(name)) &#123; result.add(alias); retrieveAliases(alias, result); &#125; &#125;);&#125; 2. DefaultSingletonBeanRegistry提供了保存单例Bean的Map、Set等集合，不仅仅是完全体的Bean，也有正在创建中的Bean，以及Bean之间的依赖关系都在这里。看看这个类的属性，就知道它的功能： 1234567891011121314151617181920212223242526272829303132333435363738/** Cache of singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** Cache of singleton factories: bean name to ObjectFactory. */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/** Cache of early singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);/** Set of registered singletons, containing the bean names in registration order. */private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;&gt;(256);/** Names of beans that are currently in creation. */private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16));/** Names of beans currently excluded from in creation checks. */private final Set&lt;String&gt; inCreationCheckExclusions = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16));/** List of suppressed Exceptions, available for associating related causes. */@Nullableprivate Set&lt;Exception&gt; suppressedExceptions;/** Flag that indicates whether we&#x27;re currently within destroySingletons. */private boolean singletonsCurrentlyInDestruction = false;/** Disposable bean instances: bean name to disposable instance. */private final Map&lt;String, Object&gt; disposableBeans = new LinkedHashMap&lt;&gt;();/** Map between containing bean names: bean name to Set of bean names that the bean contains. */private final Map&lt;String, Set&lt;String&gt;&gt; containedBeanMap = new ConcurrentHashMap&lt;&gt;(16);/** Map between dependent bean names: bean name to Set of dependent bean names. */private final Map&lt;String, Set&lt;String&gt;&gt; dependentBeanMap = new ConcurrentHashMap&lt;&gt;(64);/** Map between depending bean names: bean name to Set of bean names for the bean&#x27;s dependencies. */private final Map&lt;String, Set&lt;String&gt;&gt; dependenciesForBeanMap = new ConcurrentHashMap&lt;&gt;(64); 3. FactoryBeanRegistrySupport这个类提供了对FactoryBean的支持，有一些bean不是直接创建的，而是通过FactoryBean工厂创建的，我们在上文讲过了FactoryBean。这个类的主要功能就是从FactoryBean中调用getObject方法拿到工厂创建出来的实例。 123456789101112131415161718192021222324252627/** * Obtain an object to expose from the given FactoryBean. * @param factory the FactoryBean instance * @param beanName the name of the bean * @return the object obtained from the FactoryBean * @throws BeanCreationException if FactoryBean object creation failed * @see org.springframework.beans.factory.FactoryBean#getObject() */private Object doGetObjectFromFactoryBean(final FactoryBean&lt;?&gt; factory, final String beanName) throws BeanCreationException &#123; Object object; try &#123; if (System.getSecurityManager() != null) &#123; AccessControlContext acc = getAccessControlContext(); try &#123; object = AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) factory::getObject, acc); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; // 就是这句，调用了FactoryBean的getObject()方法，拿到工厂创建的实例。 object = factory.getObject(); &#125; &#125; 很简单的一个类，不多讲了，这个类的代码也很简单，主要做了各种异常控制、权限检查、log打印，真正的关键代码只有object = factory.getObject();这一行。 4. AbstractBeanFactory &amp; AbstractAutowireCapableBeanFactory里面实现了BeanFactory中的核心方法：getBean 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Overridepublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125;/** * Return an instance, which may be shared or independent, of the specified bean. */protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; ... final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between &#x27;&quot; + beanName + &quot;&#x27; and &#x27;&quot; + dep + &quot;&#x27;&quot;); &#125; registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;&#x27;&quot; + beanName + &quot;&#x27; depends on missing bean &#x27;&quot; + dep + &quot;&#x27;&quot;, ex); &#125; &#125; &#125; // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; ...&#125; 前面如果设置了ParentBeanFactory，那么调用ParentBeanFactory去getBean。 先根据beanName拿到RootBeanDefinition，然后递归解析bean的所有依赖，朋友们可以想一下这个过程，最后保证当前所有的依赖都已经创建了，然后开始准备创建当前bean。 可以看到创建bean的工作委托给了createBean，这个方法在子类AbstractAutowireCapableBeanFactory中实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; ... // 真正创建bean的类 Object beanInstance = doCreateBean(beanName, mbdToUse, args); ... &#125; protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; ... // 省略了其他代码 instanceWrapper = createBeanInstance(beanName, mbd, args); populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); ... &#125; /** * Initialize the given bean instance, applying factory callbacks * as well as init methods and bean post processors. * &lt;p&gt;Called from &#123;@link #createBean&#125; for traditionally defined beans, * and from &#123;@link #initializeBean&#125; for existing bean instances. */ protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, &quot;Invocation of init method failed&quot;, ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean; &#125; 这里就非常清晰了： 首先委托给了真正的创建方法：doCreateBean doCreateBean实例化Bean分三步走： doCreateBean中首先调用createBeanInstance实例化Bean，这个时候Bean被实例化了。createBeanInstance中根据各种不同的配置，采用不同的构造函数进行实例化。 doCreateBean中然后调用populateBean方法，改方法将Bean的各种依赖通过BeanWrapper提供的对属性的编辑方法，设置到Bean中。这一步完成了Bean的依赖的组装。 doCreateBean最后调用了initializeBean，意为初始化Bean，这个时候的Bean已经是一个Object实例，并且Bean中通过@Autowire设置的依赖也全部设置完毕。但是最后还有一些初始化工作要做，看代码：首先，如何这个Bean实现了各种Aware接口，则依次调用这些接口的set方法设置信息；然后调用所有的BeanPostProcessors中的Before方法；然后调用通过”init-method”指定的init方法；最后调用所有BeanPostProcessors中的After方法。 最后，这些方法一层一层向上返回了初始化完成的Bean实例。 返回到AbstractBeanFactory中后调用了getObjectForBeanInstance()，检查返回的Bean Instance是否是FactoryBean，如果是，则调用getObject方法获取真正的实例。 创建完后的Bean会放进各种Map中，前面已经讲过了，下次再次getBean的时候，就是从缓存中获取了。 三. 总结我们没有讲Spring是怎么扫描并将各种标注了@Service的Class转换成BeanDefinition的，上面的过程是在所有的BeanDefinition已经生成并存储在内存中之后执行的。BeanFactory有一个实现类叫做XmlBeanFactory，虽然已经被遗弃了，但是里面展示了如何将application.xml中定义的Bean转化成BeanDefinition的过程，这些都不是这篇文章的重点。这篇文章重点讲解了BeanFactory的每一级继承结构，以及调用getBean的时候发生了什么，Bean的实例是如何被创建并返回的，Aware接口是什么时候被调用的。 在代码中我们可以清晰的看到一个bean被初始化的生命周期：实例化-&gt;组装各种依赖-&gt;调用Aware接口方法-&gt;调用BeanPostProcessor的before方法-&gt;指定的”init-method”方法-&gt;调用BeanPostProcessor的after方法。关于生命周期，《Spring In Action》这本书中有详细讲解。 其实到这里spring-beans模块的核心部分就已经讲完了，里面还有一些接口如：Aware、InitializingBean、DisposableBean、BeanReference等，这些都是常用接口，但是这些接口没啥好讲的，都是基于实践意义上的接口。关于RootBeanDefinition和ChildBeanDefinition是如何合并的这里也没有多说，比较简单，基于java的继承和多态机制仿的一个工能，所以也不说了。 之后可能会讲一讲spring-context包和spring-mvc包中的一些常用接口，但是我认为spring的灵魂部分，到这里算是讲完了。 其实究其本质呢，bean的初始化底层依赖两个工具，那就是反射和自省，用反射实例化Bean以及调用一些方法（如init-method），用自省去设置Bean的各种属性。中间做的各种工作，都是对这两个底层调用的封装，BeanWrapper就是对自省功能的封装，BeanDefinition是对Bean的设置，BeanFactory是对反射功能的封装。 除了spring的主体功能之外，还有异常的封装、log的打印等都是值得好好研究和学习的地方，以后有时间我也会给朋友们写一写。 如果文章中有任何不对的地方，请您不吝赐教，也欢迎加我微信交流~","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"}]},{"title":"spring-beans包源码阅读-3-BeanDefinition","slug":"spring-beans-3","date":"2019-05-31T14:16:50.000Z","updated":"2021-06-25T13:47:33.050Z","comments":true,"path":"articles/Spring/spring-beans-3/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/spring-beans-3/","excerpt":"","text":"一. BeanDefinition介绍第二个我们来说说BeanDefinition，这个接口也是spring的核心接口之一，所有的Bean在实例化之前的各种各样的信息都记录在这个接口的实现类中。 Spring中Bean的配置来源可能很多，比如xml、@Service等注解标注的类、以及硬编码等，这时需要一个统一的类去封装Bean的配置信息，这些信息会指导Bean的初始化行为和指明Bean具有的一些特性。这个封装类就是BeanDefinition。 这个接口的位置在spring-beans模块下的org.springframework.beans.factory.config，可以看到这个接口首先在factory包下，然后在config包下。这个位置也是非常合理的，因为BeanDefinition就是在BeanFactory创建Bean实例的时候，记录这个Bean的各种信息用的，比如说Bean的Class信息、是否是单例、是否懒加载、是否是抽象Bean、有哪些属性、有哪些依赖的其他Bean、initMethod的名称等等。这些信息都是用来初始化Bean的实例的时候使用到的。顾名思义的理解就是对一个Bean的定义。 这个类可以说是BeanFactory的一个辅助类，之后可以看到，BeanFactory的各种工作都是围绕着BeanDefinition进行的，也可以说这两个接口是孪生接口，谁也离不开谁。BeanFactory无疑是spring最核心的接口，在我们正式分析BeanFactory之前，先好好看看与它关系密切的BeanDefinition接口。 二. BeanDefinition实现 GenericBeanDefinition是BeanDefinition的一个实现类，与GenericBeanDefinition平级的类还有RootBeanDefinition和ChildBeanDefinition。spring的Bean有一个特性就是可以继承，一个bean可以指明另一个bean做自己的parent，这里要注意，这种方式指明的继承关系在java虚拟机中并不存在，即，如果使用instanceof等RTTI的方式去检验这两个bean的继承关系是失效的，他们只是逻辑上的继承关系并具有一些继承的特性，比如重写和重写父bean的方法和属性等。 BeanDefinition接口的绝大多数功能都在AbstractBeanDefinition中实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// AbstractBeanDefinition.java@Nullableprivate volatile Object beanClass;@Nullableprivate String scope = SCOPE_DEFAULT;private boolean abstractFlag = false;private boolean lazyInit = false;private int autowireMode = AUTOWIRE_NO;private int dependencyCheck = DEPENDENCY_CHECK_NONE;@Nullableprivate String[] dependsOn;private boolean autowireCandidate = true;private boolean primary = false;private final Map&lt;String, AutowireCandidateQualifier&gt; qualifiers = new LinkedHashMap&lt;&gt;();@Nullableprivate Supplier&lt;?&gt; instanceSupplier;private boolean nonPublicAccessAllowed = true;private boolean lenientConstructorResolution = true;@Nullableprivate String factoryBeanName;@Nullableprivate String factoryMethodName;@Nullableprivate ConstructorArgumentValues constructorArgumentValues;@Nullableprivate MutablePropertyValues propertyValues;@Nullableprivate MethodOverrides methodOverrides;@Nullableprivate String initMethodName;@Nullableprivate String destroyMethodName;private boolean enforceInitMethod = true;private boolean enforceDestroyMethod = true;private boolean synthetic = false;private int role = BeanDefinition.ROLE_APPLICATION;@Nullableprivate String description;@Nullableprivate Resource resource; 没必要一个一个解读了，这些属性的作用可以说一目了然，实现中也没有很复杂的逻辑，知道BeanDefinition的作用之后，我们就可以去看spring的核心BeanFactory了~ 当然BeanDefinition的实现类不止文中提到的三种，还有例如对注解支持的实现类和对Configuration类的实现类，但是目的都差不多，都是为了记录一个Bean的各种配置信息。 最后提一嘴这个AttributeAccessor接口，这个接口在Spring中也是无处不在，比如包装一个属性的类PropertyValue类就实现了这个接口。这个接口里面仅仅封装了一个Map&lt;String, Object&gt;，但是其作用是什么我也是不是特别清楚，在调研和学习途中，也比较了”Attribute”这个词和”Property”这两者概念的区别，但是发现google上权威的和非权威的各种解释都有矛盾的地方，甚至在java的官方词库中都没有发现”Attribute”这个词，而只有”Property”，AttributeAccessor接口本身的注释也非常的含糊其辞。所以这个地方的合理性我觉得是存疑的，如果有大佬了解这部分内容的，还请您不吝赐教。 Java官方词库：Glossary of Terms 其中对Property的解释如下： property Characteristics of an object that users can set, such as the color of a window.","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"}]},{"title":"spring-beans包源码阅读-2-BeanWrapper","slug":"spring-beans-2","date":"2019-05-31T10:16:50.000Z","updated":"2021-06-25T13:47:33.053Z","comments":true,"path":"articles/Spring/spring-beans-2/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/spring-beans-2/","excerpt":"","text":"一. BeanWrapper12345678910111213141516171819202122/** * The central interface of Spring&#x27;s low-level JavaBeans infrastructure. * * &lt;p&gt;Typically not used directly but rather implicitly via a * &#123;@link org.springframework.beans.factory.BeanFactory&#125; or a * &#123;@link org.springframework.validation.DataBinder&#125;. * * &lt;p&gt;Provides operations to analyze and manipulate standard JavaBeans: * the ability to get and set property values (individually or in bulk), * get property descriptors, and query the readability/writability of properties. * * &lt;p&gt;This interface supports &lt;b&gt;nested properties&lt;/b&gt; enabling the setting * of properties on subproperties to an unlimited depth. * * &lt;p&gt;A BeanWrapper&#x27;s default for the &quot;extractOldValueForEditor&quot; setting * is &quot;false&quot;, to avoid side effects caused by getter method invocations. * Turn this to &quot;true&quot; to expose present property values to custom editors. * */public interface BeanWrapper extends ConfigurablePropertyAccessor &#123; ...&#125; 简单翻译一下： Spring底层架构的核心接口。 主要用在BeanFactory中，而不是直接使用 提供了分析和操控标准JavaBean的操作： get和set一个property的能力，获取一个property的descriptors，以及查询properties是否可以读写。 … 从第一句话就知道，这是一个非常重要的接口，被描述为”Spring底层架构的核心接口”，可想而知其重要程度。这个接口做的事情也解释的很清楚了。BeanWrapper还继承和间接继承了很多其他的接口，之后一一解读。 这个接口有一个直接实现类：BeanWrapperImpl.java，我们直接去看这个类吧。 二. BeanWrapperImpl还是先看注释： 1234567891011121314/** * Default &#123;@link BeanWrapper&#125; implementation that should be sufficient * for all typical use cases. Caches introspection results for efficiency. * ... ... /** * Create a new BeanWrapperImpl for the given object. * @param object object wrapped by this BeanWrapper */ public BeanWrapperImpl(Object object) &#123; super(object); &#125; BeanWrapper的一个默认实现，可以满足所有的典型使用情形，缓存了自省结果。 一开头就告诉你了，这个类是一个完备的实现类，感觉spring得开发者已经在心中悄悄的给这个类标上了final，当然处于严谨没有这么做。而且构造函数也非常简单，就是传入一个实例（还有其他构造函数）。 既然这个类实现了绝大部分的功能，我们就仔细的看看这个类吧： 首先我们看继承结构。 顶级接口有三个： PropertyAccessor PropertyEditorRegistry TypeConverter 这里简单解释一下，感兴趣的朋友可以自行研究。 1. PropertyAccessor顾名思义，提供了对Bean的Property的set和get的方法，其实还有很丰富的方法，比如批量set和get属性，获取一个属性的读写权限信息，获取某个属性的类型或者类型描述（TypeDescriptor：Context about a type to convert from or to.）等方法。 2. PropertyEditorRegistry修改一个property属性不是我们自己动手修改的，而是通过PropertyEditor接口，这个接口是java.beans包下的标准接口，这个接口用来修改一个bean的特定属性。java.beans包下提供了一批默认的PropertyEditor的实现，用来修改一些常见类型的属性，比如int，List等等，而PropertyEditorRegistry接口的作用，就是让我们可以注册自定义的PropertyEditor，让spring知道对于特定的类型的属性，去调用那个PropertyEditor进行具体的操作。 3. TypeConverter对类型转换的支持，比如我设置一个属性，但是传入的类型和属性的类型不匹配，怎么办呢？那就进行类型转换，其实常见的类型转换有很多，比如String.valueOf就是讲一个其他类型的变量转换成String类型的方法。当然，可以预计有很多复杂的和自定义的不同类型之间的转换，那就是通过这个接口去实现。 到这里其实就已经能够知道BeanWrapper的主要作用了，那就是将一个Bean包起来，然后去set和get它的各种属性。 要注意的是，BeanWrapper对象的内部没有保存bean的属性的字段，最初我以为bean的属性会以一个map的形式存在BeanWrapper中，然后需要操作那个具体的Property就去根据这个Property的名字去get，其实不是的，所有的bean的信息在后来转换成了CachedIntrospectionResults对象： 123456789public class BeanWrapperImpl extends AbstractNestablePropertyAccessor implements BeanWrapper &#123; /** * Cached introspections results for this object, to prevent encountering * the cost of JavaBeans introspection every time. */ @Nullable private CachedIntrospectionResults cachedIntrospectionResults; 这个对象里面保存了一个static Map，缓存了所有的Class自省的结果： 1234567891011public final class CachedIntrospectionResults &#123; ... /** * Map keyed by Class containing CachedIntrospectionResults, strongly held. * This variant is being used for cache-safe bean classes. */ static final ConcurrentMap&lt;Class&lt;?&gt;, CachedIntrospectionResults&gt; strongClassCache = new ConcurrentHashMap&lt;&gt;(64); ...&#125; 每个CachedIntrospectionResults对象里面又有以下属性： 12345678/** The BeanInfo object for the introspected bean class. */ private final BeanInfo beanInfo; /** PropertyDescriptor objects keyed by property name String. */ private final Map&lt;String, PropertyDescriptor&gt; propertyDescriptorCache; /** TypeDescriptor objects keyed by PropertyDescriptor. */ private final ConcurrentMap&lt;PropertyDescriptor, TypeDescriptor&gt; typeDescriptorCache; 这些属性保存了BeanWrapper包装Bean的BeanInfo、PropertyDescriptor、TypeDescriptor，这些信息就是Bean的自省结果。所有对Bean的属性的设置和获取最后都是通过CachedIntrospectionResults获取的。CachedIntrospectionResults在BeanWrapper中是懒加载的，在用户真正去调用Bean的相关信息的时候才去创建CachedIntrospectionResults。懒加载也是Spring的一贯作风。 三. PropertyEditorRegistrySupport为了进一步理解BeanWrapper中有哪些东西，我们再看看上层的一些实现类，里面做了一些什么： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public class PropertyEditorRegistrySupport implements PropertyEditorRegistry &#123; @Nullable private ConversionService conversionService; private boolean defaultEditorsActive = false; private boolean configValueEditorsActive = false; @Nullable private Map&lt;Class&lt;?&gt;, PropertyEditor&gt; defaultEditors; @Nullable private Map&lt;Class&lt;?&gt;, PropertyEditor&gt; overriddenDefaultEditors; @Nullable private Map&lt;Class&lt;?&gt;, PropertyEditor&gt; customEditors; @Nullable private Map&lt;String, CustomEditorHolder&gt; customEditorsForPath; @Nullable private Map&lt;Class&lt;?&gt;, PropertyEditor&gt; customEditorCache; ... /** * Actually register the default editors for this registry instance. */ private void createDefaultEditors() &#123; this.defaultEditors = new HashMap&lt;&gt;(64); // Simple editors, without parameterization capabilities. // The JDK does not contain a default editor for any of these target types. this.defaultEditors.put(Charset.class, new CharsetEditor()); this.defaultEditors.put(Class.class, new ClassEditor()); this.defaultEditors.put(Class[].class, new ClassArrayEditor()); this.defaultEditors.put(Currency.class, new CurrencyEditor()); this.defaultEditors.put(File.class, new FileEditor()); this.defaultEditors.put(InputStream.class, new InputStreamEditor()); this.defaultEditors.put(InputSource.class, new InputSourceEditor()); this.defaultEditors.put(Locale.class, new LocaleEditor()); this.defaultEditors.put(Path.class, new PathEditor()); this.defaultEditors.put(Pattern.class, new PatternEditor()); this.defaultEditors.put(Properties.class, new PropertiesEditor()); this.defaultEditors.put(Reader.class, new ReaderEditor()); this.defaultEditors.put(Resource[].class, new ResourceArrayPropertyEditor()); this.defaultEditors.put(TimeZone.class, new TimeZoneEditor()); this.defaultEditors.put(URI.class, new URIEditor()); this.defaultEditors.put(URL.class, new URLEditor()); this.defaultEditors.put(UUID.class, new UUIDEditor()); this.defaultEditors.put(ZoneId.class, new ZoneIdEditor()); // Default instances of collection editors. // Can be overridden by registering custom instances of those as custom editors. this.defaultEditors.put(Collection.class, new CustomCollectionEditor(Collection.class)); this.defaultEditors.put(Set.class, new CustomCollectionEditor(Set.class)); this.defaultEditors.put(SortedSet.class, new CustomCollectionEditor(SortedSet.class)); this.defaultEditors.put(List.class, new CustomCollectionEditor(List.class)); this.defaultEditors.put(SortedMap.class, new CustomMapEditor(SortedMap.class)); // Default editors for primitive arrays. this.defaultEditors.put(byte[].class, new ByteArrayPropertyEditor()); this.defaultEditors.put(char[].class, new CharArrayPropertyEditor()); // The JDK does not contain a default editor for char! this.defaultEditors.put(char.class, new CharacterEditor(false)); this.defaultEditors.put(Character.class, new CharacterEditor(true)); // Spring&#x27;s CustomBooleanEditor accepts more flag values than the JDK&#x27;s default editor. this.defaultEditors.put(boolean.class, new CustomBooleanEditor(false)); this.defaultEditors.put(Boolean.class, new CustomBooleanEditor(true)); // The JDK does not contain default editors for number wrapper types! // Override JDK primitive number editors with our own CustomNumberEditor. this.defaultEditors.put(byte.class, new CustomNumberEditor(Byte.class, false)); this.defaultEditors.put(Byte.class, new CustomNumberEditor(Byte.class, true)); this.defaultEditors.put(short.class, new CustomNumberEditor(Short.class, false)); this.defaultEditors.put(Short.class, new CustomNumberEditor(Short.class, true)); this.defaultEditors.put(int.class, new CustomNumberEditor(Integer.class, false)); this.defaultEditors.put(Integer.class, new CustomNumberEditor(Integer.class, true)); this.defaultEditors.put(long.class, new CustomNumberEditor(Long.class, false)); this.defaultEditors.put(Long.class, new CustomNumberEditor(Long.class, true)); this.defaultEditors.put(float.class, new CustomNumberEditor(Float.class, false)); this.defaultEditors.put(Float.class, new CustomNumberEditor(Float.class, true)); this.defaultEditors.put(double.class, new CustomNumberEditor(Double.class, false)); this.defaultEditors.put(Double.class, new CustomNumberEditor(Double.class, true)); this.defaultEditors.put(BigDecimal.class, new CustomNumberEditor(BigDecimal.class, true)); this.defaultEditors.put(BigInteger.class, new CustomNumberEditor(BigInteger.class, true)); // Only register config value editors if explicitly requested. if (this.configValueEditorsActive) &#123; StringArrayPropertyEditor sae = new StringArrayPropertyEditor(); this.defaultEditors.put(String[].class, sae); this.defaultEditors.put(short[].class, sae); this.defaultEditors.put(int[].class, sae); this.defaultEditors.put(long[].class, sae); &#125; &#125; ... @Override public void registerCustomEditor(Class&lt;?&gt; requiredType, PropertyEditor propertyEditor) &#123; registerCustomEditor(requiredType, null, propertyEditor); &#125; ... &#125; 首先简单粗暴的加载了各种默认的PropertiesEditor以及Spring自己实现的一些PropertiesEditor，然后最用户自定义的PropertiesEditor做了支持。所有的PropertiesEditor都保存在Map中，用的时候根据不同的Class去查询对应Class的PropertiesEditor。 四. TypeConverterSupport使用了委托模式，将所有的TypeConvert请求都委托给了真正进行类型转换的类TypeConverterDelegate，而TypeConverterDelegate的转换请求最终又由一个ConversionService去实现，ConversionService也只是一个管理类，并没有做真正的类型转换操作，最最最终的类型转换，交给了负责各种类型互相转的Converter，这些Converter实现了GenericConverter接口，感兴趣的可以仔细阅读一下这部分代码，这部分代码位于spring-core模块下的org.springframework.core.convert包中，里面包含了大量spring已经编码好的Converter。 总之这里就是对不同类型的互相转换做支持。 五. AbstractNestablePropertyAccessor最后讲一下AbstractNestablePropertyAccessor这个类，这个类完成了非常多的BeanWrapper功能，但是主要是对嵌套类的属性操作做支持。 AbstractNestablePropertyAccessor内部持有一个 private Map&lt;String, AbstractNestablePropertyAccessor&gt; nestedPropertyAccessors; 理解这个是理解AbstractNestablePropertyAccessor的关键。 例如有以下的类型： 123456789class bean &#123; private A a; get() &amp; set()&#125;class A &#123; private String name; get() &amp; set()&#125; 那么，bean对应的AbstractNestablePropertyAccessor内部的nestedPropertyAccessors就有一个： a -&gt; AbstractNestablePropertyAccessor of class A 的map entry。 假设AbstractNestablePropertyAccessor of class A 的实例名称是nestablePropertyAccessorOfA，那么nestablePropertyAccessorOfA内部的nestedPropertyAccessors就有一个： name -&gt; AbstractNestablePropertyAccessor of class String 的map entry。 所以Bean中类型的嵌套和AbstractNestablePropertyAccessor中nestedPropertyAccessors的嵌套是一一对应的。 AbstractNestablePropertyAccessor有一个字段nestedPath，它表示对于一个嵌套属性的路径，比如在上例中，class A的name属性在class Bean中被表示为：a.name，那么如何拿到最name属性的PropertyAccessor呢？ 12345678910111213141516171819/** * Recursively navigate to return a property accessor for the nested property path. * @param propertyPath property path, which may be nested * @return a property accessor for the target bean */ @SuppressWarnings(&quot;unchecked&quot;) // avoid nested generic protected AbstractNestablePropertyAccessor getPropertyAccessorForPropertyPath(String propertyPath) &#123; int pos = PropertyAccessorUtils.getFirstNestedPropertySeparatorIndex(propertyPath); // Handle nested properties recursively. if (pos &gt; -1) &#123; String nestedProperty = propertyPath.substring(0, pos); String nestedPath = propertyPath.substring(pos + 1); AbstractNestablePropertyAccessor nestedPa = getNestedPropertyAccessor(nestedProperty); return nestedPa.getPropertyAccessorForPropertyPath(nestedPath); &#125; else &#123; return this; &#125; &#125; 就在这段代码中，这段代码递归的解析propertyPath，每层递归都返回外层嵌套的AbstractNestablePropertyAccessor，直到拿到最里面的属性，这里，当我们传入propertyPath = “a.name”时，先回拿到属性a对应的AbstractNestablePropertyAccessor，然后调用属性a的AbstractNestablePropertyAccessor去查找”name”属性，最终返回的是”name”属性对应的AbstractNestablePropertyAccessor。 AbstractNestablePropertyAccessor这个类理解起来稍复杂一些，关键是理解如果Bean的属性是其他Bean的情况下，如果去处理。 六. 简单的总结BeanWrapper的初始化流程： 传入一个实例 -&gt; 将registerDefaultEditors设置为true，表示要注册默认的PropertyEditors -&gt; 然后调用setWrappedInstance： 123456789101112131415161718192021222324252627// AbstractNestablePropertyAccessor.javapublic void setWrappedInstance(Object object, @Nullable String nestedPath, @Nullable Object rootObject) &#123; this.wrappedObject = ObjectUtils.unwrapOptional(object); Assert.notNull(this.wrappedObject, &quot;Target object must not be null&quot;); this.nestedPath = (nestedPath != null ? nestedPath : &quot;&quot;); this.rootObject = (!&quot;&quot;.equals(this.nestedPath) ? rootObject : this.wrappedObject); this.nestedPropertyAccessors = null; this.typeConverterDelegate = new TypeConverterDelegate(this, this.wrappedObject); &#125;// BeanWrapperImpl.java@Overridepublic void setWrappedInstance(Object object, @Nullable String nestedPath, @Nullable Object rootObject) &#123; super.setWrappedInstance(object, nestedPath, rootObject); setIntrospectionClass(getWrappedClass()); &#125; /** * Set the class to introspect. * Needs to be called when the target object changes. * @param clazz the class to introspect */protected void setIntrospectionClass(Class&lt;?&gt; clazz) &#123; if (this.cachedIntrospectionResults != null &amp;&amp; this.cachedIntrospectionResults.getBeanClass() != clazz) &#123; this.cachedIntrospectionResults = null; &#125; &#125; AbstractNestablePropertyAccessor中，设置了各种基本的bean的信息，并初始化了TypeConverterDelegate，BeanWrapperImpl中重写了父类AbstractNestablePropertyAccessor中的setWrappedInstance方法，并多了一个操作就是调用setIntrospectionClass。到这里初始化就完成了。 然后再调用convertForProperty、getLocalPropertyHandler、getPropertyDescriptors、getPropertyDescriptor这四个方法中的一个时，对包装的bean进行自省，创建CachedIntrospectionResults并缓存下来。 BeanWrapper主要封装了对一个Bean的属性的操作。 有不对的地方，欢迎指正~","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"}]},{"title":"spring-beans包源码阅读-1-源码导读","slug":"spring-beans-1","date":"2019-05-31T09:16:50.000Z","updated":"2021-06-25T13:47:33.054Z","comments":true,"path":"articles/Spring/spring-beans-1/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/spring-beans-1/","excerpt":"","text":"前言-如何阅读Spring源码想想大概是去年这个时候clone的spring-frameword工程，到现在整整一年了，起初功力太弱，实在是读不了spring，现在算是功力有所精进，期间断断续续也把Spring的工程打开浏览过几次，但是都只是粗略的走读，一方面刚刚说了，功力不够，另一方面，也是自己心浮气躁，沉不下心来，再加上spring代码层次之复杂，如果不仔细分析琢磨，那就更不可能读懂了。 要说为什么要读Spring呢，其实我给的答案比较简单，就是好奇，想知道它是怎么做的，因为已经工作了，所以没有应付面试官这种需求了。当然如果抱着功利的心态去读也是没有错的，因为读源码这件事本身就可以从中获取大量的知识，包括比较基础的语言知识也好，或者是框架设计层面的也好，而且读这些高难度的源码也能够提升我们的视野，让我们不局限在工作的crud + html中，毕竟如果想成为一名优秀的工程师甚至是架构师，宏观框架的设计能力也是必须有的，而且就目前来说，spring几乎成为了行业标准，市面上很多其他的框架都是基于spring做的扩展，或者至少也做到和spring兼容，比如dubbo等等，更不用说spring cloud这一个超大社区，里面包含了大量的分布式框架，无一不对spring做了兼容。所以想在java道路上走的更远，精通spring是绕不开的一个节点。 Spring优秀吗？当然优秀了，曾经看到一些对spring的质疑，觉得spring有过度设计的嫌疑，这点我本人暂时保留态度，因为我代码还没读完呢，没有发言权。但以一个社区的力量，做到现在成为行业标准（准标准吧）相比也不是等闲之辈，怀着一些谦卑的态度去看待的话，我觉得我还是能学到不少东西的。 前段时间算是仔细阅读了一部分，这里也算是做个记录，记录一下阅读过程中的一些小小心得，对自己也算是一种监督，如果有幸一字半句还能帮助到来访的人，那也算是我的荣幸。 Spring算是大工程，60W行代码（包含测试代码），想要阅读起来绝对不轻松。怎么入手呢？首先好好掌握java基础知识，其中反射和自省机制是重中之重，然后要掌握设计模式以及设计模式的各种理念和原则，这是整个Spring的重要脉络。如果掌握了这些，那么可以开始阅读Spring了。 但是读源码也有技巧，愣看也不行，得有方法。首先需要从spring-beans这个包入手，这个包是spring的核心，如果说spring只能选一个必看的包那就是这个了，这个包中定义了spring的核心逻辑，那就是bean以及factory，里面一切的内容都是围绕着这两个概念进行的。 看源码环境不能少，建议使用IDEA阅读，具体构建步骤不再赘述，github上写得很明白。从哪入手呢？建议先把所有的Interface看一遍，并仔细阅读每个interface上的注释，这样至少会对整体的架构和最抽象的设计有一个模糊的印象，并且在阅读的过程中，自然就能发现哪些接口是核心接口。看完接口之后，就可以看看一些核心接口的具体实现了，既要有细读，也要有宏观的理解，还要有Test的调试。 熟悉Spring的朋友肯定知道，BeanFactory、BeanDefinition、BeanWrapper算的上是这个包乃至整个spring的核心接口。我也打算先这几个接口，以及如何实现开始说起。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"}]},{"title":"思考，2018 年总结，2019 年目标","slug":"aim","date":"2019-05-30T14:16:50.000Z","updated":"2021-06-25T13:47:33.059Z","comments":true,"path":"articles/Summary/aim/","link":"","permalink":"https://www.jelliclecat.cn/articles/Summary/aim/","excerpt":"","text":"0. 2018从2018年4月1日正式开始工作，到现在已经有14个月了，14个月前，自己还是一个java小白，那个时候，java语法还只会流程控制语句，面向对象思维一点没有，OOP更是谈不上，对于框架，到是听过大名鼎鼎的spring，但也只会使用@Autowired和@Service。实习第一个星期，leader让我做一个BookManager系统，使用的框架是Spring、paoding-rose（web）、paoding-jade（持久层），paoding框架是原人人网的框架，以后有机会详细介绍一下，个人认为paoding-jade算是一款非常简单易用的持久层框架。最开始虽然啥也不会，但是依葫芦画瓢的水平还是有的，大致看看leader写的几个样例，自己照着写一下，debug一下，最后三天的时间差不多搞定了。短短三天，我依稀觉得自己跨入了一道门槛。这三天时间，安装intellij、nginx、mysql、maven等等环境，并动手写了一个小项目，从数据库的crud到velocity的模板渲染，算是入门了吧！对于基础薄弱的自己，实习期的表现应该还是基本合格的吧，这也得益于大学写了不少C++。但是合格与优秀之间差了十万八千里地，当然，这是之后感觉到的，毕竟菜鸡对自己的菜的认识也是有限的。 随着业务项目的慢慢深入，也随着自己渐渐进入”java研发工程师”这样一个角色，对自己的不足也认识得越来越清晰。虽然框架基本会用了，开发新的业务也没有问题，但是要问一句我是谁，那无疑是灵魂的拷问，crud + html填空，谁上都行，我的价值在哪里呢？我觉得我的水平应当远不限于此。 在2018年6月份，我clone了spring的framework，最后证明，走出这一步的意义不关乎于我对spring的理解，而在于我走上了技术探寻的道路。读源码无疑是枯燥的，煎熬的，并且后来发现，还是需要技术的。无疑，才接触java不到3个月的我，是看不懂spring的源码的，一个模块也看不懂，但这无疑也是一件好事，因为它让我变得”不舒适”。 “不舒适”的好处就是告诉你，你很菜，这句话你的同事不会说，你的爸爸妈妈会告诉你你很棒，你的朋友会羡慕你高工资，你的女朋友会让你relax，但是优秀的源码会告诉你，你就是个菜鸡，连我在干嘛都不知道。从那时候开始，我发现优秀的源码和书籍十分的重要，他们会时刻告诉你你有多菜，你有多少东西不知道。 大跃进式的学习是无效的，如果连OOP思维萌芽都没有，连java一些基础语法和特性都没有办法完全理解，连java基础类库的全部用法都不能掌握，拿什么东西去看spring呢，浪费时间罢了。这时候才能开始体会到大牛们常常挂在嘴边的那句，基础最重要。 大概7月到11月的时间，开始回头看一些经典的书籍，《java编程思想》，《设计模式》是这段时间重点学习的两本书籍。对《java编程思想》这本书的评价总是褒贬不一，现在来说，这本书绝对不是入门书籍，以前我记得有老师教我们，”看计算机的书有不懂的没关系，看到后面自然就懂了”，这句话同样不适用于《java编程思想》，如果前面有地方没有搞懂，我保证，看到后面不懂的只会变多，而不是变少。这本书是一本宏观的杂谈，没有很规整的基础知识点的罗列，没有由浅入深的节奏，它不会语重心长、郑重其事的讲解这些知识，而是以一种更高层次的态度平等的去阐述java的各种特性。《java编程思想》适合已经具备一定java基础的人去弥补自己的不足，适合在初学java的时候反复观看。《设计模式》我看的是head first的版本，这本书非常棒，目前来说，是对我提升最大的一本书，它使我开始转变java的编程思维，当然是变成OOP的思维，里面讲述了如何使用设计模式去增强复用以及提升系统的扩展性和稳定性，里面讲述了几点设计原则，这些原则应该算是OOP的精华，就像牛顿三定律在力学的地位一样。在学习完这两本书籍之后，完成了一个小的分页模块，里面使用了一些OOP的思维，使用了接口和继承，使用了模板方法模式和工厂模式。让我对OOP有了更深刻的理解。 当然，java相关的知识不是一个计算机从业者需要唯一关心的，很多计算机的基础理论会极大的丰富你解决问题的思维。去年五月份，我在一个独立工程里面使用了流水线模型，完成了一个高性能高可靠性的异步任务系统。由于需求的特殊，每一个task必须独占系统的所有资源，用来公平的对task的性能做评估，所以核心步骤必须是单线程的，这就像极了CPU，CPU不也是采用流水线架构来提升单核吞吐量的吗，受这点的启发，除了独占系统的那部分时间外，其他的工作例如前期的task初始化、远程获取、垃圾清理等等步骤都可以使用不同的流水线去完成，不同流水线之间使用一个线程安全的队列去同步，这样，即避免了多线程并发带来的系统复杂度飙升，也极大的提升了系统的吞吐量，由于系统天生线程安全，又极大保证了系统的稳定性。现在看来，这并不是一个了不起的工作，但是重点是，在我还不会java并发技术时，传统的一些计算机思维和算法仍然能够给予我极大的帮助。这个例子表明，活跃的思维和汲取灵感的能力也非常重要，要随时避免思维僵化。 2018年大概10月期间，接到一个调研数据平台的任务，与其说是调研，不如说是学习。java的家族之大，生态之活跃完全超乎我的想象，调研持续了1周，从Hadoop到Hbase再到Sqoop，从自己编译Hadoop到部署一个小的集群做MR计算，完全颠覆了我的视野，原来java可以干这么多事情。 在这期间，我还看了《Spring In Action》英文版，不得不说，这对于我的英文阅读水平有非常大的提升，读英文书籍确实比那些翻译稀烂的中文技术书要舒服得多，当然，通过这本书使我对Spring也有了一个更全面的了解。 2018年12月和2019年2月，可以算作”失去的三个月”，这三个月里面，似乎是误入了歧途。最近盛起的机器学习大潮冲昏了我的头脑，大学期间，我就十分痴迷于神经网络算法，那种痴迷就像是发现了神迹一般。机器学习的盛起让我动摇了，我把公司的《深度学习》带回了家，从家里寄来了《机器学习》和《统计学习方法》，在原本属于java的时间里面，研究起了机器学习、python、吴恩达的课程，甚至一度萌生了考研究生的念头。这期间的我是迷失的，拿不定方向的，一方面是算法，一方面是工程。等头脑渐渐清醒的时候，发现自己不可能是那个可以用算法改变世界的人，机器学习在现阶段也要落地到具体工程上。回头望向好久没有精进的java，还好它还在等我，魅力不减当年。当然，这段经历也不是全然没有帮助，首先它帮助我明确了目标，其次它提供了一种更加数学的和更加形式化的方式去看待计算机问题。 2019年3月到现在，重振旗鼓之后，算是踏踏实实的去好好学习了一下java，期间也深入看了不少框架。比起60W行的spring和5W行的mybatis，我仔仔细细的阅读完了paoding-jade框架，这个框架很小巧，完全基于spring对jdbc的支持和动态代理完成的一个持久层框架，框架一共不到5K行，麻雀虽小五脏俱全，核心思路就是使用动态代理，创建各种interface的代理类，然后解析注解里面的sql语句，扔进spring的JdbcTemplate执行，最后将结果使用自定义的RowMapper去解析。大致用法和Mybatis的注解用法差不多，但是简洁很多，比如对”in”的支持和一些动态表达式的支持等等。之后又阅读了部分paoding-rose框架，个人感觉这个框架过分强调了模型而在某种程度上忽略了功能，感觉比较臃肿，所以放弃了，但是核心思路看到了，debug也不成问题，我觉得到这个程度就可以了，rose基于filter去拦截请求而不是servlet的思路让我觉得非常新颖，”约定大于配置”的信条也非常前卫（应该是来自于ruby on rails）。除了这些框架以外，我还看了Jedis的部分源码，Jedis算是一个简单粗暴的框架，里面主要封装了和redis的通信，以及pool，比较深入的用法还没有来得及研究。Spring仔细阅读了bean部分的代码还有很多其他代码。哦，对了，WebMagic这个爬虫框架也完全阅读过了，并做了一些自己的扩展。仔细的阅读完了ThreadPoolExecutor的源码和BlockingQueue的源码，对并发的技术提升不少。自己尝试写了一个封装阿里云TableStoreSDK的持久层框架，用jade的思路，It works，很开心，对Class、动态代理以及反射技术掌握了很多。 2018年由于业务需要，还学习了一段时间的Ruby，这个语言真的花里胡哨的，语法糖巨多，个人不太喜欢，但是做到了基本能读懂它在干什么。也学习了Python，感觉python是不能够做工程的，给人的感觉没有java严谨，写写脚本那真的非常棒。node.js对我算是一次颠覆，它在对那种高并发的轻量请求比java来的容易的多，因为它是基于异步事件驱动的语言，而且启动快，去年有一个小服务我就是用node.js做的。之后有空可以看看Golang，了解一些其他语言的理念也是很棒的事情。 目前在看dubbo框架，这个框架真是一想之美，又勾勾又丢丢。我想我们的架构离进一步的微服务化也不远了。 硬要做一个总结的话，踏实不足浮躁有余，很多东西掌握得都还非常的表面，比如Spring框架的阅读，还有很多代码下载了都只是瞟了一眼，要弄清工作、学习、女朋友、身体这四者的关系也着实不容易。总之2018年到现在有失去的，有得到的，更多的应该还是得到的。要说不满意的地方，那就是学习效率和学习深度。 1. 2019其实现在已经过去5个月了，但是考虑到2018年四月才入职，算了，就不在意这些细节了，争取明年的总结时间提到1月份。 那2019的计划当然也是剩下的7个月里的计划。 接下来的7个月里面，java的进一步掌握就是我要攻克的重点。 java集合源码全部阅读，JUC源码阅读，弄懂nio。 看源码一定要写demo然后去debug netty spring-bean spring-mvc spring-context Dubbo SOFA tomcat Apollo zk RocketMQ 一致性算法 raft 工资upup 野心不可谓不大，也许无法全部完成，但是尽力吧！ 最后，送上一句”莫那·鲁道”的话共勉：”站在十年之后看今天的自己”。","categories":[{"name":"Summary","slug":"Summary","permalink":"https://www.jelliclecat.cn/categories/Summary/"}],"tags":[{"name":"Summary","slug":"Summary","permalink":"https://www.jelliclecat.cn/tags/Summary/"}]},{"title":"Filter 的实现原理","slug":"FilterPattern","date":"2019-05-30T04:16:50.000Z","updated":"2021-06-25T13:47:33.060Z","comments":true,"path":"articles/Java/FilterPattern/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/FilterPattern/","excerpt":"","text":"一. Filter原理最近刚刚接触dubbo，瞬间被dubbo的简洁和扩展性圈粉了，用郭大爷的话来说就是又勾勾又丢丢，一想之美。代码算上测试一共短短12W行，没有像spring那么复杂的继承结构，但是对各种设计模式和架构设计理念的运用又极度的优雅。 跑题了，这里主要记录一下Filter的作用原理。Filter在很多地方都有用到，比如Servlet。Dubbo中也不例外，在一个Invoker被调用之前，可以配置多个Filter去过滤一次调用。Filter的作用可以看做一个AOP，在真正调用的前后做一些工作，并且Filter可以非常方便的层层嵌套。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER);&#125;private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (filters.size() &gt; 0) &#123; for (int i = filters.size() - 1; i &gt;= 0; i --) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; public URL getUrl() &#123; return invoker.getUrl(); &#125; public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last;&#125; 这段代码可以非常清晰的看到filter是如何被一层一层组装的。 二. 自己模拟实现 目录结构如上，Filter和Invoker也超级简单： 1234567public interface Filter &#123; int invoke(Invoker invoker, int i);&#125;public interface Invoker &#123; int result(int i);&#125; 看看实现类： 1234567891011121314151617181920212223242526272829303132333435363738public class InvokerImpl implements Invoker &#123; @Override public int result(int i) &#123; System.out.println(&quot;invoker impl&quot;); return i * 2; &#125;&#125;public class FilterA implements Filter&#123; @Override public int invoke(Invoker invoker, int i) &#123; try &#123; System.out.println(&quot;Filter A&quot;); int result = invoker.result(i); System.out.println(&quot;after Filter A&quot;); return result; &#125;catch (Exception e) &#123; throw e; &#125; &#125;&#125;public class FilterB implements Filter &#123; @Override public int invoke(Invoker invoker, int i) &#123; try &#123; System.out.println(&quot;Filter B&quot;); int result = invoker.result(i); System.out.println(&quot;after Filter B&quot;); return result; &#125; catch (Exception e) &#123; throw e; &#125; &#125;&#125; 组装filter并测试： 123456789101112131415161718192021public class Test &#123; public static void main(String[] args) &#123; Filter filter1 = new FilterA(); Filter filter2 = new FilterB(); List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); filters.addAll(Arrays.asList(filter1, filter2)); Invoker last = new InvokerImpl(); // 注意顺序，filter2 -&gt; filter1 -&gt; invoker for(Filter filter : filters) &#123; final Invoker next = last; last = (i) -&gt; filter.invoke(next, i); &#125; System.out.println(last.result(1)); &#125;&#125; 这里要注意组装的顺序，决定最后先调用那个filter。 看看最后的运行结果： 123456Filter BFilter Ainvoker implafter Filter Aafter Filter B2 结合以上代码，不难看出filter的执行顺序，filter其实就是一个硬编码的栈，用户可以决定在栈的什么地方做一个操作。","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.jelliclecat.cn/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"源码分析","slug":"源码分析","permalink":"https://www.jelliclecat.cn/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"HttpClient 带Cookie请求的一个Bug","slug":"HttpClientBug","date":"2019-05-22T07:24:50.000Z","updated":"2021-06-25T13:47:33.050Z","comments":true,"path":"articles/Java/HttpClientBug/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/HttpClientBug/","excerpt":"","text":"一、情景复现最近在使用HttpClient做rpc的时候，需要带上Cookie做认证，是一个很简单的功能，官网上有标准做法： 12345678910111213141516171819202122232425public static String Get(String url, String ticket) throws IOException &#123; CookieStore cookieStore = new BasicCookieStore(); BasicClientCookie cookie = new BasicClientCookie(cookie_name, ticket); cookie.setDomain(&quot;.zrj.com&quot;); // 示意domain cookie.setPath(&quot;/&quot;); cookieStore.addCookie(cookie); CloseableHttpClient httpClient = HttpClients.custom() .setDefaultCookieStore(cookieStore) .build(); final HttpGet httpGet = new HttpGet(url); CloseableHttpResponse response = httpClient.execute(httpGet); int statusCode = response.getStatusLine().getStatusCode(); if (statusCode &gt; 299 || statusCode &lt; 200) &#123; throw new IOException(&quot;statusCode error : &quot; + statusCode); &#125; HttpEntity entity = response.getEntity(); String responseStr = IOUtils.toString(entity.getContent()); EntityUtils.consume(entity); response.close(); httpClient.close(); return responseStr;&#125; 发现服务的provider认证始终不能通过，服务端调试的时候，发现request里面没有携带任何cookie，确定不是服务的问题。那就可能是我们的HttpClient客户端没有发送cookie，google了一堆，没有发现任何问题，大部分博文中提到的标准写法就是上面的这种。 实在没有办法了，只能自己DEBUG，看看设置的CookieStore最后到底怎么着了。 二、DEBUG过程在google的过程中，也不是完全没有收获，其中有一段话： HttpClient的cookie最终都转换成了header保存在request中，但是于直接setHeather不同的是，使用CookieStore设置的Cookies会经过各种合规性校验。 这里看起来是我们解决问题的切入点，看看CookieStore最后是怎么转换为Header的。 1CloseableHttpResponse response = httpClient.execute(httpGet); 这里打断点进去，具体跟踪断点的方法不在这里赘述，我们的目标是找到CookieStore转换为Header的逻辑。 一直到ProtocolExec中： 1this.httpProcessor.process(request, context); debug的过程中可以看到HttpClient的大致逻辑，各种http请求的参数和设置都保存在context中，可以看到我们的CookieStore也在里面，还有Cookie的Spec集合，如果我们不设置cookie协议，会自动设置为”default”： 继续进去，发现关键逻辑： 123456789// ImmutableHttpProcessor.java @Override public void process( final HttpRequest request, final HttpContext context) throws IOException, HttpException &#123; for (final HttpRequestInterceptor requestInterceptor : this.requestInterceptors) &#123; requestInterceptor.process(request, context); &#125; &#125; 这段代码使用各种不同的解释器，将context中的各种参数解析成标准的http格式，放在request中。 dubug模式下看一下RequestInterceptors列表，发现了一个RequestAddCookies实例，毫无疑问这就是将CookieStore转换为Header的解释器，进去看。 这个类里面，前面为我们将CookieSpecs设置成了”default”： 123456789// RequestAddCookies.javafinal RequestConfig config = clientContext.getRequestConfig();String policy = config.getCookieSpec();if (policy == null) &#123; policy = CookieSpecs.DEFAULT;&#125;if (this.log.isDebugEnabled()) &#123; this.log.debug(&quot;CookieSpec selected: &quot; + policy);&#125; 继续往后就看到了我们的关键代码： 12345678910111213141516// RequestAddCookies.javafor (final Cookie cookie : cookies) &#123; if (!cookie.isExpired(now)) &#123; if (cookieSpec.match(cookie, cookieOrigin)) &#123; if (this.log.isDebugEnabled()) &#123; this.log.debug(&quot;Cookie &quot; + cookie + &quot; match &quot; + cookieOrigin); &#125; matchedCookies.add(cookie); &#125; &#125; else &#123; if (this.log.isDebugEnabled()) &#123; this.log.debug(&quot;Cookie &quot; + cookie + &quot; expired&quot;); &#125; expired = true; &#125;&#125; 这里的for循环遍历了我们通过CookieStore设置的所有Cookie。其中有一个cookieSpec.match操作，当这个操作成功后，就会将我们的cookie设置到Header，直接走下去，发现我们自己的cookies没有了，说明这里的match操作失败了，进去看看为什么match失败： 123456789101112// CookieSpecBase.java@Overridepublic boolean match(final Cookie cookie, final CookieOrigin origin) &#123; Args.notNull(cookie, &quot;Cookie&quot;); Args.notNull(origin, &quot;Cookie origin&quot;); for (final CookieAttributeHandler handler: getAttribHandlers()) &#123; if (!handler.match(cookie, origin)) &#123; return false; &#125; &#125; return true;&#125; 这段代码是match真正执行的地方，通过一组Handler去match，如果有一个失败就退出，并返回失败，看看是哪个失败了： 最后一直走到BasicDomainHandler.java中： 1234567891011121314151617181920212223@Overridepublic boolean match(final Cookie cookie, final CookieOrigin origin) &#123; Args.notNull(cookie, &quot;Cookie&quot;); Args.notNull(origin, &quot;Cookie origin&quot;); final String host = origin.getHost(); String domain = cookie.getDomain(); if (domain == null) &#123; return false; &#125; if (domain.startsWith(&quot;.&quot;)) &#123; domain = domain.substring(1); &#125; domain = domain.toLowerCase(Locale.ROOT); if (host.equals(domain)) &#123; return true; &#125; if (cookie instanceof ClientCookie) &#123; if (((ClientCookie) cookie).containsAttribute(ClientCookie.DOMAIN_ATTR)) &#123; return domainMatch(domain, host); &#125; &#125; return false;&#125; 前面先检查了我们通过cookie.setDomain(“.zrj.com”)设置的domain信息。 关于cookie的domain： 如果domain设置的是”.zrj.com”，那么对于”t.zrj.com”、”www.zrj.com&quot;等等host地址，这个cookie都应该生效。 这里我们的host是t.zrj.com，而domain是zrj.com，检查不通过（这里检查不通过就很奇怪了，按理说应该通过），然后接下来使用cookie里面的Attribute去检查domain： 1if (((ClientCookie) cookie).containsAttribute(ClientCookie.DOMAIN_ATTR)) 这句话就是去检查我们cookie里面有没有通过Attribute设置”domain”信息： 12345// BasicClientCookie.java@Overridepublic boolean containsAttribute(final String name) &#123; return this.attribs.containsKey(name);&#125; 当然，我是通过setDomain方法设置的，下图中可以看到，attribs为空（我们没有设置这个），最终这里判定我们设置的cookie是不合法的。 三、解决问题1234567 CookieStore cookieStore = new BasicCookieStore(); BasicClientCookie cookie = new BasicClientCookie(cookie_name, ticket);// cookie.setDomain(&quot;.zrj.com&quot;); // 示意domain cookie.setAttribute(&quot;domain&quot;,&quot;.zrj.com&quot;); cookie.setPath(&quot;/&quot;); cookieStore.addCookie(cookie); 既然它检查了attribs，那我们通过attribs设置domain试试看，改成cookie.setAttribute(&quot;domain&quot;,&quot;.zrj.com&quot;);后，再次测试，发现server provider可以顺利拿到我们发送的cookie。 这里我仍然坚持设置domain为”.zrj.com”，而不是迎合它的检查方法设置成和host一模一样，因为这个cookie可能会在多个子域名使用。 这里非常奇怪，我们通过setDomain方法和setAttribute设置的domain的值是一样的，但是通过setDomain设置的没有通过检查，而通过setAttribute就通过了，怀疑这里是一个Bug，当然也可能是我自己对Cookie的协议理解有问题，回头看一下Cookie的各种协议确认一下。如果有大佬知道这里的原由，请不吝赐教！ PS:HttpClient版本（maven）： 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.6&lt;/version&gt; &lt;/dependency&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"HttpClient","slug":"HttpClient","permalink":"https://www.jelliclecat.cn/tags/HttpClient/"}]},{"title":"Java的回调机制","slug":"CallBackInJava","date":"2019-04-12T10:35:50.000Z","updated":"2021-06-25T13:47:33.055Z","comments":true,"path":"articles/Java/CallBackInJava/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/CallBackInJava/","excerpt":"","text":"一、回调（Callback）回调（Callback）是编程中常用的一种编程模式。在程序运行中，当程序执行到某个特定的点或者达到某个条件后，会执行一个用户自定义的方法，用于执行用户自定义的在这个点执行的逻辑，这种机制被称为回调。回调一般与一个事件绑定，当事件发生后，会自动调用这个方法。回调在很多地方都有用到，例如，注册一个监听器监听一个点击事件，在点击发生之前这个监听器将阻塞，点击事件发生后，就会自动调用用户自定义的运行逻辑，这种调用就是回调。回调的时机一般不是由用户自己控制的，而是由框架或者事件控制的，例如Spring中就大量使用回调机制（各种Template类，例如TransactionTemplate.java，JdbcTemplate.java等），这种回调机制类似一种hook，在模板执行的逻辑中的某些点上，使用用户自定义的逻辑。 TransactionTemplate.java中的execute方法，这里删除了一些逻辑： 123456789101112131415161718192021222324@Override @Nullable public &lt;T&gt; T execute(TransactionCallback&lt;T&gt; action) throws TransactionException &#123; .... TransactionStatus status = this.transactionManager.getTransaction(this); T result; try &#123; result = action.doInTransaction(status); &#125; catch (RuntimeException | Error ex) &#123; // Transactional code threw application exception -&gt; rollback rollbackOnException(status, ex); throw ex; &#125; catch (Throwable ex) &#123; // Transactional code threw unexpected exception -&gt; rollback rollbackOnException(status, ex); throw new UndeclaredThrowableException(ex, &quot;TransactionCallback threw undeclared checked exception&quot;); &#125; this.transactionManager.commit(status); return result; &#125;&#125; Java不能像C++那样将一个函数作为参数传入另一个函数，但是Java可以传入一个实例作为参数，这样，我们可以将一个方法封装到一个类里面，并使其竟可能的轻量级。当我们需要传入这样的参数的时候，可以传入一个匿名内部类，在JDK8之后，你可以传入一个Lambda表达式。 所以，Java的回调是通过匿名内部类实现的。 以上面的Spring的TransactionTemplate.java类为例，其中封装了回调方法的类是TransactionCallback&lt;T&gt; action，这里删除了一些注释： 12345@FunctionalInterfacepublic interface TransactionCallback&lt;T&gt; &#123; @Nullable T doInTransaction(TransactionStatus status);&#125; 这里面只封装了一个方法，这个方法就是回调方法，在execute方法里面调用： 1result = action.doInTransaction(status); @FunctionalInterface是一个编译器检查注解，用于提醒编译器检查这个接口是不是一个函数式接口。函数式接口意味着这个接口里面有且只有一个抽象方法。例如一下两个接口都是函数式接口： 12345678910111213@FunctionalInterfacepublic interface TransactionCallback&lt;T&gt; &#123; @Nullable T doInTransaction(TransactionStatus status);&#125;@FunctionalInterfaceinterface GreetingService&#123; void foo0(String message); default void foo1()&#123;&#125; default void foo1()&#123;&#125;&#125; 函数式接口意味着，你在传入一个这个接口类型的参数的时候，可以使用Lambda表达式。 当然，你可以选择不使用@FunctionalInterface，也没有任何影响，因为它的作用仅仅是提醒编译器去检查一下。 二、自己写一个回调12345678910111213141516171819202122@FunctionalInterfaceinterface Callback &#123; void do();&#125;class Caller &#123; public void call(Callback callback) &#123; System.out.println(&quot;before&quot;); callback.do(); System.out.println(&quot;after&quot;); &#125;&#125;public static void main(String[] args) &#123; Caller caller = new Caller(); caller.call(() -&gt; System.out.println(&quot;doing&quot;));&#125;// 结果：beforedoingafter 是不是很简单~ 当然，上面的例子只是一个简单的示例，回调有一个非常好的好处是，可以在某个事件发生的时候再调用我们定义的回调： 1234567891011121314151617181920212223242526@FunctionalInterfaceinterface Callback &#123; void do();&#125;class Event &#123; private String name; public String getName() &#123; return name; &#125;&#125;class Caller &#123; private BlockingQueue&lt;Event&gt; queue; public void setQueue(BlockingQueue&lt;Event&gt; queue) &#123; this.queue = queue; &#125; public void call(Callback callback) &#123; Event event = queue.take(); if(&quot;click&quot;.equals(event.getName())) callback.do(); &#125;&#125;public static void main(String[] args) &#123; Caller caller = new Caller(); caller.call(() -&gt; System.out.println(&quot;click done&quot;));&#125; 假设在其他地方会不定时的产生各种event，这些event会被一个producer加入到queue中，我们的方法中，会使用Event event = queue.take()去阻塞的获取各种产生的event，当event的类型是”click”时，调用Callback中定义的方法，打印”click done”。这种实现方式就是一种最原始的监听器（Listener）编程模式（貌似不是设计模式，待确认）。 欢迎交流~","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"}]},{"title":"ThreadPoolExecutor全解","slug":"ThreadPoolExecutor","date":"2019-04-11T10:16:50.000Z","updated":"2021-06-25T13:47:33.048Z","comments":true,"path":"articles/Java/ThreadPoolExecutor/","link":"","permalink":"https://www.jelliclecat.cn/articles/Java/ThreadPoolExecutor/","excerpt":"","text":"导读第一章，阐述了阅读代码的方法和ThreadPoolExecutor的继承结构，可以自己分析继承结构的朋友可以跳过本章。 第二章，详细讲解了ThreadPoolExecutor的内部运作原理，包括线程的重用、内部队列、申请新线程策略等，是本文重点。 第三章，作为补充，讲解Runnable和Thread的用法，如果你不了解Java的线程，推荐先看这章。 第四章，作为补充，讲解ThreadPoolExecutor的基本用法。 一、ThreadPoolExecutor整体结构1. 研究方法我们在研究面向对象源码（至少是Java源码）的时候，总应该先从继承（包括对接口的实现）关系图入手，看过Spring源码的同学一定清楚，Spring中频繁用到了非常复杂的继承技术，举个几个例子： org.springframework.beans下的BeanWrapperImpl类的继承结构如下： 通过分析BeanWrapperImpl实现的所有接口，不难推测出BeanWrapperImpl中具体有哪些功能。当然Spring中还有很多更加复杂的继承关系，例如BeanFactory和BeanDefination等类的实现，感兴趣的朋友们可以自己研究一下，相信在仔细研读之后，对面向对象技术的理解会更加深刻。 在阅读每一个接口代码的时候，请尝试自己猜想一下，最后这些方法会怎么实现。 当然，除了宏观的类继承结构以外，细节代码的精读也是必不可少的。 2. ThreadPoolExecutor的继承结构 可以看到，ThreadPoolExecutor的继承结构非常简单，我们一个个来看： Executor.java123public interface Executor &#123; void execute(Runnable command);&#125; 这接口很简单，只定义了一个方法execute，这个方法接受一个Runnable参数（这里假定你知道Runnable接口有关的知识，如果不了解，可以先跳转到第三章，那里会介绍Runnable接口和Thread类），可以猜想一下，实现后的execute方法里面肯定会调用这个Runnable参数的run方法。这里将一个任务抽象成了Runnable接口。 ExecutorService.java12345678910111213141516171819202122232425262728293031323334public interface ExecutorService extends Executor &#123; void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 这是ThreadPoolExecutor的核心接口了，当时这个接口还不能算作线程池，只能算作一个线程执行引擎或者说代理。接口里面定义了几个核心的方法： void shutdown(); 关闭这个执行器 List&lt;Runnable&gt; shutdownNow(); 立即关闭，并返回一个Runnable集合，不妨猜想一下，这个集合是还没来得及执行的任务集合，并且shutdown()和shutdownNow()之间的执行策略会有比较大的区别 Future&lt;?&gt; submit(Runnable task); 提交一个Runnable任务 其他有几个boolean方法用来判断当前状态。以及几个invokeAny和invokeAll方法，猜想一下，这两个方法用来批量执行任务 好了，现在一个任务执行器已经有了一个大致的轮廓，接下来看看具体实现。 AbstractExecutorService.java123456public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; submit方法是最重要的方法之一，在AbstractExecutorService.java中做了简单的实现，首先检查task不能为null，然后将Runnable封装成一个RunnableFuture，最后具体的执行工作扔给了execute（Executor.java中定义的方法）方法，当我们想具体看看execute方法时，发现这个方法在这一层还没有实现。其他的实现大家可以自行阅读一下，这里不再赘述。 最后，看最核心的ThreadPoolExecutor。 二、 ThreadPoolExecutor.java源码详解这是重头戏。 如果你不清楚ThreadPoolExecutor的基本用法请跳到第四章，本章不会介绍基本用法并会默认你已经能够使用 1. 头部的位运算ThreadPoolExecutor类一开始有这样一段代码，其中涉及了不少的位运算，Java类库中有不少位运算出现，例如大名鼎鼎的HashMap（里面的resize方法，hash方法等），Reentrantlock中的读写锁。位运算有两个明显的好处：a.可以使用掩码对一个int数据做高位和低位运算达到压缩数据的目的、b.运算速度快。我们分析一下这里的位运算： 123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 首先，上面这段代码将Integer.SIZE - 3也就是29赋值给COUNT_BITS，并将CAPACITY赋值为(1 &lt;&lt; COUNT_BITS) - 1，CAPACITY这个名称在集合类库中非常常见，用来指定当前容器的能力，或者说容量上限。这里的CAPACITY并非是Integer.MAXVALUE，而是(1 &lt;&lt; COUNT_BITS) - 1。那么目的已经呼之欲出了，对于一个int，将其高三位用作表示运行状态，低29位用于表示容器的当前大小，实现了使用一个int同时保存两种信息的功能。 12private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; 知道了这一点，上面这两个函数的用途就非常好懂了，CAPACITY相当于掩码，c &amp; ~CAPACITY相当于获得c的高三位，得到运行状态，c &amp; CAPACITY用来获得c的低29位，获得当前容器大小。这里的c是什么呢？就是第一行定义的AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));变量，这个变量中同时保存了当前容器的运行状态和容器大小，并将存在于ThreadPoolExecutor的整个生命周期。 2. 还记得Executor.java中的execute方法吗？在AbstractExecutorService中，这个方法在submit方法中被调用了，但是我们没有找到它的实现，我们猜想，这个方法一定在子类中实现了。这是典型的模板方法模式。 前面讲过，ThreadPoolExecutor中最重要的方法之一就是submit方法，这个方法告诉我们怎么提交一个新的任务，并使用各种策略去执行它（使用coreThread？加入队列？或者创建一个新的线程去执行？）。 在ThreadPoolExecutor中，我们如愿以偿的找到了execute的实现： 1234567891011121314151617181920public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 当我们调用了submit方法提交一个任务后，最后任务的执行是在这段代码中。 这段代码干了三件事： 如果当前线程池（或者说容器）中的线程数少于corePoolSize，则调用addWorker(command, true)去创建一个核心线程，并执行任务。 如果当前核心线程数以满，则将新的任务放进缓存队列，等待执行。 如果加入队列失败，则调用addWorker(command, false)开启一个非核心线程去执行任务。 从这段代码我们清楚了线程池对核心线程和非核心线程的生成策略：首先如果当前核心线程数小于设置的corePoolSize，则无论已有的核心线程是否空闲，优先选择新生成一个核心线程去完成新的任务；如果核心线程数量已经达到corePoolSize，则尝试将任务扔进内部的等待队列，看是否有空闲的核心线程去执行任务；如果加入等待队列失败，则创建一个临时线程去执行任务，临时任务在完成任务后，等待keepAliveTime的时间看是否有新任务，如果没有新任务则关闭这个临时线程。 3. addWorker()方法其中有一个关键方法：addWorker，这里先贴出方法签名，第一个参数表示将要执行的任务，第二个参数表示新添加的线程是否是一个core线程。 123456789101112131415161718192021222324252627282930 private boolean addWorker(Runnable firstTask, boolean core) &#123; // 省略了一些控制代码 .... boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 控制代码，暂且忽略 .... &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 可以看到，这段代码首先new了一个Worker，Worker是什么呢？在创建的时候，往构造函数里面传入了我们需要执行的task（一个Runnable对象），在下面的代码中，通过final Thread t = w.thread;得到了一个Thread类，可以猜想一下，Worker是对Runnable的封装，并在Worker内部创建了一个新的Thread。后面一堆控制代码暂且不看，最后有： 1234if (workerAdded) &#123; t.start(); workerStarted = true;&#125; workerAdded表示Worker是否成功创建，然后调用刚刚从新的Worker获得线程的start方法，启动这个新的线程，并标志新的Worker是否成功。 4. Worker内部类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125; 可以看到，Worker本身也是一个Runnable，看看其构造函数： 12345 Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this);&#125; 当接收到一个Runnable任务firstTask后，首先是持有了这个任务，这里注意，然后调用getThreadFactory().newThread(this)获得一个新的线程，传入的是this（一个Worker，Worker实现了Runable）而不是持有的任务。 当调用addWorker调用t.start();的时候，这个线程开始执行Worker的run方法： 123public void run() &#123; runWorker(this);&#125; 这里调用了外部类的runWorker方法，并又将自己（Worker）作为参数传入了其中，这个Worker持有了我们真正需要执行的任务：firstTask。 5. runWorker(Worker w)方法希望你没有晕，这里确实有点绕，在仔细阅读runWorker之前，我们先捋一下，假设现在核心线程数小于corePoolSize，当我们调用一个ThreadPoolExecutor的submit方法之后都发生了什么： 调用submit方法，提交一个任务 执行submit内部的execute方法去执行任务 execute方法调用addWorker，传入需要执行的任务，封装成一个Worker内部类对象 addWorker创建Worker成功后，获取其线程，调用t.start启动 t.start启动线程后，开始执行Worker的run方法 run方法实际执行的是外部类的runWorker(Worker w)方法 就到我们这里啦~，流程到这里没有想明白的话，不建议继续往下看。 12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125; &#125; 好了，果不其然，当Worker作为参入传入之后，立马获得真正需要执行的任务：Runnable task = w.firstTask;，如果Worker是新建的，那么task必然!=null。这里有一个循环体，我们浓缩一下，删除一些状态控制代码、锁控制代码和异常控制代码： 123456789while (task != null || (task = getTask()) != null) &#123; try&#123; beforeExecute(wt, task); task.run(); afterExecute(task, thrown); &#125; finally &#123; task = null; &#125;&#125; 这里用了一个典型的代理模式（Worker代理Runnable，Runnable是真正的task），允许在真正的task.run()方法调用之前和之后做一些自定义操作，不出意外这两个方法应该是protected的空方法： 12protected void beforeExecute(Thread t, Runnable r) &#123; &#125;protected void afterExecute(Runnable r, Throwable t) &#123; &#125; 用法是，继承一个ThreadPoolExecutor然后实现这两个方法。然后用的时候，将你自定义的类，向上转型为ThreadPoolExecutor去使用即可。 好了，最后终于执行到task.run，经历了千辛万苦，终于执行了真正任务的run方法。由于每个任务的方法只执行一次（当然，你可以在你提交的任务里面写一个循环，但是在ThreadPoolExecutor看来，每个任务都只执行一次），执行完后，令task = null，然后进入下一轮循环。可以看到，到这里Worker的第一个任务task任务已经执行完，并被GC了，但是Worker的使命还没有结束，还要继续执行其他的task。 这里也就理解了，为什么Worker被构造的时候，持有的task被命名为”firstTask”的参数持有，因为Worker创建成功后会首先去执行这个任务，再去等待执行之后的任务。 那么第一个任务执行完成后，Worker怎么继续执行其他的任务呢？请看task = getTask()。 6. getTask()方法12345678910111213141516171819202122232425262728293031323334353637private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125; &#125; 我们先看看return null会怎么样，很简单，这里返回空，runWorker方法中的循环就退出了，这个线程也就结束了。否则，调用workQueue的poll和take方法去获得一个任务，注意这两个方法都是阻塞的： 1234567891011121314151617181920212223/** * Retrieves and removes the head of this queue, waiting if necessary * until an element becomes available. * * @return the head of this queue * @throws InterruptedException if interrupted while waiting */E take() throws InterruptedException;/** * Retrieves and removes the head of this queue, waiting up to the * specified wait time if necessary for an element to become available. * * @param timeout how long to wait before giving up, in units of * &#123;@code unit&#125; * @param unit a &#123;@code TimeUnit&#125; determining how to interpret the * &#123;@code timeout&#125; parameter * @return the head of this queue, or &#123;@code null&#125; if the * specified waiting time elapses before an element is available * @throws InterruptedException if interrupted while waiting */E poll(long timeout, TimeUnit unit) throws InterruptedException; allowCoreThreadTimeOut参数代表是否允许核心线程空转（实际上不是空转，而是阻塞），换句话说，如果allowCoreThreadTimeOut = true，那么在没有任务可做的时候，核心线程也会被回收。 这里假设设置了allowCoreThreadTimeOut = false用来保留核心线程。 假设现在线程数大于corePoolSize，如果设置了keepAliveTime，poll会等待keepAliveTime纳秒的时间，如果时间到后还没有取到任务，则timedOut = true，然后在下一轮循环的时候，判断allowCoreThreadTimeOut || wc &gt; corePoolSize;为true（前面的假设），返回null，释放当前阻塞的线程。注意这里释放线程的时候并不区分是临时线程和核心线程，只是单纯的保证线程数量。也就是说，你最开始申请的线程是核心线程，但是在随后线程数量超过corePoolSize之后，参与竞争的是所有的核心线程和非核心线程，这时超时释放的线程并不一定是临时线程，也有可能是最初申请的核心线程。换句话说，所有的线程都是地位都是一样，所谓的核心线程只是一个代指，代指在竞争中存活下来的线程。 假设现在有4个核心线程和2个临时线程并设置了keepAliveTime为1s，如果现在所有的任务已经执行完毕后，这6个线程会同时阻塞在workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) 这句，如果时间到了还没有任务到来，则销毁这6个线程中的随机两个。销毁两个后，再次循环判断的时候，allowCoreThreadTimeOut || wc &gt; corePoolSize判断为false，剩下的4个线程阻塞在了workQueue.take()。 好了，最后一个问题，workQueue中的数据是哪里来的呢？前面介绍execute方法的时候讲过，如果新的方法到来，但是核心线程已经满了，这时会把数据插入到一个队列中，这个队列就是这里的workQueue： 1if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; 三、Runnable和Thread（补充）经常看到这样的总结： Java中创建Thread的两种方式： 继承Thread类 实现Runnable接口 实际上这么说并不准确，并且会造成误导。 因为创建Thread的方式只有一种，那就是 new Thread(Runnable target)。 单纯的实现Runnable接口并没有任何作用，Runnable接口对比与其他接口并没有任何的特殊之处，实现Runnable接口的类也仅仅是多了一个名为run的方法。 之所以Runnable特殊是因为他是Thread的一个回调接口（关于回调，请参考Java的回调机制），Thread的构造函数接受一个Runnable类型的参数target，并持有这个参数，并在线程start后，调用run方法（Thread本身也实现了Runnable），然后里面调用了target的run方法： 123456@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 所以，Runnable接口如果脱离Thread使用，那么它和一个普通接口没有区别。 知道Runnable和Thread的关系之后，就可以灵活运用了： 创建一个匿名内部类 1234Thread t = new Thread(() -&gt; &#123; System.out.println(&quot;继续&quot;);&#125;);t.start(); 创建一个匿名Thread，并无限循环 12345new Thread(() -&gt; &#123; while(true) &#123; System.out.println(&quot;继续&quot;); &#125;&#125;).start; 等等，你也可以单独创建一个类实现Runnable方法，然后使用这个类的实例去构建Thread。Thread还有很多重载的构造函数，可以给Thread命名等，不一一赘述。 不知道大家自己有没有考虑过线程池的实现，线程池的实现方式还是比较特殊的。其他的资源池可能会创建一些可以重复使用的类，然后放在一个集合里面（List、Set等），需要用到的时候拿一个出来，用完了再换回去。线程池并不是这么实现的，如果仔细阅读了ThreadPoolExecutor的源码，发现所有的线程内部都是一个循环，这个循环在没有任务的时候，就会阻塞，等有任务了之后，再竞争的这种做法。这是因为，一旦一个Thread执行完成（run方法退出），这个线程就不能用了，如果再次调用start方法，会抛出IllegalThreadStateException异常。这是因为线程执行完成之后，其状态会被虚拟机标志为TERMINATED，只有处于NEW状态的线程可以调用start方法： 123456789101112public synchronized void start() &#123; /** * This method is not invoked for the main method thread or &quot;system&quot; * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state &quot;NEW&quot;. */ if (threadStatus != 0) throw new IllegalThreadStateException(); ....&#125; 线程的所有状态如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public enum State &#123; /** * Thread state for a thread which has not yet started. */ NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * &#123;@link Object#wait() Object.wait&#125;. */ BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * &lt;ul&gt; * &lt;li&gt;&#123;@link Object#wait() Object.wait&#125; with no timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join() Thread.join&#125; with no timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#park() LockSupport.park&#125;&lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;/tt&gt; * on an object is waiting for another thread to call * &lt;tt&gt;Object.notify()&lt;/tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;/tt&gt; on * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;/tt&gt; * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * &lt;ul&gt; * &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;/li&gt; * &lt;/ul&gt; */ TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED; &#125; 这个枚举类在Thread类里面，是一个嵌套枚举类（有必要区分一下嵌套和内部的区别，一般认为static标识的内部类为嵌套类，而不是内部类），里面保存了线程的六个状态，大家自行查看注释即可，不再赘述。 因此，线程池内的线程必然不能退出run方法，只能在runWorker方法中采用了一个死循环，为了避免线程空转（空转会消耗CPU资源），便使用一个BlockQueue把所有的线程阻塞住。所以ThreadPoolExecutor的内部线程是阻塞的。 四、 ThreadPoolExecutor基本用法请看ThreadPoolExecutor的构造函数： 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 名称 含义 类型 corePoolSize 核心线程池大小 int maximumPoolSize 最大线程池大小 int keepAliveTime 线程最大空闲时间 long unit 时间单位 TimeUnit workQueue 任务等待队列 BlockingQueue threadFactory 线程创建工厂 ThreadFactory handler 拒绝策略 RejectedExecutionHandler 这里有几篇很棒的博客推荐一下： 线程池之ThreadPoolExecutor概述 线程池之ThreadPoolExecutor使用 后面一篇文章讲述了Executors.java中预定义的几个常用线程池（这是一种常见的静态工厂方法，见《Effective Java》第一章第一节，用法类似的还有Collections.java）：（以下内容引用线程池之ThreadPoolExecutor使用这篇文章的内容）： 1. FixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; corePoolSize与maximumPoolSize相等，即其线程全为核心线程，是一个固定大小的线程池，是其优势； keepAliveTime = 0 该参数默认对核心线程无效，而FixedThreadPool全部为核心线程； workQueue 为LinkedBlockingQueue（无界阻塞队列），队列最大值为Integer.MAX_VALUE。如果任务提交速度持续大余任务处理速度，会造成队列大量阻塞。因为队列很大，很有可能在拒绝策略前，内存溢出。是其劣势； FixedThreadPool的任务执行是无序的； 适用场景：可用于Web服务瞬时削峰，但需注意长时间持续高峰情况造成的队列阻塞。 2. CachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; corePoolSize = 0，maximumPoolSize = Integer.MAX_VALUE，即线程数量几乎无限制； keepAliveTime = 60s，线程空闲60s后自动结束。 workQueue 为 SynchronousQueue 同步队列，这个队列类似于一个接力棒，入队出队必须同时传递，因为CachedThreadPool线程创建无限制，不会有队列等待，所以使用SynchronousQueue； 适用场景：快速处理大量耗时较短的任务，如Netty的NIO接受请求时，可使用CachedThreadPool。 3. SingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 这里多了一层FinalizableDelegatedExecutorService包装，这一层有什么用呢，对SingleThreadExecutor被包装后，无法成功向上转型，否则可以通过向上转型进行修改。因此，SingleThreadExecutor被定以后，无法修改，做到了真正的Single。 4. ScheduledThreadPoolExecutor123public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; newScheduledThreadPool调用的是ScheduledThreadPoolExecutor的构造方法，而ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，构造是还是调用了其父类的构造方法。具体使用本文不做描述。 最后提一嘴，SynchronousQueue这个东西类似一个接力棒，里面只能存储一个东西，类似一个窗口，窗口的一边只能放一个东西，然后就要等待窗口的另一边取走这个东西。 有任何错误或者建议，欢迎指正 欢迎交流~","categories":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"源码","slug":"源码","permalink":"https://www.jelliclecat.cn/tags/%E6%BA%90%E7%A0%81/"},{"name":"并发","slug":"并发","permalink":"https://www.jelliclecat.cn/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Spring Cache 使用实践","slug":"SpringCache","date":"2019-04-04T13:16:50.000Z","updated":"2021-06-25T13:47:33.054Z","comments":true,"path":"articles/Spring/SpringCache/","link":"","permalink":"https://www.jelliclecat.cn/articles/Spring/SpringCache/","excerpt":"","text":"@Deprecated 不建议阅读一. Spring Cache的基本应用Spring对cache有注解层的支持，我们可以非常方便的使用这些注解来实现业务中的缓存逻辑。建议使用Spring的同学手下一定有一个Spring源码的阅读环境。Spring主要的cache注解如下: （源码位于spring-context -&gt; cache -&gt; annotation） @interface Cacheable 这个注解应该是最常用的一个注解，这个注解可以标注一个方法，这个方法返回的数据会被缓存，下次调用将直接返回缓存中的数据。 @interface CachePut 这个注解标注的方法返回的数据也会被缓存，但是每次调用该方法都将执行该方法，并将最新数据放入相关联的缓存之中。所以即使缓存中已经有数据，还是会去执行这个方法。需要体会一下和Cacheable的区别。 @interface CacheEvict 这个注解标注的方法被调用时，CacheEvict指定的缓存数据将失效。 看一下Cacheable的源码，这里大致解释了一下主要字段的作用，其他的注解也类似。 123456789101112131415161718192021222324252627@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Cacheable &#123; @AliasFor(&quot;cacheNames&quot;) String[] value() default &#123;&#125;; // 关联的缓存名字，指定一个缓存 @AliasFor(&quot;value&quot;) String[] cacheNames() default &#123;&#125;; String key() default &quot;&quot;; // 对应缓存中相关数据的key String keyGenerator() default &quot;&quot;; // key自动生成策略 String cacheManager() default &quot;&quot;; String cacheResolver() default &quot;&quot;; String condition() default &quot;&quot;; String unless() default &quot;&quot;; boolean sync() default false; // 异步刷新数据，防止缓存穿透&#125; 当然只有注解是不行的，我们还需要具体的cache，这里我们使用的是GuavaCache。Spring 5 已经放弃了对GuavaCache的支持，据说是性能原因，取而代之的是CaffeineCache和EhCacheCache。之后的文章会介绍并对比GuavaCache、CaffeineCache和EhCacheCache的区别。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@EnableCaching@Configurationpublic class CacheConfig extends CachingConfigurerSupport &#123; public final static String CACHE_FIVE_MINUTE = &quot;CACHE_FIVE_MINUTE&quot;; public final static String CACHE_ONE_HOUR = &quot;CACHE_ONE_HOUR&quot;; private static List&lt;String&gt; cacheList; static&#123; cacheList = new ArrayList&lt;&gt;(); cacheList.add(CACHE_FIVE_MINUTE); cacheList.add(CACHE_ONE_HOUR); &#125; public static List&lt;String&gt; getCacheList() &#123; return cacheList; &#125; @Override @Bean public CacheManager cacheManager() &#123; SimpleCacheManager cacheManager = new SimpleCacheManager(); GuavaCache guava5mCache = new ImmutableGuavaCache(CACHE_FIVE_MINUTE, CacheBuilder .newBuilder() .recordStats() .maximumSize(5000) .expireAfterWrite(5, TimeUnit.MINUTES).build()); GuavaCache guava1hourCache = new ImmutableGuavaCache(CACHE_ONE_HOUR, CacheBuilder .newBuilder() .recordStats() .maximumSize(5000) .expireAfterWrite(1, TimeUnit.HOURS).build()); cacheManager.setCaches(Arrays.asList(guavaCache, guava30Cache, guava5mCache, guava1hourCache)); return cacheManager; &#125; @Override @Bean(name = &quot;simpleJsonKeyGenerator&quot;) public KeyGenerator keyGenerator() &#123; return new SimpleJsonKeyGenerator(); &#125; public static class SimpleJsonKeyGenerator implements KeyGenerator&#123; private static Log logger = LogFactory.getLog(CacheConfig.class); @Override public Object generate(Object target, Method method, Object... params) &#123; String key = method + JSONObject.toJSONString(params); return key; &#125; &#125;&#125; 这里注册了两个cache，名称分别是CACHE_FIVE_MINUTE 和CACHE_ONE_HOUR。并注册了一个KeyGenerator，用于生产cache的key。这里的生成策略很简单，方法public Object generate(Object target, Method method, Object... params)的参数值得注意一下，target是调用被缓存方法的对象，method是被调用的方法，params是方法的参数签名，这种参数组合在Spring中非常常见，在Java中的InvocationHandler也使用了这种参数组合，public Object invoke(Object proxy, Method method, Object[] args)，表示”某个对象调用了某个方法”。 KeyGenerator简单的返回了一个独一无二的key，这里会导致一个很麻烦的问题，下面来详细讨论。 二. Cache Key 引发的问题上面描述了Spring Cache的一个简单实践，我们已经可以很方便的在业务逻辑代码中使用我们注册的Cache了： 1234567/** * 查找数据库中所有的书名，并缓存5分钟。 */@Cacheable(cacheNames = CacheConfig.CACHE_FIVE_MINUTE, sync = true)public Map&lt;Integer, Book&gt; getAllBooks() &#123; return bookDAO.selectAllBooks();&#125; 我们设置了缓存5分钟自动失效，缓存失效后，再次调用getAllBooksName()会直接去数据库拿数据，然后再次缓存。但是我们面临一个严峻的问题。 假设有以下情景：有一个用户在数据库中新增了一本书，然后用户需要立即使用刚刚新增的这本书籍，这是就出现了问题，因为缓存中并没有这个数据，而只有当缓存到期自动失效后，再次从数据库中加载数据时，才会加载到刚刚新增的书籍到缓存中。这时，缓存和数据库中的数据出现了不一致。而且不一致的时间最长达到5分钟。 要解决这个问题就不得不提到”大名鼎鼎”的 缓存更新策略问题，这个问题是可以算作cache的一个经典问题。这里介绍一个常用的策略，称作：Cache Aside。简单描述一下这个更新策略： 应用在查询数据的时候，先从缓存Cache中读取数据，如果缓存中没有，则再从数据库中读取数据，得到数据库的数据之后，将这个数据也放到缓存Cache中。 如果应用要更新某个数据，也是先去更新数据库中的数据，更新完成之后，则通过指令让缓存Cache中的数据失效。 我们的问题有了解决办法：那就是当这个用户在数据库新增完书籍之后(注意这里一定是确保添加完毕之后)，主动让缓存失效，当用户再次调用获取所有书籍的方法时，由于缓存已经失效，方法会从数据库中去获取最新的数据，这是缓存中的数据和数据库一致了。要注意的是，这里的一致并不是强一致，因为在并发环境下，用户添加完数据和调用主动缓存失效方法之间，可能会有其他的用户读取数据，这时，缓存仍然是旧缓存(因为发生在主动使缓存失效之前)，但是数据库中已经有了最新的数据(发生在添加完数据之后)，所以缓存的数据和数据库中的数据有一瞬间是不一致的。但是我们了解这一点就行，因为这种应用情景下，并不需要如此严格的数据一致性。 如果需要特定的缓存失效，我们只需要新增一个方法，然后标注上CacheEvict注解即可： 12345/** * 使缓存失效 */@CacheEvict(cacheNames = CacheConfig.CACHE_FIVE_MINUTE, key = ???)public void invalidateBooksCache() &#123;&#125; 这个方法不需要实现任何逻辑，当这个方法被调用时，缓存就失效了。 但是注意key这个参数，这里需要让缓存中一个特定的key对应的数据失效时，我们需要指定这个key，然而不幸的是，在上文代码中所见，使用了KeyGenerator去自动生成一个key，当再次需要这个key时，只能去按照规则去还原这个key(根据Object target, Method method, Object... params参数)，这无疑是不能接受的。 ​ 三. Cache Key 如何管理？这是本篇文章的重点，在缓存中，数据由CacheName和一个Key唯一决定，如果需要对特定的数据进行修改，则需要根据CacheName和Key去找到对应的数据。CacheName在本文实践中，只有两个：CACHE_FIVE_MINUTE 和 CACHE_ONE_HOUR，所以CacheName的获得并不是问题。真正的问题是Key，因为我们已经使用了一个KeyGenerator去自动生和被调用方法一一对应的Key，由于Key是和被调用方法一一对应的，在其他的方法中需要得到这个Key将变得困难。 1. 全局Enum让我们忘记KeyGenerator这个东西。回到最初，我们最原始的管理方法是什么呢？我想最简单的方法就是定义一个全局的Enum类，里面去管理所有的CacheKey，大概像这样： 123456public enum CacheKeyEnum &#123; BOOKS, USERS, ... // 等等其他的Key ;&#125; 然后上文中的代码，缓存注解就变成了这样： 12345678910@Cacheable( cacheNames = CacheConfig.CACHE_FIVE_MINUTE, key = CacheKeyEnum.BOOKS.toString(), sync = true)public Map&lt;Integer, Book&gt; getAllBooks() &#123; return bookDAO.selectAllBooks();&#125;@CacheEvict(cacheNames = CacheConfig.CACHE_FIVE_MINUTE, key = CacheKeyEnum.BOOKS.toString())public void invalidateBooksCache() &#123;&#125; 好了，这样通过一个全局Enum去管理所有的CacheKey的方式，比较好的解决掉了CacheKey的管理问题，目前看是这样。 缺点：如果你是一个经历过数十万行代码的人，相信你一定见过这种工程中的全局Enum，可能还会遇到全局的public static final String = &quot;xxx&quot;;管理类，不得不说这是一种十分方便的管理常量的方式，但是随着工程的膨胀，这种类也将变得越来越大，你很难从一堆看着差不多的大写常量中找到自己想要的那个，这种情况在多人合作时将变得更加严重，因为你不确定别人是否已经定义了你想定义的常量，即使你在几百个常量中找到了你觉得可能是你需要的常量，你也不确定这就是你想定义的常量，你可能需要去找作者交流一下，即使你不管这些，定义一个属于你自己的常量，这可能导致同一个系统中存在多个意义一样但是命名不同的常量，极端情况下，大家可能自顾自的去添加各种常量，这部分系统将变得不可维护。 不难发现，一个系统中的CacheKey的数目绝对不是一个小数量，使用这种方式无异饮鸩止渴。 2. 抽象Cache的管理另外一条思路就是，抽象一个AbstractCacheService，用来管理所有的Cache相关的工作。 缺点：很明显，以后我们所有需要Cache的Service，都会继承自AbstractCacheService，然而继承这种做法并不是Java工程师首先会考虑的解决问题的方式，因为继承太重了，这是由于Java中的单继承机制引起的。在决定去继承一个类之前，需要确定子类没有其他更重要的类需要继承，而且将来也不会有，因为要修改所有子类继承的父类类型是一个庞大无趣的机械工作。这使得我们在使用继承时慎之又慎，除非子类是对父类的直接扩展。一个很好的反面教材是Java标准库中的Observer和Observable，这是Java API对观察者模式的通用封装，而我们却鲜少见到有人用，原因和上述的原因是相同的，我们只能选择去继承Observable，而不是实现一个接口。 未完待续…","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"},{"name":"Cache","slug":"Cache","permalink":"https://www.jelliclecat.cn/tags/Cache/"}]},{"title":"从零搭建Latex服务器","slug":"Latex","date":"2019-04-03T14:16:50.000Z","updated":"2021-06-25T13:47:33.052Z","comments":true,"path":"articles/Linux/Latex/","link":"","permalink":"https://www.jelliclecat.cn/articles/Linux/Latex/","excerpt":"","text":"一. 什么是Latex服务器简单来说就是一个在线的实时数学公式解析服务器。这种服务器非常常见，例如知乎、掘金等都有自己的Latex服务器。 知乎latex服务器 这里的”三分之一”就是实时渲染的，打开浏览器的调试模式，可以看到Response的Content-Type = image/svg+xml。 Latex服务器必须高可用、低延时。 二. 搭建基本Latex服务器这里有一篇博客： 手动搭建latex公式渲染服务器 里面使用了Linux环境下的latex软件，现在的新版安装方法应该是： 1apt-get install texlive-full 强烈建议不要使用这种方法安装，安装任何软件之前，建议优先去官网查看安装教程，一般官网上会有详细的教程。这里推荐在镜像上下载到iso版本，然后scp到Linux环境下安装。这种方式貌似安装更加全面。 我最先使用apt-get安装，后来怎么也显示不了中文，安装了各种字体，调整了各种自定义配置，最后感觉是玩坏了，全部卸载删除，找到3.2版本的iso版本，安装之后就可以显示中文了。 期间踩了无数坑，有几篇比较好的博客推荐一下，提前说明，最后的成品没有使用TeXlive： Ubuntu下 TeX Live 2018 的安装与配置 LaTeX 中如何使用中文 Ubuntu 下安装 Texlive 并设置 CTeX 中文套装 最后，有问题，请Google 再安装好texlive之后，可以使用 1xelatex -no-pdf --interaction=nonstopmode --output-directory %s %s 将xxx.tex文件转换为xdv文件，xelatex可以方便的处理好中文字符，然后使用： 1dvisvgm --no-fonts --no-styles -s -c2,2 %s 可以将xdv文件转换为svg标准输出流。 -s 表示svg以标准输出流输出数据，而不是输出到文件。 –no-fonts –no-styles 删除各种字体信息。 基本的环境已经搭好了。 接下来需要一个http服务器去解析请求，并在底层调用上述命令，最后从标准输出流中读取svg文件数据，返回给客户端。在手动搭建latex公式渲染服务器这篇博客中，作者使用了python搭建，我对java比较熟悉，就用java吧。 使用start.spring.io可以很方便的构建一个基于Spring-boot的web应用，这是一个非常简单的应用： 将请求的参数使用String.Format写入tex文件 调用上述第一个命令生成xdv文件 调用上述第二个命令，并读取标准输出 将标准输出封装成response返回 总体代码是手动搭建latex公式渲染服务器这篇博客中python代码的java翻译版，中间加了一些中文的处理，由于比较简单，不贴代码了。 三. 性能优化1. 初步优化Latex服务器具有以下特点：高可用、高实时性。 我们所用的底层服务是一个IO密集&amp;CPU密集的程序，而Latex服务器对延时非常敏感，对于一篇博客，内容中的公式加载不出来或者加载过慢是不能接受的，所以我们要想办法提高服务器的承载能力。由于同一个公式往往会重复出现多次，例如一篇博客可能会被很多不同用户观看，而每次观看加载的公式都是一样的，这样，将已经出现过的公式保存到数据库是一个不错的选择。 当新的请求到来时，总是先去Mysql里面寻找TeX表达式对应的svg文件（svg文件是一种xml格式，可用TEXT保存），当然，由于公式的量会非常大，我们还需要考虑Mysql查询的优化，每次请求都去扫表是不能接受的。容易想到的是使用TeX字符串作为KEY建立索引，但是Innodb对索引长度是有限制的（是由B+Tree的节点也叫”页”的大小决定的，具体可以看MySQL索引背后的数据结构及算法原理这篇文章），而有时候的TeX表达式可能超出这个限制，所以直接以TeX作为KEY是不理想的，但是方法也很简单，对每个TeX表达式生成一个SHA256签名就行（MD5也行，但是为了防止碰撞还是采用SHA256或者更长的签名），然后对这个签名建立索引。数据库示意如下： id (PK) tex (VARCHAR) sha (INDEX,VARCHAR) svg (TEXT) created_at (DATETIME) 1 \\frac{1}{3} c45cb…..7fef6 … 2019-3-25 00:00:00 对于新来的tex请求： 根据TeX表达式字符串生成sha 在数据库中根据sha字段查找 对比请求的TeX和数据库中查找到的TeX字段是否一样(防止sha碰撞) 如果数据库中没有字段或者两个TeX不一样，都直接去调用命令重新生成svg。否则返回数据库中的svg。 这样随着时间的积累，TeX的数据库将越来越丰富，TeX服务器的性能也将越来越高。 2. 优化升级有了数据库已经能够在很大程度上改善性能问题了。对于tex服务，可以想象的到，刚刚被访问过的tex公式很可能在短期内再次被访问，所以加入缓存会进一步提升我们的性能。加缓存的方式有很多，我们可以简单的加入一个GuavaCache即可。Cache的key可以直接使用tex字符串。具体的加入方法不再细说，感兴趣的同学可以移步GuavaCache的使用方法。BTW，Spring 5已经放弃对GuavaCache的支持，可以使用CaffeineCache或EhCacheCache代替。 3. 还可以优化吗？如果在高并发环境下，如和进一步提升性能呢？比如知乎这种公司，大量的用户在编辑或者查看带有tex公式的文章时，Latex服务器的并发将达到一定的高度，在不考虑缓存的情况下，如果每次都要先去数据库查找一次才能知道用不用去调用底层的命令生成将显得臃肿，对于数据库中没有的tex公式，调用命令生成完毕后，还需要进行一次数据库写。我们有没有办法快速知道数据库中有没有记录过一个tex公式呢？ 这个问题变成了一个常见的问题： 对于海量不同的简单数据，如何知道一个数据有没有在服务器登记过？ 有一种东西叫做布隆过滤器，可以快速的知道一个简单数据是否在历史中出现过。关于布隆过滤器的原理不再赘述。 加入布隆过滤器之后，如果bloom的结果是false，那就不用再去数据库中查找了，可以100%肯定这个数据没有出现过，直接去调用底层命令生成。如果bloom的结果是true，那么有很大的概率(可能是99%以上)这个数据在数据库中有记录，去查找即可，如果bloom miss了，再调用命令去生成。这样，基本就把每次对数据库的操作限定为一次读或者写。加入缓存后，我们Latex服务器的单机并发将十分可观。 如果有进一步改善性能的思路，非常欢迎交流！可通过邮件，或者交换微信。 四. 对比与优化再次回来看知乎的Latex服务器，发现和我们做的Latex服务器有明显的不同。 我们的字体大小没办法限制，知乎的限制有：font-size: 15px 我们的对于错误语法没有提示，知乎的有语法错误提示 我们的公式生成速度大幅慢于知乎 我们的公式需要使用 $..$ 或者 $$…$$包起来，知乎不用 同样的tex，知乎生成的svg和我们生成的svg不同 知乎对于中文没有处理成svg，而是作为一个CJK字符，我们的是把中文也转换为了svg 等等其他细节 这让我对底层使用的公式解析工具产生了怀疑，再次仔细调研知乎的Latex服务器，发现另外一个值得尝试的Latex数学公式解析工具：MathJax。这是一个JS库，使用以下开源工程可以帮助我们快速的开发： https://github.com/mathjax/MathJax-node 用node.js调用 https://github.com/mathjax/mathjax-node-cli/ 可以安装在本地当做命令调用 原来一切都是这么简单，赶紧搭建一个简单的node服务验证一下： 1234567891011121314151617181920212223242526272829303132333435var mjAPI = require(&quot;./lib/main.js&quot;);var express = require(&#x27;express&#x27;);var app = express();mjAPI.config(&#123;MathJax: &#123;SVG: &#123; font: &quot;TeX&quot;, &#125;&#125;&#125;);mjAPI.start();app.get(&#x27;/equation&#x27;, function (req, res) &#123; var tex = req.query.tex; try &#123; mjAPI.typeset(&#123; math: tex, format: &#x27;TeX&#x27;, // (argv.inline ? &quot;inline-TeX&quot; : &quot;TeX&quot;), svg: true, speakText: false, // argv.speech, ex: 6, // argv.ex, width: 100, // argv.width, cjkCharWidth: 16 &#125;, function (data) &#123; res.header(&quot;Content-Type&quot;, &quot;image/svg+xml&quot;); res.send(data.svg); &#125;); &#125; catch(e) &#123; res.send(&quot;error&quot;); &#125;&#125;);var server = app.listen(8080, function () &#123; var host = server.address().address; var port = server.address().port; console.log(&#x27;Example app listening at http://%s:%s&#x27;, host, port);&#125;); 注意，MathJax官方没有对任何CJK字符做字体支持，只能由一个***”cjkCharWidth: 16”***属性控制CJK字符宽度，否则CJK字符在渲染成svg时，由于MathJax找不到对应的字符字体，无从得知字符的预留宽度而使用默认宽度，将使得CJK字符重叠在一起。 注意： 1234mjAPI.config(&#123;MathJax: &#123;SVG: &#123; font: &quot;TeX&quot;, &#125;&#125;&#125;);mjAPI.start(); 这段代码千万不要放在app.get中。 之前服务器搭好后，发现每过一段时间发现CPU和内存在短时间内直接跑满，服务彻底卡住很久。打开DEBUG模式发现： 123456789101112131415161718192021222324252627282930313233343536&lt;--- Last few GCs ---&gt;[37603:0x104800000] 527936 ms: Scavenge 1380.3 (1428.7) -&gt; 1372.7 (1429.2) MB, 2.0 / 0.0 ms (average mu = 0.388, current mu = 0.414) allocation failure[37603:0x104800000] 527949 ms: Scavenge 1380.4 (1429.2) -&gt; 1372.7 (1429.7) MB, 1.8 / 0.0 ms (average mu = 0.388, current mu = 0.414) allocation failure[37603:0x104800000] 527962 ms: Scavenge 1380.5 (1429.7) -&gt; 1372.7 (1430.2) MB, 1.8 / 0.0 ms (average mu = 0.388, current mu = 0.414) allocation failure&lt;--- JS stacktrace ---&gt;==== JS stack trace ========================================= 0: ExitFrame [pc: 0x5152ebcfc7d] 1: StubFrame [pc: 0x5152ebc872b]Security context: 0x3739581888c9 &lt;JSObject&gt; 2: split [0x3739b37aa461](this=0x37393b5989a9 &lt;String[36]: [MathJax]/jax/input/AsciiMath/jax.js&gt;,0x37393b598a51 &lt;JSRegExp &lt;String[2]: \\.&gt;&gt;) 3: Require [0x37393b416e91] [file:///Users/zhengrenjie/node/latex/node_modules/mathjax/unpacked/MathJax.js:~731] [pc=0x5152fd85892](this=0x37393b4326e9 &lt;Object map = 0x3739d840...FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memoryWriting Node.js report to file: report.20190329.191147.37603.001.jsonNode.js report completed 1: 0x100064183 node::Abort() [/usr/local/bin/node] 2: 0x1000647f1 node::OnFatalError(char const*, char const*) [/usr/local/bin/node] 3: 0x10017d12f v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [/usr/local/bin/node] 4: 0x10017d0d0 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [/usr/local/bin/node] 5: 0x100439f30 v8::internal::Heap::UpdateSurvivalStatistics(int) [/usr/local/bin/node] 6: 0x10043b971 v8::internal::Heap::CheckIneffectiveMarkCompact(unsigned long, double) [/usr/local/bin/node] 7: 0x1004392b7 v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) [/usr/local/bin/node] 8: 0x1004380a5 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [/usr/local/bin/node] 9: 0x10043ff69 v8::internal::Heap::AllocateRawWithLightRetry(int, v8::internal::AllocationSpace, v8::internal::AllocationAlignment) [/usr/local/bin/node]10: 0x10043ffb8 v8::internal::Heap::AllocateRawWithRetryOrFail(int, v8::internal::AllocationSpace, v8::internal::AllocationAlignment) [/usr/local/bin/node]11: 0x1004207e7 v8::internal::Factory::NewFillerObject(int, bool, v8::internal::AllocationSpace) [/usr/local/bin/node]12: 0x1005fd2ed v8::internal::Runtime_AllocateInNewSpace(int, v8::internal::Object**, v8::internal::Isolate*) [/usr/local/bin/node]13: 0x5152ebcfc7d14: 0x5152ebc872b[1] 37603 abort node --inspect index.js 发现在频繁的耗时GC后，并且GC没有产生任何效果(1428.7) -&gt; 1372.7后，最后抛出 1FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory 这无疑是内存泄漏一类的问题，仔细阅读源码发现mjApi.start()函数有以下注释： 12345678910111213//// Manually start MathJax (this is done automatically// when the first typeset() call is made), but delay// restart if we are already starting up (prevents// multiple calls to start() from causing confusion).//exports.start = function () &#123; if (serverState === STATE.STARTED) &#123; serverState = STATE.RESTART; &#125; else if (serverState !== STATE.ABORT) &#123; RestartMathJax(); &#125;&#125; 意思是说start函数只需要调用一次。而我们将mjAPI.start();放入了app.get中，这样每一个请求都调用了一次start函数，这显然是错误的。把这个start方法和config方法提出去即可。 注意，我们的代码中，var mjAPI = require(&quot;./lib/main.js&quot;);是从本地导入的库，而不是npm，这是因为MathJax-node工程将mjAPI.config的所有关于styles的自定义设置全部禁用了： 12345678910111213// MathJax-node/lib/main.js 244 行 : delete SVG.config.stylesvar SVG = MathJax.OutputJax.SVG, HTML = MathJax.HTML; // // Don&#x27;t need the styles // delete SVG.config.styles // 244 行 SVG.Augment(&#123; // // Set up the default ex-size and width // 所以，我们无法通过MathJax官方文档中提到的使用自定义的styles设置改变svg的默认样式，那知乎中的font-size: 15px是怎么弄的呢？我猜是改了MathJax-node项目的源码，找到 MathJax-node/lib/main.js 698行 发现以下代码： 1234567891011function GetSVG(result) &#123; if (!data.svg &amp;&amp; !data.svgNode) return; var jax = MathJax.Hub.getAllJax()[0]; if (!jax) return; var script = jax.SourceElement(), svg = script.previousSibling.getElementsByTagName(&quot;svg&quot;)[0]; svg.setAttribute(&quot;xmlns&quot;,&quot;http://www.w3.org/2000/svg&quot;); // 698行 svg.style.fontSize = &#x27;15px&#x27;; // 修改源码 // // Add the speech text and mark the SVG appropriately // if (data.speakText)&#123; 在698行，既然他可以通过svg.setAttribute，那我是不是可以自己令svg.style.fontSize = &#39;15px&#39;;呢？在699行添加我们自己的代码，改完源码后，将代码组织到自己的node服务中。重启服务器后，发现设置生效！ 在重新对比和知乎Latex的差别后，基本已经有模有样了，将我们的数据库挂到node服务上即可。 五. 总结 有问题，请Google，如果还有问题，请逐字阅读官网文档，别嫌读文档费时间，自己瞎x弄更费时间。 前期调研尽可能详细，可以少走很多弯路。 绝境中，源码绝对能提供最好的帮助。 六. 成果 https://www.nowcoder.com/equation?tex=\\frac{1}{3} 效果： 欢迎交流！！！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.jelliclecat.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.jelliclecat.cn/tags/Linux/"},{"name":"Latex","slug":"Latex","permalink":"https://www.jelliclecat.cn/tags/Latex/"}]},{"title":"常用Linux指令","slug":"LinuxCommand","date":"2019-03-17T14:16:50.000Z","updated":"2021-06-25T13:47:33.052Z","comments":true,"path":"articles/Linux/LinuxCommand/","link":"","permalink":"https://www.jelliclecat.cn/articles/Linux/LinuxCommand/","excerpt":"","text":"df -h查看文件系统的使用磁盘使用量。 -h —human 表示将结果以容易阅读的方式展现。 du -sh *查看当前文件夹下所有文件占用磁盘大小。 fc-list :lang=zh查看当前系统中的中文字体。 ps aux | grep XXX查找XXX进程。 lspci | grep -i vga查看当前系统中的显卡信息。 lsof -i:8080查看当前8080端口占用，lsof: list open file。 find . -name “*.c”查找当前目录下所有已”.c”结尾的文件。 /var/spool/cron/Linux cron文件的保存位置，老是找不到 = =","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.jelliclecat.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.jelliclecat.cn/tags/Linux/"}]}],"categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.jelliclecat.cn/categories/Mysql/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/categories/Spring/"},{"name":"Summary","slug":"Summary","permalink":"https://www.jelliclecat.cn/categories/Summary/"},{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/categories/Netty/"},{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/categories/Rpc/"},{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/categories/Java/"},{"name":"MutiThread","slug":"MutiThread","permalink":"https://www.jelliclecat.cn/categories/MutiThread/"},{"name":"DCS","slug":"DCS","permalink":"https://www.jelliclecat.cn/categories/DCS/"},{"name":"Linux","slug":"Linux","permalink":"https://www.jelliclecat.cn/categories/Linux/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.jelliclecat.cn/tags/Mysql/"},{"name":"Spring","slug":"Spring","permalink":"https://www.jelliclecat.cn/tags/Spring/"},{"name":"Summary","slug":"Summary","permalink":"https://www.jelliclecat.cn/tags/Summary/"},{"name":"Netty","slug":"Netty","permalink":"https://www.jelliclecat.cn/tags/Netty/"},{"name":"Rpc","slug":"Rpc","permalink":"https://www.jelliclecat.cn/tags/Rpc/"},{"name":"Java","slug":"Java","permalink":"https://www.jelliclecat.cn/tags/Java/"},{"name":"排序","slug":"排序","permalink":"https://www.jelliclecat.cn/tags/%E6%8E%92%E5%BA%8F/"},{"name":"性能","slug":"性能","permalink":"https://www.jelliclecat.cn/tags/%E6%80%A7%E8%83%BD/"},{"name":"DMA","slug":"DMA","permalink":"https://www.jelliclecat.cn/tags/DMA/"},{"name":"多线程","slug":"多线程","permalink":"https://www.jelliclecat.cn/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://www.jelliclecat.cn/tags/Zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"https://www.jelliclecat.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.jelliclecat.cn/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"源码分析","slug":"源码分析","permalink":"https://www.jelliclecat.cn/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"HttpClient","slug":"HttpClient","permalink":"https://www.jelliclecat.cn/tags/HttpClient/"},{"name":"源码","slug":"源码","permalink":"https://www.jelliclecat.cn/tags/%E6%BA%90%E7%A0%81/"},{"name":"并发","slug":"并发","permalink":"https://www.jelliclecat.cn/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Cache","slug":"Cache","permalink":"https://www.jelliclecat.cn/tags/Cache/"},{"name":"Linux","slug":"Linux","permalink":"https://www.jelliclecat.cn/tags/Linux/"},{"name":"Latex","slug":"Latex","permalink":"https://www.jelliclecat.cn/tags/Latex/"}]}